{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1. HP\n",
    "\n",
    "Настройка гиперпараметров и выбор алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io.arff import loadarff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = loadarff('data/raw.arff')\n",
    "data = pd.DataFrame(raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 937 entries, 0 to 936\n",
      "Data columns (total 50 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   class   937 non-null    object \n",
      " 1   attr1   937 non-null    float64\n",
      " 2   attr2   937 non-null    float64\n",
      " 3   attr3   937 non-null    float64\n",
      " 4   attr4   937 non-null    float64\n",
      " 5   attr5   937 non-null    float64\n",
      " 6   attr6   937 non-null    float64\n",
      " 7   attr7   937 non-null    float64\n",
      " 8   attr8   937 non-null    float64\n",
      " 9   attr9   937 non-null    float64\n",
      " 10  attr10  937 non-null    float64\n",
      " 11  attr11  937 non-null    float64\n",
      " 12  attr12  937 non-null    float64\n",
      " 13  attr13  937 non-null    float64\n",
      " 14  attr14  937 non-null    float64\n",
      " 15  attr15  937 non-null    float64\n",
      " 16  attr16  937 non-null    float64\n",
      " 17  attr17  937 non-null    float64\n",
      " 18  attr18  937 non-null    float64\n",
      " 19  attr19  937 non-null    float64\n",
      " 20  attr20  937 non-null    float64\n",
      " 21  attr21  937 non-null    float64\n",
      " 22  attr22  937 non-null    float64\n",
      " 23  attr23  937 non-null    float64\n",
      " 24  attr24  937 non-null    float64\n",
      " 25  attr25  937 non-null    float64\n",
      " 26  attr26  937 non-null    float64\n",
      " 27  attr27  937 non-null    float64\n",
      " 28  attr28  937 non-null    float64\n",
      " 29  attr29  937 non-null    float64\n",
      " 30  attr30  937 non-null    float64\n",
      " 31  attr31  937 non-null    float64\n",
      " 32  attr32  937 non-null    float64\n",
      " 33  attr33  937 non-null    float64\n",
      " 34  attr34  937 non-null    float64\n",
      " 35  attr35  937 non-null    float64\n",
      " 36  attr36  937 non-null    float64\n",
      " 37  attr37  937 non-null    float64\n",
      " 38  attr38  937 non-null    float64\n",
      " 39  attr39  937 non-null    float64\n",
      " 40  attr40  937 non-null    float64\n",
      " 41  attr41  937 non-null    float64\n",
      " 42  attr42  937 non-null    float64\n",
      " 43  attr43  937 non-null    float64\n",
      " 44  attr44  937 non-null    float64\n",
      " 45  attr45  937 non-null    float64\n",
      " 46  attr46  937 non-null    float64\n",
      " 47  attr47  937 non-null    float64\n",
      " 48  attr48  937 non-null    float64\n",
      " 49  attr49  937 non-null    float64\n",
      "dtypes: float64(49), object(1)\n",
      "memory usage: 366.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработайте набор данных, разбейте набор данных на тренировочную, валидационную и тестовую части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"class\"] = data[\"class\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.std()\n",
    "#data.attr23.value_counts()\n",
    "data.drop(columns=['attr23'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = (data - data.mean()) / data.std()\n",
    "normalized[\"class\"] = data[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(562, 187, 188)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled = normalized.sample(frac=1, random_state=1337)\n",
    "train, validate, test = np.split(\n",
    "    shuffled, [int(0.6 * len(shuffled)), int(0.8 * len(shuffled))])\n",
    "len(train), len(validate), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = train.drop(columns=[\"class\"]), train[\"class\"]\n",
    "validateX, validateY = validate.drop(columns=[\"class\"]), validate[\"class\"]\n",
    "testX, testY = test.drop(columns=[\"class\"]), test[\"class\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сведите задачу выбора алгоритма и настройки гиперпараметров к одной задаче настройки гиперпараметров. Можно использовать любую функцию ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-16 22:06:45,380]\u001b[0m A new study created in memory with name: no-name-dfcdab53-afe5-44d5-8a0a-b252c103e921\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,388]\u001b[0m Trial 0 finished with value: 0.37433155080213903 and parameters: {'classifier': 'Gauss', 'smoothing': 1.4696700436240618e-09}. Best is trial 0 with value: 0.37433155080213903.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,438]\u001b[0m Trial 1 finished with value: 0.5775401069518716 and parameters: {'classifier': 'Gauss', 'smoothing': 8.59970907093886e-06}. Best is trial 1 with value: 0.5775401069518716.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,448]\u001b[0m Trial 2 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 3.218015702504886e-09, 'kernel': 'linear', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,455]\u001b[0m Trial 3 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 44, 'min_samples_split': 0.7774578321871413, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,475]\u001b[0m Trial 4 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.030229833667110417, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,684]\u001b[0m Trial 5 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.846177525806897}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,690]\u001b[0m Trial 6 finished with value: 0.6203208556149733 and parameters: {'classifier': 'Gauss', 'smoothing': 0.0002840718773489907}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:06:45,701]\u001b[0m Trial 7 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'l1', 'l1_ratio': 0.6102506131500833, 'max_iter': 1997, 'learning_rate': 'invscaling', 'eta0': 3.745307328559608e-08, 'power_t': -0.31214446695979237, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,709]\u001b[0m Trial 8 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 118, 'min_samples_split': 0.8814856307845202, 'max_features': 'log2', 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,721]\u001b[0m Trial 9 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 2436031.2755333125, 'kernel': 'poly', 'degree': 5, 'gamma': 'auto', 'coef0': 18.366386986965793, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,796]\u001b[0m Trial 10 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.5644527715166394}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,864]\u001b[0m Trial 11 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.6204991307181542}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:45,931]\u001b[0m Trial 12 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.6848576981007555}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,118]\u001b[0m Trial 13 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 23, 'weights': 'distance', 'p': 4.745984208877928}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,221]\u001b[0m Trial 14 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.0467607774075565}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,298]\u001b[0m Trial 15 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 25, 'weights': 'uniform', 'p': 2.436227370670984}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,326]\u001b[0m Trial 16 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'perceptron', 'penalty': 'elasticnet', 'l1_ratio': 1.1148044059885814e-10, 'max_iter': 4995, 'learning_rate': 'optimal', 'eta0': 2.051796950077654, 'power_t': 0.9609994534405393, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,403]\u001b[0m Trial 17 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 40, 'weights': 'uniform', 'p': 2.6712012491421366}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,469]\u001b[0m Trial 18 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 16, 'weights': 'distance', 'p': 1.0806608452229947}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,534]\u001b[0m Trial 19 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 15, 'weights': 'uniform', 'p': 2.1544635323482724}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:06:46,550]\u001b[0m Trial 20 finished with value: 0.9625668449197861 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 192, 'min_samples_split': 0.02194509715821713, 'max_features': 'auto', 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,617]\u001b[0m Trial 21 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.7039552482849378}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,779]\u001b[0m Trial 22 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 1.753549516168106}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,870]\u001b[0m Trial 23 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 3.2536499790220756}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,937]\u001b[0m Trial 24 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 38, 'weights': 'uniform', 'p': 1.5290736020787112}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:46,956]\u001b[0m Trial 25 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'log_loss', 'penalty': 'l2', 'l1_ratio': 8.089116871379312e-06, 'max_iter': 129, 'learning_rate': 'adaptive', 'eta0': 6.10499767749187e-10, 'power_t': -0.9955865591362583, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,020]\u001b[0m Trial 26 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 2.0990549060342123}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,096]\u001b[0m Trial 27 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 20, 'weights': 'distance', 'p': 1.3475890198999796}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,171]\u001b[0m Trial 28 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 31, 'weights': 'uniform', 'p': 2.062004228698319}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,183]\u001b[0m Trial 29 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Gauss', 'smoothing': 0.9518148955993853}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:06:47,204]\u001b[0m Trial 30 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 33, 'min_samples_split': 0.3761992784785692, 'max_features': 'auto', 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,337]\u001b[0m Trial 31 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.5929986598368158}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,442]\u001b[0m Trial 32 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.49426290657204}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,452]\u001b[0m Trial 33 finished with value: 0.37433155080213903 and parameters: {'classifier': 'Gauss', 'smoothing': 1.5208175748815047e-09}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,471]\u001b[0m Trial 34 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 580813052.3295012, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': -46.4646376823197, 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,537]\u001b[0m Trial 35 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.0011910878526862}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,606]\u001b[0m Trial 36 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 50, 'weights': 'uniform', 'p': 1.8970850362078329}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,629]\u001b[0m Trial 37 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'l1', 'l1_ratio': 0.8041677664088489, 'max_iter': 4796, 'learning_rate': 'constant', 'eta0': 0.0014479300886919677, 'power_t': 0.9789678766127545, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,643]\u001b[0m Trial 38 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 1.5893002116769504e-10, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,652]\u001b[0m Trial 39 finished with value: 0.9037433155080213 and parameters: {'classifier': 'Gauss', 'smoothing': 0.35782514977409}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,667]\u001b[0m Trial 40 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 181, 'min_samples_split': 0.9963952842057144, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,760]\u001b[0m Trial 41 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.1382474263844928}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:47,924]\u001b[0m Trial 42 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.3996789862711958}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,047]\u001b[0m Trial 43 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.0218964294214816}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,137]\u001b[0m Trial 44 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.7838501254372972}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,205]\u001b[0m Trial 45 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.3391500669117993}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,240]\u001b[0m Trial 46 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 9.617606794101652, 'kernel': 'poly', 'degree': 1, 'gamma': 'scale', 'coef0': 45.05834299461874, 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,305]\u001b[0m Trial 47 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'distance', 'p': 1.3946830448696335}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,366]\u001b[0m Trial 48 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'squared_epsilon_insensitive', 'penalty': 'elasticnet', 'l1_ratio': 1.338774534174212e-10, 'max_iter': 2755, 'learning_rate': 'adaptive', 'eta0': 4.690396343927483e-06, 'power_t': 0.16720335980728868, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,449]\u001b[0m Trial 49 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 17, 'weights': 'uniform', 'p': 1.693261701475035}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,531]\u001b[0m Trial 50 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.9228256198835239}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,607]\u001b[0m Trial 51 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 14, 'weights': 'uniform', 'p': 1.6631799339187219}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,675]\u001b[0m Trial 52 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.306632690122738}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,743]\u001b[0m Trial 53 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.824512304228323}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,814]\u001b[0m Trial 54 finished with value: 0.9572192513368984 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'distance', 'p': 2.3049091333982483}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,887]\u001b[0m Trial 55 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.929321509865193}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,902]\u001b[0m Trial 56 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 102, 'min_samples_split': 0.5491393320101077, 'max_features': 'log2', 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,969]\u001b[0m Trial 57 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.2146755408646288}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:48,980]\u001b[0m Trial 58 finished with value: 0.5401069518716578 and parameters: {'classifier': 'Gauss', 'smoothing': 8.761063411745274e-07}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,047]\u001b[0m Trial 59 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 20, 'weights': 'uniform', 'p': 1.5732790280445008}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,069]\u001b[0m Trial 60 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'l2', 'l1_ratio': 3.7483390349475754e-06, 'max_iter': 311, 'learning_rate': 'optimal', 'eta0': 1.32041317226576e-10, 'power_t': -0.9541583408078709, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,146]\u001b[0m Trial 61 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.5721985232212168}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,212]\u001b[0m Trial 62 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.6352096692827132}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,278]\u001b[0m Trial 63 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.195339305359984}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,343]\u001b[0m Trial 64 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 2.3091383916174895}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,413]\u001b[0m Trial 65 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.7914338959294818}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,436]\u001b[0m Trial 66 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 5062938890.483902, 'kernel': 'sigmoid', 'gamma': 'auto', 'coef0': -33.72701988602945, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,510]\u001b[0m Trial 67 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 27, 'weights': 'distance', 'p': 2.6007796584487806}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,588]\u001b[0m Trial 68 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 16, 'weights': 'uniform', 'p': 1.4885355153458526}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,603]\u001b[0m Trial 69 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 106, 'min_samples_split': 0.07335454456891166, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,612]\u001b[0m Trial 70 finished with value: 0.6684491978609626 and parameters: {'classifier': 'Gauss', 'smoothing': 0.0016171004548243822}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,688]\u001b[0m Trial 71 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.491623406961582}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,763]\u001b[0m Trial 72 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.268867339958605}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,840]\u001b[0m Trial 73 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 2.0308868908425644}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,907]\u001b[0m Trial 74 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.6795902734336348}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:49,976]\u001b[0m Trial 75 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.4841787154105357}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,048]\u001b[0m Trial 76 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.1262021812334049}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,183]\u001b[0m Trial 77 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 2.1405287066099166}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,210]\u001b[0m Trial 78 finished with value: 0.9411764705882353 and parameters: {'classifier': 'SGD', 'loss': 'squared_hinge', 'penalty': 'l1', 'l1_ratio': 0.0007753236437326075, 'max_iter': 3205, 'learning_rate': 'invscaling', 'eta0': 2.5029524527026643, 'power_t': 0.34566907751508824, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,222]\u001b[0m Trial 79 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 7.230316870529638e-05, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,291]\u001b[0m Trial 80 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.814395182961983}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,363]\u001b[0m Trial 81 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.0853599098622213}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,438]\u001b[0m Trial 82 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.058822293378373}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,524]\u001b[0m Trial 83 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.3483001710398843}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,592]\u001b[0m Trial 84 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.4092393231625795}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,660]\u001b[0m Trial 85 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 14, 'weights': 'uniform', 'p': 1.0117122586136795}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,723]\u001b[0m Trial 86 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 36, 'weights': 'distance', 'p': 1.2076450599108544}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,746]\u001b[0m Trial 87 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 14, 'min_samples_split': 0.6537456839658482, 'max_features': 'log2', 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,833]\u001b[0m Trial 88 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 48, 'weights': 'uniform', 'p': 1.5756672884527587}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,843]\u001b[0m Trial 89 finished with value: 0.49732620320855614 and parameters: {'classifier': 'Gauss', 'smoothing': 1.4841630650192072e-07}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,908]\u001b[0m Trial 90 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.7126702733350396}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:50,975]\u001b[0m Trial 91 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.005471823146016}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,046]\u001b[0m Trial 92 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.2643443277181934}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,115]\u001b[0m Trial 93 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.4143492915235614}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,194]\u001b[0m Trial 94 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.1576128523781484}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,261]\u001b[0m Trial 95 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.948963950569797}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,330]\u001b[0m Trial 96 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.3478121939827068}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,362]\u001b[0m Trial 97 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'elasticnet', 'l1_ratio': 4.068904030424689e-08, 'max_iter': 1528, 'learning_rate': 'constant', 'eta0': 0.0004200995959136704, 'power_t': -0.37382917801191096, 'random_state': 1337}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,429]\u001b[0m Trial 98 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.5771329433009627}. Best is trial 5 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:06:51,448]\u001b[0m Trial 99 finished with value: 0.9786096256684492 and parameters: {'classifier': 'SVC', 'C': 48.81218632183156, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:06:51,467]\u001b[0m Trial 100 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 1241.8674820806866, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:06:51,484]\u001b[0m Trial 101 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 17229.893999983655, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,499]\u001b[0m Trial 102 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.09594006489229308, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,524]\u001b[0m Trial 103 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 4.4502235265788976e-05, 'kernel': 'poly', 'degree': 3, 'gamma': 'scale', 'coef0': -4.6870091578269175, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,589]\u001b[0m Trial 104 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'distance', 'p': 1.8232577041694122}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,662]\u001b[0m Trial 105 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.2151702159177882}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,689]\u001b[0m Trial 106 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 514695.9783071268, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,755]\u001b[0m Trial 107 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 1.693887798335314}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:06:51,773]\u001b[0m Trial 108 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 150, 'min_samples_split': 0.3311822194368551, 'max_features': 'auto', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,860]\u001b[0m Trial 109 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.4570732039554437}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,871]\u001b[0m Trial 110 finished with value: 0.6684491978609626 and parameters: {'classifier': 'Gauss', 'smoothing': 0.001938050794465075}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:51,938]\u001b[0m Trial 111 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.3517173403931666}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,006]\u001b[0m Trial 112 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.1844312923715064}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,075]\u001b[0m Trial 113 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 19, 'weights': 'uniform', 'p': 1.5640590958109568}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,148]\u001b[0m Trial 114 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.45347373817636}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,224]\u001b[0m Trial 115 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 24, 'weights': 'uniform', 'p': 1.7309877617022191}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,294]\u001b[0m Trial 116 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.2891451967370284}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,364]\u001b[0m Trial 117 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.1154513226638565}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,432]\u001b[0m Trial 118 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.6436569577471731}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,456]\u001b[0m Trial 119 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'l2', 'l1_ratio': 0.0013144307611954434, 'max_iter': 3604, 'learning_rate': 'optimal', 'eta0': 1.8469960801961645e-07, 'power_t': 0.5249225525175112, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,538]\u001b[0m Trial 120 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.9228185210410034}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,608]\u001b[0m Trial 121 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.8334073016662686}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,679]\u001b[0m Trial 122 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 2.0195355445894223}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,749]\u001b[0m Trial 123 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.48026861928413}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,816]\u001b[0m Trial 124 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'distance', 'p': 1.7627774910933258}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,899]\u001b[0m Trial 125 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.5612208958913303}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:52,974]\u001b[0m Trial 126 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.2902906132541263}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,053]\u001b[0m Trial 127 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 1.6530994041390292}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,073]\u001b[0m Trial 128 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 88.3158117516289, 'kernel': 'sigmoid', 'gamma': 'auto', 'coef0': -11.845692462006745, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,149]\u001b[0m Trial 129 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.3717013424524658}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,166]\u001b[0m Trial 130 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 68, 'min_samples_split': 0.7014805902585521, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,263]\u001b[0m Trial 131 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.0128070672785612}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,337]\u001b[0m Trial 132 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 28, 'weights': 'uniform', 'p': 1.128535983736529}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,408]\u001b[0m Trial 133 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.5111207244698928}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,484]\u001b[0m Trial 134 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.401603821458313}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,571]\u001b[0m Trial 135 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.2260276220284219}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,644]\u001b[0m Trial 136 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.8591167683533287}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,718]\u001b[0m Trial 137 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.7035098444658874}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,729]\u001b[0m Trial 138 finished with value: 0.7593582887700535 and parameters: {'classifier': 'Gauss', 'smoothing': 0.04200448506881092}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,748]\u001b[0m Trial 139 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SVC', 'C': 3.6925196029159033, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,818]\u001b[0m Trial 140 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.5972927205250396}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,900]\u001b[0m Trial 141 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'distance', 'p': 1.3385596384890819}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:53,974]\u001b[0m Trial 142 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'distance', 'p': 1.0886560004323653}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:54,050]\u001b[0m Trial 143 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'distance', 'p': 1.502202060886034}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:54,119]\u001b[0m Trial 144 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'distance', 'p': 1.2685975930117177}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:54,192]\u001b[0m Trial 145 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.3990486183763797}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:54,221]\u001b[0m Trial 146 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'l1', 'l1_ratio': 2.0741747061454722e-08, 'max_iter': 1175, 'learning_rate': 'constant', 'eta0': 0.0026126277550476405, 'power_t': -0.15666939160334498, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:54,319]\u001b[0m Trial 147 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.7519837457339502}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:54,425]\u001b[0m Trial 148 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.1619789811104502}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:54,596]\u001b[0m Trial 149 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 15, 'weights': 'distance', 'p': 1.5870008312370798}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:54,691]\u001b[0m Trial 150 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.641248899716188}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:54,764]\u001b[0m Trial 151 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.9121535090732962}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:54,838]\u001b[0m Trial 152 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.7836715077368313}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:54,946]\u001b[0m Trial 153 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.447070131789991}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:55,019]\u001b[0m Trial 154 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.5267815944629104}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:55,095]\u001b[0m Trial 155 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.9659797986453675}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:06:55,184]\u001b[0m Trial 156 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 4904228.967297536, 'kernel': 'linear', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:55,287]\u001b[0m Trial 157 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.0672466152596225}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:55,380]\u001b[0m Trial 158 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.286979411973214}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:06:55,401]\u001b[0m Trial 159 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 147, 'min_samples_split': 0.23521949700850542, 'max_features': 'auto', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:55,482]\u001b[0m Trial 160 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 14, 'weights': 'uniform', 'p': 1.6406020515721802}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:55,567]\u001b[0m Trial 161 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.2024470277341277}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:55,668]\u001b[0m Trial 162 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.4233162146125333}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:55,786]\u001b[0m Trial 163 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.330840145854741}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:55,894]\u001b[0m Trial 164 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.8435730473293654}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:56,010]\u001b[0m Trial 165 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.7339329042605345}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:56,028]\u001b[0m Trial 166 finished with value: 0.5828877005347594 and parameters: {'classifier': 'Gauss', 'smoothing': 2.8377940626687488e-05}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:56,120]\u001b[0m Trial 167 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.5312074135944043}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:56,230]\u001b[0m Trial 168 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 17, 'weights': 'uniform', 'p': 1.138149690139692}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:56,367]\u001b[0m Trial 169 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.2263322858396581}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:06:56,406]\u001b[0m Trial 170 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 4864.589168114385, 'kernel': 'poly', 'degree': 1, 'gamma': 'scale', 'coef0': 44.92900941334618, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:56,492]\u001b[0m Trial 171 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.800442662226478}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:56,594]\u001b[0m Trial 172 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 42, 'weights': 'uniform', 'p': 2.063702385409159}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:56,718]\u001b[0m Trial 173 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.6679500597771073}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:56,808]\u001b[0m Trial 174 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.4593139959993913}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:56,887]\u001b[0m Trial 175 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.910217757126387}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:56,916]\u001b[0m Trial 176 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'l2', 'l1_ratio': 0.008126811210223683, 'max_iter': 4016, 'learning_rate': 'adaptive', 'eta0': 1.7372112482816583e-08, 'power_t': -0.6023560006436159, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,055]\u001b[0m Trial 177 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'distance', 'p': 1.0218880269908375}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,130]\u001b[0m Trial 178 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.6001349263544424}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,200]\u001b[0m Trial 179 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.330876333753972}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,270]\u001b[0m Trial 180 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.734347829667545}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,351]\u001b[0m Trial 181 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.990797867747247}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,423]\u001b[0m Trial 182 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 2.186560161383321}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,503]\u001b[0m Trial 183 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 22, 'weights': 'uniform', 'p': 1.8792679185330337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,576]\u001b[0m Trial 184 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.802781376956937}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,704]\u001b[0m Trial 185 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.6912751234736438}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,789]\u001b[0m Trial 186 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.538701976037116}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,855]\u001b[0m Trial 187 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'distance', 'p': 1.3919299623041472}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,886]\u001b[0m Trial 188 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.002457079781617154, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': 14.621963439171148, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,956]\u001b[0m Trial 189 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.0895159224208215}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:57,974]\u001b[0m Trial 190 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 70, 'min_samples_split': 0.5470501328488864, 'max_features': 'log2', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,060]\u001b[0m Trial 191 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 1.5879659476304273}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,155]\u001b[0m Trial 192 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.4907992554587324}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,235]\u001b[0m Trial 193 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.6412637757622555}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,324]\u001b[0m Trial 194 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 33, 'weights': 'uniform', 'p': 1.277035371636006}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,415]\u001b[0m Trial 195 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.8976965889761168}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,499]\u001b[0m Trial 196 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.7632737568870922}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,572]\u001b[0m Trial 197 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.1936564109083738}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,656]\u001b[0m Trial 198 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.4374607864843627}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,741]\u001b[0m Trial 199 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 2.015453805429663}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,753]\u001b[0m Trial 200 finished with value: 0.5240641711229946 and parameters: {'classifier': 'Gauss', 'smoothing': 3.409570890703136e-07}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,826]\u001b[0m Trial 201 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.6500958869075564}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,903]\u001b[0m Trial 202 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.5222703419895112}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:58,982]\u001b[0m Trial 203 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.8381172753248074}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,075]\u001b[0m Trial 204 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.7374666130545984}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,159]\u001b[0m Trial 205 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.5918980405563212}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,234]\u001b[0m Trial 206 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'distance', 'p': 1.3693459263543524}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,311]\u001b[0m Trial 207 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.1176316708429244}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,329]\u001b[0m Trial 208 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 81.36729176664818, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,418]\u001b[0m Trial 209 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 2.887451478913077}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,501]\u001b[0m Trial 210 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.9522213342409274}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,578]\u001b[0m Trial 211 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.0163329959844816}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,659]\u001b[0m Trial 212 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.2483853851784963}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,747]\u001b[0m Trial 213 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.1844078091980421}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:06:59,775]\u001b[0m Trial 214 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 0.00012007855288676076, 'max_iter': 948, 'learning_rate': 'invscaling', 'eta0': 3.5651834999261375e-06, 'power_t': 0.03352551743427473, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,858]\u001b[0m Trial 215 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.3253861552578037}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:06:59,935]\u001b[0m Trial 216 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.6926956850006094}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,014]\u001b[0m Trial 217 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.4607086907279248}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,099]\u001b[0m Trial 218 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.5374048839017718}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,171]\u001b[0m Trial 219 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.1299548686235532}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,241]\u001b[0m Trial 220 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'distance', 'p': 1.8291682367841435}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,318]\u001b[0m Trial 221 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 14, 'weights': 'uniform', 'p': 2.4350056081842735}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,416]\u001b[0m Trial 222 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 2.1140482666966234}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,491]\u001b[0m Trial 223 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.632491572274002}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,566]\u001b[0m Trial 224 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 2.216757365290648}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,637]\u001b[0m Trial 225 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.7406684417369498}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,708]\u001b[0m Trial 226 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.8917977677697506}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,726]\u001b[0m Trial 227 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 1.8591668848662044e-07, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,811]\u001b[0m Trial 228 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 2.059335248301654}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:00,832]\u001b[0m Trial 229 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 6, 'min_samples_split': 0.4152792921354415, 'max_features': 'auto', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,908]\u001b[0m Trial 230 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 15, 'weights': 'uniform', 'p': 1.3873011642004252}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:00,988]\u001b[0m Trial 231 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.8280884778146875}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,102]\u001b[0m Trial 232 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.7828196785137516}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,197]\u001b[0m Trial 233 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.6923830944143736}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,297]\u001b[0m Trial 234 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.6129400426895308}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,375]\u001b[0m Trial 235 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.980602122201742}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,476]\u001b[0m Trial 236 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.5031902568787296}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,488]\u001b[0m Trial 237 finished with value: 0.7486631016042781 and parameters: {'classifier': 'Gauss', 'smoothing': 0.029989898224570027}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,565]\u001b[0m Trial 238 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.938155343086073}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,639]\u001b[0m Trial 239 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.5787589172569951}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,707]\u001b[0m Trial 240 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'distance', 'p': 1.2739836318256854}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,800]\u001b[0m Trial 241 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.4671017997889702}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,872]\u001b[0m Trial 242 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.7258287475109666}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:01,943]\u001b[0m Trial 243 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.5478502043395614}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,017]\u001b[0m Trial 244 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.4039085692170703}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,088]\u001b[0m Trial 245 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.7926986360393862}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,172]\u001b[0m Trial 246 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.6568162833630051}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,243]\u001b[0m Trial 247 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.0048925144493697}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,318]\u001b[0m Trial 248 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.873058011275227}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,349]\u001b[0m Trial 249 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.1566217569883333, 'kernel': 'linear', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,420]\u001b[0m Trial 250 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.2223276062717345}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,451]\u001b[0m Trial 251 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'squared_hinge', 'penalty': 'l2', 'l1_ratio': 4.7216243253645074e-07, 'max_iter': 2481, 'learning_rate': 'optimal', 'eta0': 0.07860568073861468, 'power_t': 0.5904098337146912, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,530]\u001b[0m Trial 252 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.3339099816508073}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,603]\u001b[0m Trial 253 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.0919064702428904}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,673]\u001b[0m Trial 254 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.4491778553113264}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,745]\u001b[0m Trial 255 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.582313904019693}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,824]\u001b[0m Trial 256 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'distance', 'p': 2.349262427130698}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,898]\u001b[0m Trial 257 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.6913156398911209}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:02,968]\u001b[0m Trial 258 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 2.6087832820568586}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,038]\u001b[0m Trial 259 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.780439281514536}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,112]\u001b[0m Trial 260 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 3.4548411137713413}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,191]\u001b[0m Trial 261 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.5046503708502657}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,210]\u001b[0m Trial 262 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 162, 'min_samples_split': 0.1932914323676443, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,230]\u001b[0m Trial 263 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 1.608710419862005, 'kernel': 'sigmoid', 'gamma': 'auto', 'coef0': -45.876266839124455, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,300]\u001b[0m Trial 264 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 1.1503677248749773}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,427]\u001b[0m Trial 265 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 17, 'weights': 'uniform', 'p': 1.3913919837656683}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,528]\u001b[0m Trial 266 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.660425629300475}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,540]\u001b[0m Trial 267 finished with value: 0.41711229946524064 and parameters: {'classifier': 'Gauss', 'smoothing': 2.528793497296288e-08}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,692]\u001b[0m Trial 268 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.8966530569468825}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,831]\u001b[0m Trial 269 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.2977460300680783}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:03,927]\u001b[0m Trial 270 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'distance', 'p': 1.5879531447949273}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:04,028]\u001b[0m Trial 271 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 2.0170743831453457}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:04,121]\u001b[0m Trial 272 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.767614897552974}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:04,228]\u001b[0m Trial 273 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 30, 'weights': 'uniform', 'p': 1.49926720687924}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:04,318]\u001b[0m Trial 274 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.2474194535174647}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:04,462]\u001b[0m Trial 275 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.3944394846944699}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:04,513]\u001b[0m Trial 276 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'l1', 'l1_ratio': 0.015237557638174883, 'max_iter': 4225, 'learning_rate': 'constant', 'eta0': 7.320188323824371e-05, 'power_t': -0.6542569180244542, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:04,708]\u001b[0m Trial 277 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.05883479139157}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:04,741]\u001b[0m Trial 278 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.0019872786408210927, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:04,924]\u001b[0m Trial 279 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.7076034637663369}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:05,105]\u001b[0m Trial 280 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.1866114984913592}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:05,232]\u001b[0m Trial 281 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 44, 'weights': 'uniform', 'p': 1.8476173682917074}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:05,352]\u001b[0m Trial 282 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.6154734498025627}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:05,467]\u001b[0m Trial 283 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 2.1196696123296443}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:05,589]\u001b[0m Trial 284 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'distance', 'p': 1.9631558770035498}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:05,715]\u001b[0m Trial 285 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.5277290738267455}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:05,830]\u001b[0m Trial 286 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.3417097435432865}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:05,955]\u001b[0m Trial 287 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.793777943028503}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:06,068]\u001b[0m Trial 288 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.0009770973475651}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:06,099]\u001b[0m Trial 289 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 78, 'min_samples_split': 0.48004039406411, 'max_features': 'log2', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:06,236]\u001b[0m Trial 290 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.4563696126896135}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:06,311]\u001b[0m Trial 291 finished with value: 0.9358288770053476 and parameters: {'classifier': 'SVC', 'C': 116319.9124194551, 'kernel': 'poly', 'degree': 5, 'gamma': 'auto', 'coef0': -22.544447354232332, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:06,424]\u001b[0m Trial 292 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.6668598149033125}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:06,539]\u001b[0m Trial 293 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 14, 'weights': 'uniform', 'p': 1.1273045636002563}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:06,657]\u001b[0m Trial 294 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.6033579418393311}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:06,673]\u001b[0m Trial 295 finished with value: 0.5721925133689839 and parameters: {'classifier': 'Gauss', 'smoothing': 5.691113062305296e-06}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:06,791]\u001b[0m Trial 296 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.873627259310688}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:06,920]\u001b[0m Trial 297 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 20, 'weights': 'distance', 'p': 1.2969976737114415}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:07,052]\u001b[0m Trial 298 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.7339438088036987}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:07,185]\u001b[0m Trial 299 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.4372722900948496}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:07,299]\u001b[0m Trial 300 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.9558739912669019}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:07,375]\u001b[0m Trial 301 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 2.0618023574760627}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:07,411]\u001b[0m Trial 302 finished with value: 0.44919786096256686 and parameters: {'classifier': 'SGD', 'loss': 'squared_epsilon_insensitive', 'penalty': 'elasticnet', 'l1_ratio': 7.667370650636329e-05, 'max_iter': 2063, 'learning_rate': 'adaptive', 'eta0': 0.013621346176560068, 'power_t': 0.10684662660394181, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:07,490]\u001b[0m Trial 303 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.5509735211873557}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:07,592]\u001b[0m Trial 304 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.192073617881614}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:07,671]\u001b[0m Trial 305 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.8316990482436633}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:07,694]\u001b[0m Trial 306 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 135661014.7551153, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:07,772]\u001b[0m Trial 307 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 2.2422355620626244}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:07,849]\u001b[0m Trial 308 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.0829396238078899}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:07,950]\u001b[0m Trial 309 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 26, 'weights': 'uniform', 'p': 1.6946016134495037}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,026]\u001b[0m Trial 310 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 15, 'weights': 'distance', 'p': 1.355948105196541}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,122]\u001b[0m Trial 311 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.5083713573130955}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,283]\u001b[0m Trial 312 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.6299821025686838}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,390]\u001b[0m Trial 313 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.2489944358314877}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:08,418]\u001b[0m Trial 314 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 131, 'min_samples_split': 0.13051067028661534, 'max_features': 'auto', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,491]\u001b[0m Trial 315 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 37, 'weights': 'uniform', 'p': 1.7389957255295398}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,565]\u001b[0m Trial 316 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 2.1214514708052827}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,649]\u001b[0m Trial 317 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.4433636907930762}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,723]\u001b[0m Trial 318 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.5527560411959527}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,767]\u001b[0m Trial 319 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SVC', 'C': 215.7439588145633, 'kernel': 'poly', 'degree': 3, 'gamma': 'scale', 'coef0': 12.02864419391972, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,838]\u001b[0m Trial 320 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.913281194953115}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,908]\u001b[0m Trial 321 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.7856304492119586}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:08,921]\u001b[0m Trial 322 finished with value: 0.6203208556149733 and parameters: {'classifier': 'Gauss', 'smoothing': 0.0002807777083663637}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,002]\u001b[0m Trial 323 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.3776524546437972}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,075]\u001b[0m Trial 324 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'distance', 'p': 1.1465155789357622}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,150]\u001b[0m Trial 325 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.6377111077529602}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,221]\u001b[0m Trial 326 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 23, 'weights': 'uniform', 'p': 2.002014738048637}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,303]\u001b[0m Trial 327 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 2.453694784227936}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,375]\u001b[0m Trial 328 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.2894870451658127}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,403]\u001b[0m Trial 329 finished with value: 0.9037433155080213 and parameters: {'classifier': 'SGD', 'loss': 'log_loss', 'penalty': 'l2', 'l1_ratio': 5.069202846960621e-09, 'max_iter': 718, 'learning_rate': 'invscaling', 'eta0': 6.430033963216053e-05, 'power_t': 0.7543911495308748, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,477]\u001b[0m Trial 330 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.4626959054219137}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,549]\u001b[0m Trial 331 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.8373742253597112}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,647]\u001b[0m Trial 332 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.576007992798937}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,721]\u001b[0m Trial 333 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.6952146494853677}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,740]\u001b[0m Trial 334 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 7.543095515976887e-07, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,812]\u001b[0m Trial 335 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.0933632538359659}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,885]\u001b[0m Trial 336 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.7721712850895488}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:09,974]\u001b[0m Trial 337 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.2196745143502477}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,042]\u001b[0m Trial 338 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'distance', 'p': 1.0006352002495718}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,119]\u001b[0m Trial 339 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.9066530604137921}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,190]\u001b[0m Trial 340 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.3482463697990208}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,211]\u001b[0m Trial 341 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 91, 'min_samples_split': 0.2717535578096757, 'max_features': 'log2', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,305]\u001b[0m Trial 342 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.5374871295630472}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,400]\u001b[0m Trial 343 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 2.733745674986686}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,477]\u001b[0m Trial 344 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 2.1816344193606616}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,550]\u001b[0m Trial 345 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 2.0471950805711314}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,563]\u001b[0m Trial 346 finished with value: 0.40641711229946526 and parameters: {'classifier': 'Gauss', 'smoothing': 1.5883340801744312e-08}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,649]\u001b[0m Trial 347 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 1.6162455159339741}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,674]\u001b[0m Trial 348 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 20888.53550573563, 'kernel': 'sigmoid', 'gamma': 'auto', 'coef0': -23.489760695739164, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,746]\u001b[0m Trial 349 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.4250066434514168}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,859]\u001b[0m Trial 350 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 3.1214114469076546}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:10,927]\u001b[0m Trial 351 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'distance', 'p': 1.7047206925339067}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,018]\u001b[0m Trial 352 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.8479979955712023}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,092]\u001b[0m Trial 353 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.497613898452145}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,168]\u001b[0m Trial 354 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.2961879950262445}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,207]\u001b[0m Trial 355 finished with value: 0.32085561497326204 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'elasticnet', 'l1_ratio': 1.1629719718104022e-06, 'max_iter': 3184, 'learning_rate': 'optimal', 'eta0': 6.754890572342144e-07, 'power_t': 0.3237433599705627, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,284]\u001b[0m Trial 356 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.1396736971393133}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,370]\u001b[0m Trial 357 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.6850321699264863}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,444]\u001b[0m Trial 358 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.924094108921864}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,519]\u001b[0m Trial 359 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.7560619959197994}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,597]\u001b[0m Trial 360 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 34, 'weights': 'uniform', 'p': 1.601122831595855}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,684]\u001b[0m Trial 361 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 16, 'weights': 'uniform', 'p': 1.1941691427283092}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,715]\u001b[0m Trial 362 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 34228527.247230045, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,789]\u001b[0m Trial 363 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.3832377318909241}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,862]\u001b[0m Trial 364 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'distance', 'p': 1.825701310133846}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:11,940]\u001b[0m Trial 365 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.078424506255375}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,027]\u001b[0m Trial 366 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 50, 'weights': 'uniform', 'p': 1.4966624826152362}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,048]\u001b[0m Trial 367 finished with value: 0.9572192513368984 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 40, 'min_samples_split': 0.0038589602866245243, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,123]\u001b[0m Trial 368 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 4.6577031099357225}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,198]\u001b[0m Trial 369 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.254266901112476}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,271]\u001b[0m Trial 370 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.9794895857244557}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,359]\u001b[0m Trial 371 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.6480732586660485}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,372]\u001b[0m Trial 372 finished with value: 0.5401069518716578 and parameters: {'classifier': 'Gauss', 'smoothing': 1.7368227642054119e-06}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,445]\u001b[0m Trial 373 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 2.2832023773754972}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,520]\u001b[0m Trial 374 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.4460782799824914}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,594]\u001b[0m Trial 375 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.7603727742906878}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,684]\u001b[0m Trial 376 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.5507413274053707}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:12,708]\u001b[0m Trial 377 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 329241.48972914566, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,782]\u001b[0m Trial 378 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'distance', 'p': 2.086530492413481}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,867]\u001b[0m Trial 379 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 19, 'weights': 'uniform', 'p': 1.3042821556597353}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:12,941]\u001b[0m Trial 380 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.8753029663435783}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,030]\u001b[0m Trial 381 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.0620356511579092}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,057]\u001b[0m Trial 382 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'perceptron', 'penalty': 'l1', 'l1_ratio': 2.599661305860722e-07, 'max_iter': 4478, 'learning_rate': 'invscaling', 'eta0': 2.4338565394698802e-05, 'power_t': -0.08707032348653268, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,135]\u001b[0m Trial 383 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 14, 'weights': 'uniform', 'p': 1.39459567384874}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,211]\u001b[0m Trial 384 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.6288197228749643}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,287]\u001b[0m Trial 385 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.2090791720770004}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,374]\u001b[0m Trial 386 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.7042092937688893}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,452]\u001b[0m Trial 387 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.538712755955399}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,533]\u001b[0m Trial 388 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.7851523715288982}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,609]\u001b[0m Trial 389 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.9951497193596017}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,632]\u001b[0m Trial 390 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 9034915851.237186, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,710]\u001b[0m Trial 391 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'distance', 'p': 1.352874863257074}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,790]\u001b[0m Trial 392 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 2.150455687305696}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,814]\u001b[0m Trial 393 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 198, 'min_samples_split': 0.1787141661813494, 'max_features': 'log2', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,886]\u001b[0m Trial 394 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 2.3701337730244907}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:13,982]\u001b[0m Trial 395 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.469868788896567}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,068]\u001b[0m Trial 396 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 1.150828343205355}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,143]\u001b[0m Trial 397 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.5949055673570307}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,156]\u001b[0m Trial 398 finished with value: 0.5882352941176471 and parameters: {'classifier': 'Gauss', 'smoothing': 3.472889902835203e-05}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,246]\u001b[0m Trial 399 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.9027670169947442}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,319]\u001b[0m Trial 400 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.6885041144593063}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,402]\u001b[0m Trial 401 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.8277928886585453}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,478]\u001b[0m Trial 402 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.263912614595345}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,553]\u001b[0m Trial 403 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.4265210308034544}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,626]\u001b[0m Trial 404 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'distance', 'p': 1.5266516724202566}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,676]\u001b[0m Trial 405 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 7007371.739803887, 'kernel': 'poly', 'degree': 2, 'gamma': 'scale', 'coef0': 30.704838159888947, 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,766]\u001b[0m Trial 406 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.0621009736506488}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,841]\u001b[0m Trial 407 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.7416589039745936}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,873]\u001b[0m Trial 408 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'elasticnet', 'l1_ratio': 9.9050486456213e-10, 'max_iter': 1712, 'learning_rate': 'adaptive', 'eta0': 2.6882253621400188e-09, 'power_t': 0.2628138549418868, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:14,947]\u001b[0m Trial 409 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 14, 'weights': 'uniform', 'p': 1.0052112320067565}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,021]\u001b[0m Trial 410 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.6309139123436673}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,105]\u001b[0m Trial 411 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 29, 'weights': 'uniform', 'p': 1.944847710122137}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,181]\u001b[0m Trial 412 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.3371693610655515}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,256]\u001b[0m Trial 413 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.163032190180358}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,332]\u001b[0m Trial 414 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.8344761679034376}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,418]\u001b[0m Trial 415 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 2.0306654827218344}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,493]\u001b[0m Trial 416 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 2.250845153485188}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,565]\u001b[0m Trial 417 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'distance', 'p': 1.5157807339090965}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,599]\u001b[0m Trial 418 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 2.0071761018946e-10, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': 3.068423182862564, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:15,623]\u001b[0m Trial 419 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 170, 'min_samples_split': 0.45616247726626596, 'max_features': 'auto', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,775]\u001b[0m Trial 420 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.7517428566154651}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,855]\u001b[0m Trial 421 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.4146779587307845}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:15,933]\u001b[0m Trial 422 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 48, 'weights': 'uniform', 'p': 2.429740365916807}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,013]\u001b[0m Trial 423 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.5930399395433066}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,102]\u001b[0m Trial 424 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 2.1728320069804603}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,116]\u001b[0m Trial 425 finished with value: 0.4919786096256685 and parameters: {'classifier': 'Gauss', 'smoothing': 1.04418798004073e-07}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,200]\u001b[0m Trial 426 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 39, 'weights': 'uniform', 'p': 1.6702872412613312}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,280]\u001b[0m Trial 427 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.2678906993932513}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,356]\u001b[0m Trial 428 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.1150930919823785}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,444]\u001b[0m Trial 429 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 2.520618083083497}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,531]\u001b[0m Trial 430 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.8632368871015192}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,615]\u001b[0m Trial 431 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'distance', 'p': 2.7221580693194998}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,696]\u001b[0m Trial 432 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 1.4650405059844096}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,750]\u001b[0m Trial 433 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SVC', 'C': 0.948739934705356, 'kernel': 'linear', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,833]\u001b[0m Trial 434 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.3497999807434469}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,867]\u001b[0m Trial 435 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'l2', 'l1_ratio': 2.7918577313130426e-05, 'max_iter': 3797, 'learning_rate': 'constant', 'eta0': 1.0276899289169508e-10, 'power_t': -0.1859099226930429, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:16,957]\u001b[0m Trial 436 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.193632436113606}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,034]\u001b[0m Trial 437 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.7670406323444885}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,120]\u001b[0m Trial 438 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 1.5808435610675933}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,197]\u001b[0m Trial 439 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 2.1112854620252617}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,275]\u001b[0m Trial 440 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.6680234972088883}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,349]\u001b[0m Trial 441 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 2.2788820305379964}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,445]\u001b[0m Trial 442 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.9374926582828627}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,525]\u001b[0m Trial 443 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 1.5415224271968047}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,549]\u001b[0m Trial 444 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 57, 'min_samples_split': 0.5642419766630907, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,621]\u001b[0m Trial 445 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'distance', 'p': 2.960946999310404}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,719]\u001b[0m Trial 446 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.4509253456450881}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,743]\u001b[0m Trial 447 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 17.568298721083007, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,841]\u001b[0m Trial 448 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.253611773848291}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:17,923]\u001b[0m Trial 449 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.8114972684056014}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,005]\u001b[0m Trial 450 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.7154798828673177}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,088]\u001b[0m Trial 451 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 2.060970718029975}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,180]\u001b[0m Trial 452 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 3.2819923909266366}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,192]\u001b[0m Trial 453 finished with value: 0.40106951871657753 and parameters: {'classifier': 'Gauss', 'smoothing': 9.398256625101055e-09}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,275]\u001b[0m Trial 454 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.3628674230687696}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,354]\u001b[0m Trial 455 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.001326471506582}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,436]\u001b[0m Trial 456 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 21, 'weights': 'uniform', 'p': 1.6322856211234391}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,527]\u001b[0m Trial 457 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 15, 'weights': 'uniform', 'p': 1.0871992714233905}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,604]\u001b[0m Trial 458 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'distance', 'p': 2.792664704423425}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,688]\u001b[0m Trial 459 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.9831515962565196}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,776]\u001b[0m Trial 460 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 2.374421294982059}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:18,825]\u001b[0m Trial 461 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'l1', 'l1_ratio': 1.0605390308140536e-07, 'max_iter': 2839, 'learning_rate': 'optimal', 'eta0': 3.271185402919303e-09, 'power_t': 0.06769982374961564, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,874]\u001b[0m Trial 462 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SVC', 'C': 347975376.5723033, 'kernel': 'poly', 'degree': 4, 'gamma': 'auto', 'coef0': 31.00955112829995, 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:18,951]\u001b[0m Trial 463 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.5564974877635922}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,032]\u001b[0m Trial 464 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.9069305011993531}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,109]\u001b[0m Trial 465 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.48128332795967}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,193]\u001b[0m Trial 466 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.315775440873687}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,271]\u001b[0m Trial 467 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.1625066317599042}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,349]\u001b[0m Trial 468 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 1.7242006689127003}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,425]\u001b[0m Trial 469 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.799648457216279}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,520]\u001b[0m Trial 470 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 2, 'weights': 'uniform', 'p': 2.223188583408941}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,542]\u001b[0m Trial 471 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 126, 'min_samples_split': 0.2687459330352733, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,616]\u001b[0m Trial 472 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 32, 'weights': 'distance', 'p': 2.5828818086624294}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,698]\u001b[0m Trial 473 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.632279171294852}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,778]\u001b[0m Trial 474 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 1.3881327369730698}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:19,812]\u001b[0m Trial 475 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 1124.67849155807, 'kernel': 'linear', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,899]\u001b[0m Trial 476 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.841039196662511}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:19,977]\u001b[0m Trial 477 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 2.6516098378190875}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,057]\u001b[0m Trial 478 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.2138052882426047}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,071]\u001b[0m Trial 479 finished with value: 0.5294117647058824 and parameters: {'classifier': 'Gauss', 'smoothing': 4.350942308773697e-07}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,174]\u001b[0m Trial 480 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 1.4890234919807317}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,256]\u001b[0m Trial 481 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 1.7221249368986211}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,338]\u001b[0m Trial 482 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 1.57404361905213}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,419]\u001b[0m Trial 483 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 1.0905326309467647}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,514]\u001b[0m Trial 484 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'uniform', 'p': 1.6621654403806807}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,589]\u001b[0m Trial 485 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'distance', 'p': 1.892396524420784}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,625]\u001b[0m Trial 486 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'squared_hinge', 'penalty': 'l1', 'l1_ratio': 2.651084753618651e-06, 'max_iter': 445, 'learning_rate': 'constant', 'eta0': 4.124012730289416e-07, 'power_t': 0.5103884688477067, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,702]\u001b[0m Trial 487 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.4142364365868707}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,787]\u001b[0m Trial 488 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 1.3026525545950556}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,872]\u001b[0m Trial 489 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 17, 'weights': 'uniform', 'p': 1.7999394314791086}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:20,900]\u001b[0m Trial 490 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 5.473603209388773e-09, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': -10.330319527356124, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:21,049]\u001b[0m Trial 491 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 2.0382804467278097}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:21,143]\u001b[0m Trial 492 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 2.4942670367535134}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:21,233]\u001b[0m Trial 493 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 1.5027741555407823}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:21,341]\u001b[0m Trial 494 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 27, 'weights': 'uniform', 'p': 1.2400416339484084}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:21,460]\u001b[0m Trial 495 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'uniform', 'p': 2.853427982793805}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:21,574]\u001b[0m Trial 496 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.5933492809688312}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:21,653]\u001b[0m Trial 497 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 2.1137176516583325}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:21,726]\u001b[0m Trial 498 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'distance', 'p': 2.5747212294150668}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:21,755]\u001b[0m Trial 499 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 28, 'min_samples_split': 0.3366423049372089, 'max_features': 'log2', 'random_state': 1337}. Best is trial 99 with value: 0.9786096256684492.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Study):\n",
    "    classifier_name = trial.suggest_categorical(\n",
    "        'classifier', ['KNN', 'SVC', 'Gauss', 'Tree', 'SGD']\n",
    "    )\n",
    "\n",
    "    if classifier_name == 'KNN':\n",
    "        neighbors = trial.suggest_int('n_neighbors', 2, 50)\n",
    "        weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "        p = trial.suggest_float('p', 1.0, 5.0)\n",
    "        classifier_obj = KNeighborsClassifier(\n",
    "            n_neighbors=neighbors, weights=weights, p=p\n",
    "        )\n",
    "    elif classifier_name == 'SVC':\n",
    "        C = trial.suggest_float(\"C\", 1e-10, 1e10, log=True)\n",
    "        kernel = trial.suggest_categorical(\n",
    "            \"kernel\", ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "        degree = 3\n",
    "        if kernel == 'poly':\n",
    "            degree = trial.suggest_int('degree', 1, 5)\n",
    "        gamma = 'scale'\n",
    "        if kernel in ['rbf', 'poly', 'sigmoid']:\n",
    "            gamma = trial.suggest_categorical(\"gamma\", ['scale', 'auto'])\n",
    "        coef0 = 0.0\n",
    "        if kernel in ['poly', 'sigmoid']:\n",
    "            coef0 = trial.suggest_float('coef0', -50.0, 50.0)\n",
    "        shrinking = trial.suggest_categorical(\"shrinking\", [True, False])\n",
    "        probability = trial.suggest_categorical(\"probability\", [True, False])\n",
    "        random_state = trial.suggest_categorical(\"random_state\", [1337])\n",
    "        classifier_obj = SVC(\n",
    "            C=C, kernel=kernel, gamma=gamma, shrinking=shrinking,\n",
    "            probability=probability, random_state=random_state,\n",
    "            degree=degree, coef0=coef0, max_iter=5000\n",
    "        )\n",
    "    elif classifier_name == 'Gauss':\n",
    "        var_smoothing = trial.suggest_float(\"smoothing\", 1e-9, 1, log=True)\n",
    "        classifier_obj = GaussianNB(\n",
    "            var_smoothing=var_smoothing\n",
    "        )\n",
    "    elif classifier_name == 'Tree':\n",
    "        criterion = trial.suggest_categorical(\n",
    "            \"criterion\", [\"gini\", \"entropy\", \"log_loss\"])\n",
    "        splitter = trial.suggest_categorical(\"splitter\", [\"best\", \"random\"])\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 5, 200)\n",
    "        min_samples_split = trial.suggest_float(\n",
    "            \"min_samples_split\", 1e-3, 1 - 1e-3)\n",
    "        max_features = trial.suggest_categorical(\n",
    "            \"max_features\", [\"auto\", \"sqrt\", \"log2\"])\n",
    "        random_state = trial.suggest_categorical(\"random_state\", [1337])\n",
    "        classifier_obj = DecisionTreeClassifier(\n",
    "            criterion=criterion, splitter=splitter, max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split, max_features=max_features,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        loss = trial.suggest_categorical(\"loss\", ['hinge', 'log_loss', 'log', 'modified_huber', 'squared_hinge', 'perceptron',\n",
    "                                                  'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'])\n",
    "        penalty = trial.suggest_categorical(\n",
    "            \"penalty\", ['l2', 'l1', 'elasticnet'])\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 1e-10, 1, log=True)\n",
    "        max_iter = trial.suggest_int(\"max_iter\", 10, 5000)\n",
    "        learning_rate = trial.suggest_categorical(\n",
    "            \"learning_rate\", ['constant', 'optimal', 'invscaling', 'adaptive'])\n",
    "        eta0 = trial.suggest_float(\"eta0\", 1e-10, 3, log=True)\n",
    "        power_t = trial.suggest_float(\"power_t\", -1, 1)\n",
    "        random_state = trial.suggest_categorical(\"random_state\", [1337])\n",
    "        classifier_obj = SGDClassifier(\n",
    "            loss=loss, penalty=penalty, l1_ratio=l1_ratio,\n",
    "            max_iter=max_iter, learning_rate=learning_rate,\n",
    "            eta0=eta0, power_t=power_t, random_state=random_state\n",
    "        )\n",
    "    \n",
    "    classifier_obj.fit(trainX, trainY)\n",
    "    pred = classifier_obj.predict(validateX)\n",
    "    return accuracy_score(validateY, pred)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9786096256684492"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните полученный результат со случайным поиском."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-16 22:07:29,254]\u001b[0m A new study created in memory with name: no-name-e189834b-788f-48b4-ab58-40674744509d\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,263]\u001b[0m Trial 0 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 80, 'min_samples_split': 0.6282441771806322, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 0 with value: 0.9518716577540107.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,288]\u001b[0m Trial 1 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 159748.01710328073, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 0 with value: 0.9518716577540107.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,349]\u001b[0m Trial 2 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 37, 'weights': 'uniform', 'p': 1.5065391187633503}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,360]\u001b[0m Trial 3 finished with value: 0.9090909090909091 and parameters: {'classifier': 'SVC', 'C': 611958.1181978937, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': 6.451897947453844, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,372]\u001b[0m Trial 4 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 1.651715511787393e-10, 'kernel': 'linear', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,439]\u001b[0m Trial 5 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 23, 'weights': 'distance', 'p': 2.973592979124784}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:29,446]\u001b[0m Trial 6 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 109, 'min_samples_split': 0.2380357435517234, 'max_features': 'auto', 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,453]\u001b[0m Trial 7 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 125, 'min_samples_split': 0.40766327449175677, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,462]\u001b[0m Trial 8 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.4956521096604241, 'kernel': 'poly', 'degree': 1, 'gamma': 'auto', 'coef0': -37.449225781541784, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,528]\u001b[0m Trial 9 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 5, 'weights': 'uniform', 'p': 3.8947193427919484}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,535]\u001b[0m Trial 10 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'l1', 'l1_ratio': 2.974898312582649e-09, 'max_iter': 3378, 'learning_rate': 'invscaling', 'eta0': 5.6133525089496657e-08, 'power_t': 0.43831358512455454, 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,543]\u001b[0m Trial 11 finished with value: 0.9411764705882353 and parameters: {'classifier': 'SGD', 'loss': 'perceptron', 'penalty': 'l2', 'l1_ratio': 6.059134991598737e-05, 'max_iter': 4228, 'learning_rate': 'constant', 'eta0': 3.487825598920661e-05, 'power_t': 0.5660855833820373, 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,601]\u001b[0m Trial 12 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 34, 'weights': 'distance', 'p': 4.1270796107907755}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,659]\u001b[0m Trial 13 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 42, 'weights': 'distance', 'p': 3.86897209804128}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,665]\u001b[0m Trial 14 finished with value: 0.6684491978609626 and parameters: {'classifier': 'Gauss', 'smoothing': 0.0015626019672161555}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,725]\u001b[0m Trial 15 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 38, 'weights': 'uniform', 'p': 1.6283303555699922}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,731]\u001b[0m Trial 16 finished with value: 0.6310160427807486 and parameters: {'classifier': 'Gauss', 'smoothing': 0.00048206586584671664}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,739]\u001b[0m Trial 17 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 103, 'min_samples_split': 0.3140644141957021, 'max_features': 'log2', 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,806]\u001b[0m Trial 18 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 38, 'weights': 'uniform', 'p': 3.313659897363805}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,812]\u001b[0m Trial 19 finished with value: 0.7593582887700535 and parameters: {'classifier': 'Gauss', 'smoothing': 0.03907144030094952}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,825]\u001b[0m Trial 20 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'elasticnet', 'l1_ratio': 0.0030687501523029796, 'max_iter': 1165, 'learning_rate': 'optimal', 'eta0': 0.00177058278385344, 'power_t': 0.5441594641204095, 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,852]\u001b[0m Trial 21 finished with value: 0.39037433155080214 and parameters: {'classifier': 'SGD', 'loss': 'squared_epsilon_insensitive', 'penalty': 'l1', 'l1_ratio': 3.7864849857835375e-07, 'max_iter': 4619, 'learning_rate': 'optimal', 'eta0': 0.0005756526001521303, 'power_t': -0.4458589658891865, 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,859]\u001b[0m Trial 22 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 84, 'min_samples_split': 0.764435313680777, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,878]\u001b[0m Trial 23 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'l1', 'l1_ratio': 4.517109506540855e-08, 'max_iter': 2783, 'learning_rate': 'invscaling', 'eta0': 0.2301767850230986, 'power_t': 0.3207454826206666, 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:29,890]\u001b[0m Trial 24 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 20341.5406310776, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,896]\u001b[0m Trial 25 finished with value: 0.8983957219251337 and parameters: {'classifier': 'Gauss', 'smoothing': 0.3327607032907216}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,902]\u001b[0m Trial 26 finished with value: 0.5828877005347594 and parameters: {'classifier': 'Gauss', 'smoothing': 3.260487627597698e-05}. Best is trial 2 with value: 0.9679144385026738.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,960]\u001b[0m Trial 27 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'distance', 'p': 2.813727175872147}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,966]\u001b[0m Trial 28 finished with value: 0.8288770053475936 and parameters: {'classifier': 'Gauss', 'smoothing': 0.14877066833457156}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,972]\u001b[0m Trial 29 finished with value: 0.5614973262032086 and parameters: {'classifier': 'Gauss', 'smoothing': 4.2231408847630885e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,984]\u001b[0m Trial 30 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 116, 'min_samples_split': 0.9703757031833747, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:29,992]\u001b[0m Trial 31 finished with value: 0.5614973262032086 and parameters: {'classifier': 'Gauss', 'smoothing': 3.6290147622357978e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,002]\u001b[0m Trial 32 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 186, 'min_samples_split': 0.03944480259776248, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,107]\u001b[0m Trial 33 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 42, 'weights': 'distance', 'p': 2.3771238774035823}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,177]\u001b[0m Trial 34 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'distance', 'p': 1.0556397613960629}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:30,213]\u001b[0m Trial 35 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 26570769.658873785, 'kernel': 'linear', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,218]\u001b[0m Trial 36 finished with value: 0.7005347593582888 and parameters: {'classifier': 'Gauss', 'smoothing': 0.009232604059671983}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,242]\u001b[0m Trial 37 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SVC', 'C': 1.2613268462043183, 'kernel': 'poly', 'degree': 2, 'gamma': 'scale', 'coef0': 8.516627579374344, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,264]\u001b[0m Trial 38 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SVC', 'C': 48677.27388277436, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale', 'coef0': 34.35786456836689, 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,269]\u001b[0m Trial 39 finished with value: 0.5133689839572193 and parameters: {'classifier': 'Gauss', 'smoothing': 2.268798205614939e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,295]\u001b[0m Trial 40 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 5.648060419877959e-05, 'kernel': 'poly', 'degree': 3, 'gamma': 'scale', 'coef0': -42.301079528504545, 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,463]\u001b[0m Trial 41 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 31, 'weights': 'distance', 'p': 3.9682323698572692}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,485]\u001b[0m Trial 42 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.0012821321087325773, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:30,493]\u001b[0m Trial 43 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 107, 'min_samples_split': 0.24144233648626737, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,499]\u001b[0m Trial 44 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 89, 'min_samples_split': 0.4382885430600131, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,601]\u001b[0m Trial 45 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 2.388360392579712}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,618]\u001b[0m Trial 46 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.0017556082385513962, 'kernel': 'linear', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,711]\u001b[0m Trial 47 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 36, 'weights': 'distance', 'p': 2.227846691245579}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,721]\u001b[0m Trial 48 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.0012393573949646339, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,778]\u001b[0m Trial 49 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'squared_hinge', 'penalty': 'l1', 'l1_ratio': 3.2858716917858766e-09, 'max_iter': 3236, 'learning_rate': 'adaptive', 'eta0': 1.5644739201959446, 'power_t': -0.7293061321263152, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,792]\u001b[0m Trial 50 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 193, 'min_samples_split': 0.8757021931139415, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,813]\u001b[0m Trial 51 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'elasticnet', 'l1_ratio': 4.226531608052748e-06, 'max_iter': 1047, 'learning_rate': 'constant', 'eta0': 0.000127889774049356, 'power_t': 0.7486708216494089, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,819]\u001b[0m Trial 52 finished with value: 0.5989304812834224 and parameters: {'classifier': 'Gauss', 'smoothing': 0.00012392785060041413}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:30,825]\u001b[0m Trial 53 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 158, 'min_samples_split': 0.5751137533710063, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,919]\u001b[0m Trial 54 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 34, 'weights': 'distance', 'p': 2.444231246426705}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,929]\u001b[0m Trial 55 finished with value: 0.946524064171123 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 96, 'min_samples_split': 0.048322265457018676, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,948]\u001b[0m Trial 56 finished with value: 0.9732620320855615 and parameters: {'classifier': 'SGD', 'loss': 'squared_hinge', 'penalty': 'l1', 'l1_ratio': 4.91362264995046e-07, 'max_iter': 1288, 'learning_rate': 'adaptive', 'eta0': 0.00020935968140566618, 'power_t': -0.6276461960652635, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,969]\u001b[0m Trial 57 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 1704682.2273265359, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:30,982]\u001b[0m Trial 58 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 30, 'min_samples_split': 0.4389550257085649, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,010]\u001b[0m Trial 59 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 34969838.36036331, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,022]\u001b[0m Trial 60 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 58509.637082068526, 'kernel': 'sigmoid', 'gamma': 'auto', 'coef0': -21.662495518696733, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,030]\u001b[0m Trial 61 finished with value: 0.6042780748663101 and parameters: {'classifier': 'Gauss', 'smoothing': 0.00018464259348411138}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,167]\u001b[0m Trial 62 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'distance', 'p': 4.483131118762792}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,178]\u001b[0m Trial 63 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'elasticnet', 'l1_ratio': 0.00036543636892558937, 'max_iter': 3984, 'learning_rate': 'adaptive', 'eta0': 3.4569444429725167e-10, 'power_t': 0.19797599307755598, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,316]\u001b[0m Trial 64 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'distance', 'p': 3.708698357343332}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,326]\u001b[0m Trial 65 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 3.7691117214167805e-08, 'kernel': 'sigmoid', 'gamma': 'auto', 'coef0': 34.470637517517204, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,332]\u001b[0m Trial 66 finished with value: 0.48128342245989303 and parameters: {'classifier': 'Gauss', 'smoothing': 8.108150715385855e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,339]\u001b[0m Trial 67 finished with value: 0.37433155080213903 and parameters: {'classifier': 'Gauss', 'smoothing': 1.3825410759828825e-09}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,473]\u001b[0m Trial 68 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 49, 'weights': 'distance', 'p': 2.1709323358669983}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,502]\u001b[0m Trial 69 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'elasticnet', 'l1_ratio': 0.0030704794073376446, 'max_iter': 2358, 'learning_rate': 'constant', 'eta0': 0.004117700141993618, 'power_t': 0.687655506112711, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,511]\u001b[0m Trial 70 finished with value: 0.40106951871657753 and parameters: {'classifier': 'Gauss', 'smoothing': 6.922035961808233e-09}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,520]\u001b[0m Trial 71 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 80, 'min_samples_split': 0.9124968849418799, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:31,528]\u001b[0m Trial 72 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 133, 'min_samples_split': 0.947323924239216, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,543]\u001b[0m Trial 73 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'elasticnet', 'l1_ratio': 0.018075158006841164, 'max_iter': 4607, 'learning_rate': 'constant', 'eta0': 6.759046633028711e-05, 'power_t': 0.6513886011493415, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,563]\u001b[0m Trial 74 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 9218294065.184954, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': -41.92401216327926, 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,572]\u001b[0m Trial 75 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 48, 'min_samples_split': 0.6320892728288741, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,578]\u001b[0m Trial 76 finished with value: 0.679144385026738 and parameters: {'classifier': 'Gauss', 'smoothing': 0.002786547955329266}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:31,584]\u001b[0m Trial 77 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 116, 'min_samples_split': 0.8348950145745949, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,711]\u001b[0m Trial 78 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'distance', 'p': 1.1020027947097288}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,840]\u001b[0m Trial 79 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 38, 'weights': 'uniform', 'p': 4.942042540528952}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,850]\u001b[0m Trial 80 finished with value: 0.732620320855615 and parameters: {'classifier': 'Gauss', 'smoothing': 0.017241267469059254}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:31,871]\u001b[0m Trial 81 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 565.7468277227238, 'kernel': 'linear', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,879]\u001b[0m Trial 82 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'l2', 'l1_ratio': 0.28347984361613554, 'max_iter': 2301, 'learning_rate': 'adaptive', 'eta0': 1.249221487662849e-06, 'power_t': 0.2105868372880837, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,886]\u001b[0m Trial 83 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 122, 'min_samples_split': 0.10231152230881628, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,908]\u001b[0m Trial 84 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 8.021236598348903, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,918]\u001b[0m Trial 85 finished with value: 0.93048128342246 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'elasticnet', 'l1_ratio': 0.059000771752448396, 'max_iter': 2148, 'learning_rate': 'invscaling', 'eta0': 2.822362733607961, 'power_t': 0.8460385838661129, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,925]\u001b[0m Trial 86 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 128, 'min_samples_split': 0.8479994031141708, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:31,932]\u001b[0m Trial 87 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 38, 'min_samples_split': 0.4424643991400197, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,013]\u001b[0m Trial 88 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 49, 'weights': 'distance', 'p': 4.080530811026328}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:32,030]\u001b[0m Trial 89 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 101, 'min_samples_split': 0.4800630339110637, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,107]\u001b[0m Trial 90 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 22, 'weights': 'distance', 'p': 2.473670680528739}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,131]\u001b[0m Trial 91 finished with value: 0.9358288770053476 and parameters: {'classifier': 'SVC', 'C': 0.013649654231209845, 'kernel': 'poly', 'degree': 5, 'gamma': 'auto', 'coef0': -21.68007969280111, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:32,138]\u001b[0m Trial 92 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 9, 'min_samples_split': 0.7708202264153402, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:32,145]\u001b[0m Trial 93 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 130, 'min_samples_split': 0.7966777127403858, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,169]\u001b[0m Trial 94 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.07895683738717393, 'kernel': 'linear', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,232]\u001b[0m Trial 95 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'squared_hinge', 'penalty': 'l2', 'l1_ratio': 1.0367760840883471e-07, 'max_iter': 2376, 'learning_rate': 'constant', 'eta0': 1.3677867085253782e-06, 'power_t': 0.9531263274095421, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,393]\u001b[0m Trial 96 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 43, 'weights': 'distance', 'p': 4.060068481592632}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,403]\u001b[0m Trial 97 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 140, 'min_samples_split': 0.19313580326578758, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:32,506]\u001b[0m Trial 98 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 498500906.70498157, 'kernel': 'linear', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,523]\u001b[0m Trial 99 finished with value: 0.9625668449197861 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 138, 'min_samples_split': 0.033957363732357436, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,535]\u001b[0m Trial 100 finished with value: 0.6951871657754011 and parameters: {'classifier': 'Gauss', 'smoothing': 0.005341958034790335}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:32,551]\u001b[0m Trial 101 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'l2', 'l1_ratio': 0.00021293706682202698, 'max_iter': 3011, 'learning_rate': 'invscaling', 'eta0': 0.024390849768177642, 'power_t': -0.5876707230849207, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,643]\u001b[0m Trial 102 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'uniform', 'p': 1.9780409231331162}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,650]\u001b[0m Trial 103 finished with value: 0.8449197860962567 and parameters: {'classifier': 'Gauss', 'smoothing': 0.20312357731116185}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,661]\u001b[0m Trial 104 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 182.265658362614, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,667]\u001b[0m Trial 105 finished with value: 0.6951871657754011 and parameters: {'classifier': 'Gauss', 'smoothing': 0.00781045727261702}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,675]\u001b[0m Trial 106 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 104, 'min_samples_split': 0.2797018573469572, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,682]\u001b[0m Trial 107 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 145, 'min_samples_split': 0.2280849295232348, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:32,718]\u001b[0m Trial 108 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 25269.884642418696, 'kernel': 'linear', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,727]\u001b[0m Trial 109 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 7.307051191958378e-07, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,752]\u001b[0m Trial 110 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 19.806518628492537, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,759]\u001b[0m Trial 111 finished with value: 0.4385026737967914 and parameters: {'classifier': 'Gauss', 'smoothing': 4.2095167366807265e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,764]\u001b[0m Trial 112 finished with value: 0.5721925133689839 and parameters: {'classifier': 'Gauss', 'smoothing': 6.3305442520585205e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,770]\u001b[0m Trial 113 finished with value: 0.40106951871657753 and parameters: {'classifier': 'Gauss', 'smoothing': 1.120355385573677e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,778]\u001b[0m Trial 114 finished with value: 0.9197860962566845 and parameters: {'classifier': 'Gauss', 'smoothing': 0.5286255447033791}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,784]\u001b[0m Trial 115 finished with value: 0.7593582887700535 and parameters: {'classifier': 'Gauss', 'smoothing': 0.037756979572736264}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,796]\u001b[0m Trial 116 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'l1', 'l1_ratio': 1.0649750616098938e-07, 'max_iter': 1211, 'learning_rate': 'constant', 'eta0': 0.5911566201405212, 'power_t': 0.33782477609700257, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,805]\u001b[0m Trial 117 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'elasticnet', 'l1_ratio': 0.18107059464351513, 'max_iter': 1604, 'learning_rate': 'optimal', 'eta0': 0.00016177017050871052, 'power_t': -0.40490696090833556, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:32,828]\u001b[0m Trial 118 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 14342359.289452635, 'kernel': 'poly', 'degree': 1, 'gamma': 'auto', 'coef0': 11.389194462545163, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,838]\u001b[0m Trial 119 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'l2', 'l1_ratio': 5.4075109907849985e-06, 'max_iter': 3620, 'learning_rate': 'optimal', 'eta0': 1.200785031517781e-10, 'power_t': 0.4984099223865941, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,845]\u001b[0m Trial 120 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 149, 'min_samples_split': 0.4972307707607593, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:32,889]\u001b[0m Trial 121 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 4188011.609187529, 'kernel': 'linear', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:32,987]\u001b[0m Trial 122 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'distance', 'p': 2.3789395609736625}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,090]\u001b[0m Trial 123 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 17, 'weights': 'uniform', 'p': 2.379559415751261}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,111]\u001b[0m Trial 124 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'elasticnet', 'l1_ratio': 1.8281492305956361e-10, 'max_iter': 1940, 'learning_rate': 'adaptive', 'eta0': 0.10694269701626209, 'power_t': -0.5317758574594182, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,120]\u001b[0m Trial 125 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'elasticnet', 'l1_ratio': 3.2285105092799216e-05, 'max_iter': 2579, 'learning_rate': 'adaptive', 'eta0': 1.8448298745331147e-08, 'power_t': 0.9970899281596362, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:33,130]\u001b[0m Trial 126 finished with value: 0.8877005347593583 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'l1', 'l1_ratio': 1.602657853412653e-10, 'max_iter': 1351, 'learning_rate': 'invscaling', 'eta0': 5.617183212561794e-10, 'power_t': 0.8357527026601468, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,149]\u001b[0m Trial 127 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'elasticnet', 'l1_ratio': 3.715746975464461e-10, 'max_iter': 1376, 'learning_rate': 'adaptive', 'eta0': 0.035900692271042034, 'power_t': -0.06556048199236719, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,158]\u001b[0m Trial 128 finished with value: 0.6898395721925134 and parameters: {'classifier': 'Gauss', 'smoothing': 0.0031701070238347516}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,177]\u001b[0m Trial 129 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 11003.120213688757, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': 32.92661754156836, 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,185]\u001b[0m Trial 130 finished with value: 0.48663101604278075 and parameters: {'classifier': 'Gauss', 'smoothing': 9.19446550607602e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,197]\u001b[0m Trial 131 finished with value: 0.9625668449197861 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 174, 'min_samples_split': 0.033987544590254, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,206]\u001b[0m Trial 132 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 92, 'min_samples_split': 0.5370894454363366, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,214]\u001b[0m Trial 133 finished with value: 0.6737967914438503 and parameters: {'classifier': 'Gauss', 'smoothing': 0.0023326599674040487}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,230]\u001b[0m Trial 134 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 1.039025488669422e-09, 'kernel': 'linear', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:33,239]\u001b[0m Trial 135 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 34, 'min_samples_split': 0.6030467510723383, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,271]\u001b[0m Trial 136 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 3738.792553785382, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,338]\u001b[0m Trial 137 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 17, 'weights': 'uniform', 'p': 1.7032866106771176}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,346]\u001b[0m Trial 138 finished with value: 0.6951871657754011 and parameters: {'classifier': 'Gauss', 'smoothing': 0.006788760637089826}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,352]\u001b[0m Trial 139 finished with value: 0.6631016042780749 and parameters: {'classifier': 'Gauss', 'smoothing': 0.000960524845888569}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:33,368]\u001b[0m Trial 140 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 2.1389569776968173e-09, 'max_iter': 2576, 'learning_rate': 'optimal', 'eta0': 2.1725788489898923e-08, 'power_t': 0.8064102783679121, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,375]\u001b[0m Trial 141 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 170, 'min_samples_split': 0.8513335353005627, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,392]\u001b[0m Trial 142 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 1258.5326929623945, 'kernel': 'poly', 'degree': 3, 'gamma': 'scale', 'coef0': 46.42036537922549, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,403]\u001b[0m Trial 143 finished with value: 0.5882352941176471 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'elasticnet', 'l1_ratio': 0.001004201413210732, 'max_iter': 522, 'learning_rate': 'invscaling', 'eta0': 0.013386618895797989, 'power_t': -0.9635077905568314, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,412]\u001b[0m Trial 144 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 145, 'min_samples_split': 0.8811426199915577, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,417]\u001b[0m Trial 145 finished with value: 0.5721925133689839 and parameters: {'classifier': 'Gauss', 'smoothing': 6.497573259082267e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,555]\u001b[0m Trial 146 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 36, 'weights': 'uniform', 'p': 1.7763441596630742}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,721]\u001b[0m Trial 147 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 46, 'weights': 'uniform', 'p': 1.1031490782464353}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:33,733]\u001b[0m Trial 148 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 177, 'min_samples_split': 0.45892124475144414, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,852]\u001b[0m Trial 149 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'distance', 'p': 2.5529739489214758}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:33,953]\u001b[0m Trial 150 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'distance', 'p': 3.56937210526423}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,041]\u001b[0m Trial 151 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 48, 'weights': 'uniform', 'p': 4.221747675047631}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,062]\u001b[0m Trial 152 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'elasticnet', 'l1_ratio': 1.3529476903577506e-08, 'max_iter': 1614, 'learning_rate': 'invscaling', 'eta0': 0.002826209421843736, 'power_t': 0.696172684530328, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,136]\u001b[0m Trial 153 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 50, 'weights': 'uniform', 'p': 1.5595344513385871}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,144]\u001b[0m Trial 154 finished with value: 0.5828877005347594 and parameters: {'classifier': 'Gauss', 'smoothing': 2.352214680038742e-05}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,152]\u001b[0m Trial 155 finished with value: 0.5935828877005348 and parameters: {'classifier': 'Gauss', 'smoothing': 7.420992041186823e-05}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,219]\u001b[0m Trial 156 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 17, 'weights': 'distance', 'p': 3.789535386154295}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,321]\u001b[0m Trial 157 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 29, 'weights': 'uniform', 'p': 2.0776862856239795}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,331]\u001b[0m Trial 158 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 50, 'min_samples_split': 0.7329298087962879, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,343]\u001b[0m Trial 159 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'l1', 'l1_ratio': 1.7402588185760804e-06, 'max_iter': 1116, 'learning_rate': 'constant', 'eta0': 6.189617704348156e-10, 'power_t': 0.5065626303864919, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,464]\u001b[0m Trial 160 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 2.003955280181044}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,482]\u001b[0m Trial 161 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'squared_epsilon_insensitive', 'penalty': 'l1', 'l1_ratio': 6.85941505611368e-09, 'max_iter': 2086, 'learning_rate': 'invscaling', 'eta0': 1.5092361112567848e-05, 'power_t': -0.19752794134959073, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,489]\u001b[0m Trial 162 finished with value: 0.5133689839572193 and parameters: {'classifier': 'Gauss', 'smoothing': 2.656143983187711e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,651]\u001b[0m Trial 163 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 4.574158355494891}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,773]\u001b[0m Trial 164 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 17, 'weights': 'uniform', 'p': 3.338914516718203}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,837]\u001b[0m Trial 165 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 30, 'weights': 'uniform', 'p': 3.8378434282388785}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,897]\u001b[0m Trial 166 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 31, 'weights': 'uniform', 'p': 3.9599129635001957}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:34,908]\u001b[0m Trial 167 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 3.1622904627375253e-06, 'max_iter': 2223, 'learning_rate': 'optimal', 'eta0': 1.0113663362137173, 'power_t': 0.3149427672341183, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,914]\u001b[0m Trial 168 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 151, 'min_samples_split': 0.9974443500036028, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,983]\u001b[0m Trial 169 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 26, 'weights': 'distance', 'p': 2.615426094320999}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:34,992]\u001b[0m Trial 170 finished with value: 0.5080213903743316 and parameters: {'classifier': 'Gauss', 'smoothing': 2.0676880173335568e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,003]\u001b[0m Trial 171 finished with value: 0.7593582887700535 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'elasticnet', 'l1_ratio': 3.1632863448021034e-07, 'max_iter': 2674, 'learning_rate': 'invscaling', 'eta0': 2.7265630175861786e-08, 'power_t': 0.9688425885769456, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,009]\u001b[0m Trial 172 finished with value: 0.6577540106951871 and parameters: {'classifier': 'Gauss', 'smoothing': 0.0006855976803249377}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,017]\u001b[0m Trial 173 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'l2', 'l1_ratio': 7.944176707731e-07, 'max_iter': 951, 'learning_rate': 'constant', 'eta0': 0.11043255078384497, 'power_t': -0.8167958838231746, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,029]\u001b[0m Trial 174 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SVC', 'C': 0.12900909096588792, 'kernel': 'poly', 'degree': 3, 'gamma': 'auto', 'coef0': 13.772268223753116, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,057]\u001b[0m Trial 175 finished with value: 0.6844919786096256 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'l2', 'l1_ratio': 0.00018044353036155732, 'max_iter': 3378, 'learning_rate': 'optimal', 'eta0': 0.0007121662474360708, 'power_t': -0.30544443772067, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,065]\u001b[0m Trial 176 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 44, 'min_samples_split': 0.642621332483462, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,073]\u001b[0m Trial 177 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 137, 'min_samples_split': 0.8865498792718106, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,150]\u001b[0m Trial 178 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'distance', 'p': 3.796860154539056}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:35,160]\u001b[0m Trial 179 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 69, 'min_samples_split': 0.9079412162258539, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,169]\u001b[0m Trial 180 finished with value: 0.5454545454545454 and parameters: {'classifier': 'Gauss', 'smoothing': 2.4635133508035464e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:35,178]\u001b[0m Trial 181 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 100, 'min_samples_split': 0.5039089211803413, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,186]\u001b[0m Trial 182 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 15, 'min_samples_split': 0.5711635430536952, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,281]\u001b[0m Trial 183 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 24, 'weights': 'uniform', 'p': 4.228268636489957}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,303]\u001b[0m Trial 184 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'squared_epsilon_insensitive', 'penalty': 'l2', 'l1_ratio': 2.5323756285170707e-05, 'max_iter': 3761, 'learning_rate': 'invscaling', 'eta0': 0.003318845018068796, 'power_t': 0.6105903050769295, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,332]\u001b[0m Trial 185 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'elasticnet', 'l1_ratio': 4.249288991522066e-08, 'max_iter': 225, 'learning_rate': 'adaptive', 'eta0': 0.1555908203402104, 'power_t': 0.5416697866502518, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,340]\u001b[0m Trial 186 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 107, 'min_samples_split': 0.47792079526221504, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,346]\u001b[0m Trial 187 finished with value: 0.6951871657754011 and parameters: {'classifier': 'Gauss', 'smoothing': 0.00508925016575754}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,429]\u001b[0m Trial 188 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 18, 'weights': 'uniform', 'p': 3.185871192063029}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,457]\u001b[0m Trial 189 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 5683561.672241717, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,470]\u001b[0m Trial 190 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'perceptron', 'penalty': 'l1', 'l1_ratio': 3.88641652561158e-09, 'max_iter': 861, 'learning_rate': 'optimal', 'eta0': 0.0002675420360520923, 'power_t': 0.7520904067729988, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:35,479]\u001b[0m Trial 191 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 122, 'min_samples_split': 0.7805819814268006, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,621]\u001b[0m Trial 192 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 44, 'weights': 'uniform', 'p': 2.3295453190766464}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,700]\u001b[0m Trial 193 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'squared_epsilon_insensitive', 'penalty': 'l1', 'l1_ratio': 0.0010611411894544686, 'max_iter': 390, 'learning_rate': 'adaptive', 'eta0': 1.7103703052896867e-06, 'power_t': 0.8910764448033293, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,709]\u001b[0m Trial 194 finished with value: 0.3850267379679144 and parameters: {'classifier': 'Gauss', 'smoothing': 3.1066723779350394e-09}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,719]\u001b[0m Trial 195 finished with value: 0.5347593582887701 and parameters: {'classifier': 'Gauss', 'smoothing': 6.31492665936832e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,845]\u001b[0m Trial 196 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 47, 'weights': 'uniform', 'p': 4.161219953736561}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,855]\u001b[0m Trial 197 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 86, 'min_samples_split': 0.7013319875422023, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,925]\u001b[0m Trial 198 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 14, 'weights': 'distance', 'p': 4.508253446783874}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:35,948]\u001b[0m Trial 199 finished with value: 0.6256684491978609 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'l1', 'l1_ratio': 7.291178247739261e-05, 'max_iter': 331, 'learning_rate': 'optimal', 'eta0': 1.0784096561021183e-08, 'power_t': 0.5346650318751982, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,016]\u001b[0m Trial 200 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 27, 'weights': 'uniform', 'p': 2.292381123682874}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,034]\u001b[0m Trial 201 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'l1', 'l1_ratio': 7.3581171798630805e-06, 'max_iter': 3120, 'learning_rate': 'constant', 'eta0': 0.00023757111531362275, 'power_t': 0.39642083726892063, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,055]\u001b[0m Trial 202 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 674.4181183957671, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,076]\u001b[0m Trial 203 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 5.627585081888982, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:36,084]\u001b[0m Trial 204 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 165, 'min_samples_split': 0.28524075539696797, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,089]\u001b[0m Trial 205 finished with value: 0.7540106951871658 and parameters: {'classifier': 'Gauss', 'smoothing': 0.035261035642664196}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,096]\u001b[0m Trial 206 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 4.460370922637439e-08, 'kernel': 'linear', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,159]\u001b[0m Trial 207 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 38, 'weights': 'distance', 'p': 4.887932815660044}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,170]\u001b[0m Trial 208 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'perceptron', 'penalty': 'l2', 'l1_ratio': 0.009837295280950608, 'max_iter': 1598, 'learning_rate': 'optimal', 'eta0': 3.811583671360429e-06, 'power_t': 0.7736068321473453, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,230]\u001b[0m Trial 209 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 37, 'weights': 'uniform', 'p': 3.390315982828851}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,237]\u001b[0m Trial 210 finished with value: 0.45989304812834225 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'l2', 'l1_ratio': 4.920017236360897e-05, 'max_iter': 271, 'learning_rate': 'invscaling', 'eta0': 1.9313421167352762, 'power_t': -0.7520489883991544, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:36,244]\u001b[0m Trial 211 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 190, 'min_samples_split': 0.5536548832440529, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,250]\u001b[0m Trial 212 finished with value: 0.4385026737967914 and parameters: {'classifier': 'Gauss', 'smoothing': 4.4648465288478534e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,256]\u001b[0m Trial 213 finished with value: 0.6898395721925134 and parameters: {'classifier': 'Gauss', 'smoothing': 0.0031812555748539323}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,286]\u001b[0m Trial 214 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SVC', 'C': 0.5153311458790639, 'kernel': 'linear', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,293]\u001b[0m Trial 215 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 0.7380633755180089, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,303]\u001b[0m Trial 216 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 7.911645525833205e-07, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,376]\u001b[0m Trial 217 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 24, 'weights': 'uniform', 'p': 4.741997327116394}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,441]\u001b[0m Trial 218 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 35, 'weights': 'distance', 'p': 3.1416104979933754}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:36,448]\u001b[0m Trial 219 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 172, 'min_samples_split': 0.2793080061139852, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,503]\u001b[0m Trial 220 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 50, 'weights': 'distance', 'p': 1.22323944540579}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,512]\u001b[0m Trial 221 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 97, 'min_samples_split': 0.04565490616342328, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,519]\u001b[0m Trial 222 finished with value: 0.7914438502673797 and parameters: {'classifier': 'Gauss', 'smoothing': 0.08770755965112859}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,526]\u001b[0m Trial 223 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 123, 'min_samples_split': 0.18793117119465816, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:36,533]\u001b[0m Trial 224 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 55, 'min_samples_split': 0.6703684096056447, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:36,540]\u001b[0m Trial 225 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 177, 'min_samples_split': 0.6264992305181782, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,550]\u001b[0m Trial 226 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'l1', 'l1_ratio': 8.67467826981902e-09, 'max_iter': 409, 'learning_rate': 'invscaling', 'eta0': 0.0006506012555482027, 'power_t': 0.040174589327066856, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,555]\u001b[0m Trial 227 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 8, 'min_samples_split': 0.46297352874296255, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,632]\u001b[0m Trial 228 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'distance', 'p': 2.015566053102691}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,697]\u001b[0m Trial 229 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 22, 'weights': 'distance', 'p': 3.6629125689546744}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:36,712]\u001b[0m Trial 230 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 205.53551357100545, 'kernel': 'linear', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,724]\u001b[0m Trial 231 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'squared_hinge', 'penalty': 'elasticnet', 'l1_ratio': 4.917048148225956e-10, 'max_iter': 3199, 'learning_rate': 'optimal', 'eta0': 5.009425597791268e-06, 'power_t': -0.024595574244266283, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:36,730]\u001b[0m Trial 232 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 37, 'min_samples_split': 0.8314257692218515, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,738]\u001b[0m Trial 233 finished with value: 0.946524064171123 and parameters: {'classifier': 'SGD', 'loss': 'squared_hinge', 'penalty': 'l2', 'l1_ratio': 0.0034012846098316714, 'max_iter': 2897, 'learning_rate': 'invscaling', 'eta0': 1.830354392235188e-09, 'power_t': 0.34233453000019254, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,747]\u001b[0m Trial 234 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 376840.3748676211, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,755]\u001b[0m Trial 235 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'perceptron', 'penalty': 'l2', 'l1_ratio': 3.365217504835814e-07, 'max_iter': 2116, 'learning_rate': 'invscaling', 'eta0': 0.003938252923345346, 'power_t': -0.8489789876791214, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,767]\u001b[0m Trial 236 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'l1', 'l1_ratio': 1.229827622592561e-09, 'max_iter': 3704, 'learning_rate': 'optimal', 'eta0': 1.963080541973485e-06, 'power_t': 0.8891083855986948, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,774]\u001b[0m Trial 237 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 10, 'min_samples_split': 0.6790097591212901, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,782]\u001b[0m Trial 238 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'log_loss', 'penalty': 'l2', 'l1_ratio': 0.004720587566463403, 'max_iter': 1979, 'learning_rate': 'adaptive', 'eta0': 1.91384265388949e-09, 'power_t': -0.7677977234484517, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,788]\u001b[0m Trial 239 finished with value: 0.49732620320855614 and parameters: {'classifier': 'Gauss', 'smoothing': 1.8236361456780603e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,795]\u001b[0m Trial 240 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 107, 'min_samples_split': 0.22763376885313205, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,800]\u001b[0m Trial 241 finished with value: 0.40641711229946526 and parameters: {'classifier': 'Gauss', 'smoothing': 1.3425938059744194e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,807]\u001b[0m Trial 242 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 75, 'min_samples_split': 0.9091109055100037, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,873]\u001b[0m Trial 243 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 19, 'weights': 'uniform', 'p': 1.8109685135143705}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,879]\u001b[0m Trial 244 finished with value: 0.5721925133689839 and parameters: {'classifier': 'Gauss', 'smoothing': 5.946223474244112e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,891]\u001b[0m Trial 245 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 2.2423405368062343e-07, 'kernel': 'sigmoid', 'gamma': 'auto', 'coef0': 46.19485567056127, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,898]\u001b[0m Trial 246 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 0.6324838880479667, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,965]\u001b[0m Trial 247 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 48, 'weights': 'uniform', 'p': 2.6094771362787363}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,975]\u001b[0m Trial 248 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 1.5165288705734958e-10, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:36,984]\u001b[0m Trial 249 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 9.423090739306955e-05, 'kernel': 'poly', 'degree': 1, 'gamma': 'auto', 'coef0': -4.708646242853142, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,052]\u001b[0m Trial 250 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 45, 'weights': 'distance', 'p': 1.355740343956957}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,060]\u001b[0m Trial 251 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 187, 'min_samples_split': 0.6213877379051476, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,070]\u001b[0m Trial 252 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 193, 'min_samples_split': 0.33343431970748805, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:37,081]\u001b[0m Trial 253 finished with value: 0.9625668449197861 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 155, 'min_samples_split': 0.02573177406460143, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,101]\u001b[0m Trial 254 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'elasticnet', 'l1_ratio': 0.16156856482331708, 'max_iter': 2977, 'learning_rate': 'constant', 'eta0': 8.53276680673166e-05, 'power_t': 0.5842316832928396, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,183]\u001b[0m Trial 255 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 29, 'weights': 'distance', 'p': 2.219846834816156}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,276]\u001b[0m Trial 256 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 19, 'weights': 'uniform', 'p': 4.9460506495563195}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,285]\u001b[0m Trial 257 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 3.7400056873379477e-06, 'kernel': 'poly', 'degree': 4, 'gamma': 'auto', 'coef0': 4.505699325758826, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:37,291]\u001b[0m Trial 258 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 129, 'min_samples_split': 0.8694401779792713, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:37,301]\u001b[0m Trial 259 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'l2', 'l1_ratio': 0.00010075846782389158, 'max_iter': 2219, 'learning_rate': 'optimal', 'eta0': 0.00017478480084755186, 'power_t': 0.7707417510500234, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,312]\u001b[0m Trial 260 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'l1', 'l1_ratio': 0.00097360712453117, 'max_iter': 3258, 'learning_rate': 'invscaling', 'eta0': 0.0010928563782820623, 'power_t': 0.04510760424041593, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,318]\u001b[0m Trial 261 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 188, 'min_samples_split': 0.8688354663271525, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,326]\u001b[0m Trial 262 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 90, 'min_samples_split': 0.5287680401387524, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,335]\u001b[0m Trial 263 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'l1', 'l1_ratio': 2.0476103535936557e-05, 'max_iter': 2139, 'learning_rate': 'constant', 'eta0': 5.892674644328784e-09, 'power_t': 0.2866811181941382, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,414]\u001b[0m Trial 264 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'distance', 'p': 2.7734590126042686}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,425]\u001b[0m Trial 265 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'l1', 'l1_ratio': 9.818400750764065e-07, 'max_iter': 35, 'learning_rate': 'constant', 'eta0': 1.5534562847719149, 'power_t': 0.8490248022173528, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:37,464]\u001b[0m Trial 266 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 125848.48260389264, 'kernel': 'linear', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,478]\u001b[0m Trial 267 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'log_loss', 'penalty': 'l1', 'l1_ratio': 0.9349827988239133, 'max_iter': 4377, 'learning_rate': 'optimal', 'eta0': 3.527228480779609e-07, 'power_t': 0.7828309419895789, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,486]\u001b[0m Trial 268 finished with value: 0.946524064171123 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'l2', 'l1_ratio': 4.976359736436366e-09, 'max_iter': 2282, 'learning_rate': 'invscaling', 'eta0': 5.616793786419915e-06, 'power_t': 0.32895560707645344, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,493]\u001b[0m Trial 269 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 23, 'min_samples_split': 0.8763566986961072, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,551]\u001b[0m Trial 270 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 23, 'weights': 'uniform', 'p': 2.0074687406881395}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,560]\u001b[0m Trial 271 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 8.37541008738693e-08, 'kernel': 'poly', 'degree': 1, 'gamma': 'scale', 'coef0': -10.883432673761249, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,569]\u001b[0m Trial 272 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.0008895973799016443, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,580]\u001b[0m Trial 273 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'l1', 'l1_ratio': 0.035514389285952574, 'max_iter': 911, 'learning_rate': 'invscaling', 'eta0': 0.00010622667968166968, 'power_t': -0.22239145693699935, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,588]\u001b[0m Trial 274 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 9.965802396058726e-09, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,598]\u001b[0m Trial 275 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'squared_hinge', 'penalty': 'l2', 'l1_ratio': 0.03417118982557623, 'max_iter': 2111, 'learning_rate': 'optimal', 'eta0': 1.8862212524369145e-08, 'power_t': -0.0929268817215354, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,603]\u001b[0m Trial 276 finished with value: 0.7379679144385026 and parameters: {'classifier': 'Gauss', 'smoothing': 0.019897557974140386}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,614]\u001b[0m Trial 277 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 45632.616618000255, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,622]\u001b[0m Trial 278 finished with value: 0.9090909090909091 and parameters: {'classifier': 'SVC', 'C': 3219000.018338321, 'kernel': 'poly', 'degree': 4, 'gamma': 'scale', 'coef0': -9.653456245253992, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,645]\u001b[0m Trial 279 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SVC', 'C': 20518.786933918916, 'kernel': 'poly', 'degree': 4, 'gamma': 'auto', 'coef0': 33.606275643125855, 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,710]\u001b[0m Trial 280 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'distance', 'p': 1.4785354865158595}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,717]\u001b[0m Trial 281 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 11, 'min_samples_split': 0.6562926455732032, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:37,736]\u001b[0m Trial 282 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 92.94343311500351, 'kernel': 'linear', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,775]\u001b[0m Trial 283 finished with value: 0.6310160427807486 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'elasticnet', 'l1_ratio': 0.0004210216681531461, 'max_iter': 4423, 'learning_rate': 'optimal', 'eta0': 2.6942990832959533e-08, 'power_t': 0.006707363020144408, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,793]\u001b[0m Trial 284 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'squared_epsilon_insensitive', 'penalty': 'l2', 'l1_ratio': 0.001299369332494679, 'max_iter': 703, 'learning_rate': 'constant', 'eta0': 1.0416720753462613e-05, 'power_t': 0.6336929770380835, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,800]\u001b[0m Trial 285 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 197, 'min_samples_split': 0.8972575138963602, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,864]\u001b[0m Trial 286 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 46, 'weights': 'distance', 'p': 3.9839314700705653}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,878]\u001b[0m Trial 287 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 5.0433316424274456e-08, 'kernel': 'linear', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,884]\u001b[0m Trial 288 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 169, 'min_samples_split': 0.7716106460512218, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,891]\u001b[0m Trial 289 finished with value: 0.3850267379679144 and parameters: {'classifier': 'Gauss', 'smoothing': 2.363929132327136e-09}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,897]\u001b[0m Trial 290 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'l2', 'l1_ratio': 4.344203942973043e-09, 'max_iter': 2934, 'learning_rate': 'constant', 'eta0': 2.1038004872168337, 'power_t': -0.5831753483130862, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,902]\u001b[0m Trial 291 finished with value: 0.40106951871657753 and parameters: {'classifier': 'Gauss', 'smoothing': 1.1346222543521608e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,915]\u001b[0m Trial 292 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 3.433028704466288e-05, 'kernel': 'linear', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:37,988]\u001b[0m Trial 293 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 16, 'weights': 'distance', 'p': 2.2563835088064246}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,058]\u001b[0m Trial 294 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 14, 'weights': 'uniform', 'p': 1.7172882824445628}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,067]\u001b[0m Trial 295 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'elasticnet', 'l1_ratio': 0.6099010640152276, 'max_iter': 3053, 'learning_rate': 'constant', 'eta0': 2.335724318472885e-07, 'power_t': 0.26895474192819435, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,076]\u001b[0m Trial 296 finished with value: 0.5133689839572193 and parameters: {'classifier': 'Gauss', 'smoothing': 2.96182288242497e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,085]\u001b[0m Trial 297 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 174, 'min_samples_split': 0.031523231160533016, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,109]\u001b[0m Trial 298 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'log_loss', 'penalty': 'elasticnet', 'l1_ratio': 4.3822117688836375e-07, 'max_iter': 2456, 'learning_rate': 'optimal', 'eta0': 0.0023539122654268286, 'power_t': 0.42642603240090304, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,120]\u001b[0m Trial 299 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'l1', 'l1_ratio': 0.014224727465896203, 'max_iter': 150, 'learning_rate': 'constant', 'eta0': 5.2047897941274343e-08, 'power_t': -0.8153569330209183, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,126]\u001b[0m Trial 300 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 169, 'min_samples_split': 0.9624445347107008, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,134]\u001b[0m Trial 301 finished with value: 0.9090909090909091 and parameters: {'classifier': 'SVC', 'C': 61.55746404963643, 'kernel': 'poly', 'degree': 2, 'gamma': 'scale', 'coef0': -44.414240056387065, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,140]\u001b[0m Trial 302 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 177, 'min_samples_split': 0.33882785655244196, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,197]\u001b[0m Trial 303 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 14, 'weights': 'distance', 'p': 2.0261153559358878}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,203]\u001b[0m Trial 304 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 124, 'min_samples_split': 0.9538027234200994, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,212]\u001b[0m Trial 305 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 18, 'min_samples_split': 0.5489625891800795, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,270]\u001b[0m Trial 306 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 34, 'weights': 'uniform', 'p': 1.4476155851537817}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,277]\u001b[0m Trial 307 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 22, 'min_samples_split': 0.4113266620908271, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,298]\u001b[0m Trial 308 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'squared_epsilon_insensitive', 'penalty': 'l2', 'l1_ratio': 4.7187754691379215e-09, 'max_iter': 1620, 'learning_rate': 'adaptive', 'eta0': 8.151252180445419e-06, 'power_t': 0.37994730236137486, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,305]\u001b[0m Trial 309 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 57, 'min_samples_split': 0.6418348569085258, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,312]\u001b[0m Trial 310 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'squared_hinge', 'penalty': 'l2', 'l1_ratio': 1.606570265371061e-10, 'max_iter': 227, 'learning_rate': 'constant', 'eta0': 0.02061802328890601, 'power_t': 0.3064610217312105, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,319]\u001b[0m Trial 311 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 147, 'min_samples_split': 0.6801282381719626, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,327]\u001b[0m Trial 312 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'l1', 'l1_ratio': 0.050029603097721365, 'max_iter': 4203, 'learning_rate': 'constant', 'eta0': 3.351334122678139e-07, 'power_t': -0.5370126263869466, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,338]\u001b[0m Trial 313 finished with value: 0.946524064171123 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'l2', 'l1_ratio': 0.0004927353609276977, 'max_iter': 4408, 'learning_rate': 'invscaling', 'eta0': 0.0004997760713498286, 'power_t': 0.5790083756724771, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,356]\u001b[0m Trial 314 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 254536.176173905, 'kernel': 'linear', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,365]\u001b[0m Trial 315 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'l1', 'l1_ratio': 1.1246770366230077e-07, 'max_iter': 4166, 'learning_rate': 'adaptive', 'eta0': 4.45704733782912e-07, 'power_t': -0.4119346217955888, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,435]\u001b[0m Trial 316 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 44, 'weights': 'uniform', 'p': 1.1978481132090146}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,444]\u001b[0m Trial 317 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'l1', 'l1_ratio': 2.469265597497622e-07, 'max_iter': 3609, 'learning_rate': 'constant', 'eta0': 3.816211766768759e-08, 'power_t': 0.4492308938538079, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,451]\u001b[0m Trial 318 finished with value: 0.7540106951871658 and parameters: {'classifier': 'Gauss', 'smoothing': 0.037402159838889414}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,457]\u001b[0m Trial 319 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 18, 'min_samples_split': 0.8503425389683424, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,466]\u001b[0m Trial 320 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'l2', 'l1_ratio': 0.0005347181471447232, 'max_iter': 4560, 'learning_rate': 'constant', 'eta0': 8.443166246071967e-09, 'power_t': -0.8077530158161939, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,473]\u001b[0m Trial 321 finished with value: 0.9625668449197861 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 13, 'min_samples_split': 0.03201803695178331, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,482]\u001b[0m Trial 322 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 136, 'min_samples_split': 0.5037238603716577, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,488]\u001b[0m Trial 323 finished with value: 0.5828877005347594 and parameters: {'classifier': 'Gauss', 'smoothing': 3.083366882596003e-05}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,546]\u001b[0m Trial 324 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 8, 'weights': 'uniform', 'p': 2.1314470603118014}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,555]\u001b[0m Trial 325 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'elasticnet', 'l1_ratio': 2.965934437992787e-07, 'max_iter': 4098, 'learning_rate': 'constant', 'eta0': 1.892989748254236e-10, 'power_t': -0.3750343034542267, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,564]\u001b[0m Trial 326 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 0.0005381916076663484, 'max_iter': 725, 'learning_rate': 'invscaling', 'eta0': 6.3896048235238216e-09, 'power_t': -0.3564913331293884, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,570]\u001b[0m Trial 327 finished with value: 0.5401069518716578 and parameters: {'classifier': 'Gauss', 'smoothing': 7.461271937600661e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,579]\u001b[0m Trial 328 finished with value: 0.946524064171123 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 0.0006284680772344871, 'max_iter': 1108, 'learning_rate': 'invscaling', 'eta0': 1.0890429854622571e-10, 'power_t': 0.32745911121152016, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,584]\u001b[0m Trial 329 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 172, 'min_samples_split': 0.6282510533679839, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,598]\u001b[0m Trial 330 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 1.5309466294882667e-10, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,607]\u001b[0m Trial 331 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.0006619757752459792, 'kernel': 'poly', 'degree': 3, 'gamma': 'scale', 'coef0': -22.64590981600452, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,612]\u001b[0m Trial 332 finished with value: 0.7165775401069518 and parameters: {'classifier': 'Gauss', 'smoothing': 0.011143855842013784}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,626]\u001b[0m Trial 333 finished with value: 0.7433155080213903 and parameters: {'classifier': 'SGD', 'loss': 'squared_epsilon_insensitive', 'penalty': 'l2', 'l1_ratio': 3.218668598905091e-08, 'max_iter': 4683, 'learning_rate': 'optimal', 'eta0': 5.351671468991346e-09, 'power_t': 0.45300237454237546, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,638]\u001b[0m Trial 334 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 2.2378363144785656e-10, 'max_iter': 3638, 'learning_rate': 'optimal', 'eta0': 0.003788881767681123, 'power_t': -0.16795580092052065, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,645]\u001b[0m Trial 335 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 106, 'min_samples_split': 0.31586075767208627, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,651]\u001b[0m Trial 336 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 121, 'min_samples_split': 0.3715194907741785, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,658]\u001b[0m Trial 337 finished with value: 0.8235294117647058 and parameters: {'classifier': 'Gauss', 'smoothing': 0.13819523250316043}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,665]\u001b[0m Trial 338 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 125, 'min_samples_split': 0.35547163245586827, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,672]\u001b[0m Trial 339 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 10, 'min_samples_split': 0.7558267053578434, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,749]\u001b[0m Trial 340 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 30, 'weights': 'uniform', 'p': 4.250249183457384}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,757]\u001b[0m Trial 341 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 75, 'min_samples_split': 0.2946829606578021, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,763]\u001b[0m Trial 342 finished with value: 0.8342245989304813 and parameters: {'classifier': 'Gauss', 'smoothing': 0.1651206719689114}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,769]\u001b[0m Trial 343 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 161, 'min_samples_split': 0.28501548824419065, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:38,776]\u001b[0m Trial 344 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 19, 'min_samples_split': 0.456767838063018, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,785]\u001b[0m Trial 345 finished with value: 0.5882352941176471 and parameters: {'classifier': 'Gauss', 'smoothing': 5.6886623116697594e-05}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,797]\u001b[0m Trial 346 finished with value: 0.946524064171123 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'elasticnet', 'l1_ratio': 0.2555160552379293, 'max_iter': 2147, 'learning_rate': 'invscaling', 'eta0': 1.7764266311304397e-06, 'power_t': 0.4241789301339036, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,805]\u001b[0m Trial 347 finished with value: 0.5401069518716578 and parameters: {'classifier': 'Gauss', 'smoothing': 6.958976146217177e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,811]\u001b[0m Trial 348 finished with value: 0.8235294117647058 and parameters: {'classifier': 'Gauss', 'smoothing': 0.14459425885595426}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,875]\u001b[0m Trial 349 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'distance', 'p': 4.855708991882304}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,957]\u001b[0m Trial 350 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 19, 'weights': 'uniform', 'p': 4.920119905651841}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,963]\u001b[0m Trial 351 finished with value: 0.5614973262032086 and parameters: {'classifier': 'Gauss', 'smoothing': 4.463368997361213e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,968]\u001b[0m Trial 352 finished with value: 0.5828877005347594 and parameters: {'classifier': 'Gauss', 'smoothing': 1.900630337716717e-05}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,976]\u001b[0m Trial 353 finished with value: 0.9411764705882353 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'l2', 'l1_ratio': 2.0969095159337133e-10, 'max_iter': 475, 'learning_rate': 'invscaling', 'eta0': 1.1453285593638763e-07, 'power_t': 0.5715522641087956, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,982]\u001b[0m Trial 354 finished with value: 0.6470588235294118 and parameters: {'classifier': 'Gauss', 'smoothing': 0.0006016117141942495}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,987]\u001b[0m Trial 355 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 89, 'min_samples_split': 0.7155823048452395, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:38,992]\u001b[0m Trial 356 finished with value: 0.5721925133689839 and parameters: {'classifier': 'Gauss', 'smoothing': 5.450259518532703e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,016]\u001b[0m Trial 357 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'elasticnet', 'l1_ratio': 3.181777203615143e-05, 'max_iter': 2305, 'learning_rate': 'invscaling', 'eta0': 3.6634506171957425e-05, 'power_t': 0.023963459988014968, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,022]\u001b[0m Trial 358 finished with value: 0.5614973262032086 and parameters: {'classifier': 'Gauss', 'smoothing': 2.897349840335148e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,029]\u001b[0m Trial 359 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 18112594.25520241, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,034]\u001b[0m Trial 360 finished with value: 0.49732620320855614 and parameters: {'classifier': 'Gauss', 'smoothing': 1.6325021834747995e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,050]\u001b[0m Trial 361 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'l1', 'l1_ratio': 1.6715968065598964e-07, 'max_iter': 3604, 'learning_rate': 'optimal', 'eta0': 2.7296098770910935e-06, 'power_t': -0.012424710210372947, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,080]\u001b[0m Trial 362 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 14.961964950757194, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,086]\u001b[0m Trial 363 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 53, 'min_samples_split': 0.3680835906277392, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,111]\u001b[0m Trial 364 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 5.387323924968802, 'kernel': 'sigmoid', 'gamma': 'auto', 'coef0': -10.055297106984199, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,120]\u001b[0m Trial 365 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 196, 'min_samples_split': 0.3087349043429501, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,130]\u001b[0m Trial 366 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 1.1257714552460117e-07, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': 30.09669017757635, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,148]\u001b[0m Trial 367 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 5.565878017060859e-10, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': 6.012843685000938, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,155]\u001b[0m Trial 368 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'l1', 'l1_ratio': 1.0827648673004221e-08, 'max_iter': 3468, 'learning_rate': 'adaptive', 'eta0': 5.5182264078078295e-08, 'power_t': 0.585877080105955, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,161]\u001b[0m Trial 369 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 60, 'min_samples_split': 0.8954035795618146, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,232]\u001b[0m Trial 370 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 16, 'weights': 'distance', 'p': 1.932598020145063}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,238]\u001b[0m Trial 371 finished with value: 0.5614973262032086 and parameters: {'classifier': 'Gauss', 'smoothing': 4.816513262762997e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,252]\u001b[0m Trial 372 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'modified_huber', 'penalty': 'l1', 'l1_ratio': 4.119802820559903e-09, 'max_iter': 4271, 'learning_rate': 'optimal', 'eta0': 2.333885110805867e-09, 'power_t': 0.13845667938731965, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,258]\u001b[0m Trial 373 finished with value: 0.679144385026738 and parameters: {'classifier': 'Gauss', 'smoothing': 0.0026235889877881296}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,263]\u001b[0m Trial 374 finished with value: 0.37433155080213903 and parameters: {'classifier': 'Gauss', 'smoothing': 1.427269253350456e-09}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,272]\u001b[0m Trial 375 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.20941953652285455, 'kernel': 'poly', 'degree': 1, 'gamma': 'scale', 'coef0': -34.33339479408075, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,279]\u001b[0m Trial 376 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 1.8802323598442444e-09, 'kernel': 'linear', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,287]\u001b[0m Trial 377 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 23, 'min_samples_split': 0.44459634687680155, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:39,362]\u001b[0m Trial 378 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 6513304.333033566, 'kernel': 'poly', 'degree': 1, 'gamma': 'auto', 'coef0': 14.294809372186194, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,448]\u001b[0m Trial 379 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 43, 'weights': 'uniform', 'p': 3.2890273535442316}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,453]\u001b[0m Trial 380 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 60, 'min_samples_split': 0.8651665658148671, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,461]\u001b[0m Trial 381 finished with value: 0.5775401069518716 and parameters: {'classifier': 'Gauss', 'smoothing': 8.719201099096916e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,548]\u001b[0m Trial 382 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 4.295888374242899}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,733]\u001b[0m Trial 383 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'distance', 'p': 1.674077982532181}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,758]\u001b[0m Trial 384 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'l1', 'l1_ratio': 1.1396887593197045e-05, 'max_iter': 330, 'learning_rate': 'constant', 'eta0': 7.986803329271487e-05, 'power_t': 0.04314783589531079, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,811]\u001b[0m Trial 385 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'log_loss', 'penalty': 'l1', 'l1_ratio': 1.4808178570553048e-10, 'max_iter': 771, 'learning_rate': 'adaptive', 'eta0': 8.358076437626105e-05, 'power_t': 0.4311070601754541, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,829]\u001b[0m Trial 386 finished with value: 0.9732620320855615 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'l1', 'l1_ratio': 0.0004009921178635668, 'max_iter': 1270, 'learning_rate': 'adaptive', 'eta0': 0.0015194366260548374, 'power_t': 0.5095626992972624, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:39,930]\u001b[0m Trial 387 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 25, 'weights': 'distance', 'p': 3.184912869993789}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,017]\u001b[0m Trial 388 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 32, 'weights': 'uniform', 'p': 2.162130176145938}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,029]\u001b[0m Trial 389 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 8.05462256312016e-06, 'kernel': 'sigmoid', 'gamma': 'auto', 'coef0': 47.8787684398479, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,037]\u001b[0m Trial 390 finished with value: 0.9411764705882353 and parameters: {'classifier': 'SGD', 'loss': 'perceptron', 'penalty': 'l2', 'l1_ratio': 1.3296691856974334e-09, 'max_iter': 1138, 'learning_rate': 'constant', 'eta0': 0.0003073404514499363, 'power_t': 0.6777530211419573, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,047]\u001b[0m Trial 391 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 295164524.9957747, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': -20.799638508658713, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,054]\u001b[0m Trial 392 finished with value: 0.47593582887700536 and parameters: {'classifier': 'Gauss', 'smoothing': 7.392580184446316e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,149]\u001b[0m Trial 393 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 23, 'weights': 'distance', 'p': 3.0685491189274714}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,272]\u001b[0m Trial 394 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 42, 'weights': 'uniform', 'p': 3.7441856805511264}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,389]\u001b[0m Trial 395 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 39, 'weights': 'uniform', 'p': 1.5506378088205341}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,398]\u001b[0m Trial 396 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 157, 'min_samples_split': 0.7809059080794583, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,406]\u001b[0m Trial 397 finished with value: 0.7433155080213903 and parameters: {'classifier': 'Gauss', 'smoothing': 0.02771220189531701}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,514]\u001b[0m Trial 398 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 50, 'weights': 'distance', 'p': 1.7082863719749306}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,525]\u001b[0m Trial 399 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 148, 'min_samples_split': 0.9272234953431546, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,618]\u001b[0m Trial 400 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 2.26354138199654}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,624]\u001b[0m Trial 401 finished with value: 0.9358288770053476 and parameters: {'classifier': 'Gauss', 'smoothing': 0.6638404931365668}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,638]\u001b[0m Trial 402 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 1.228919591012214, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,731]\u001b[0m Trial 403 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 32, 'weights': 'distance', 'p': 1.346801803211458}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,738]\u001b[0m Trial 404 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 38, 'min_samples_split': 0.667865292500655, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,745]\u001b[0m Trial 405 finished with value: 0.5721925133689839 and parameters: {'classifier': 'Gauss', 'smoothing': 6.637831464950859e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,765]\u001b[0m Trial 406 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 4.1145604537844186e-08, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,772]\u001b[0m Trial 407 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 180, 'min_samples_split': 0.9951959372794975, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,864]\u001b[0m Trial 408 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 16, 'weights': 'distance', 'p': 3.4452426143282358}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,872]\u001b[0m Trial 409 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 195, 'min_samples_split': 0.10348121024148822, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,890]\u001b[0m Trial 410 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'elasticnet', 'l1_ratio': 5.076367432225476e-07, 'max_iter': 2302, 'learning_rate': 'adaptive', 'eta0': 0.00035353434083277164, 'power_t': 0.20935902309768073, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,902]\u001b[0m Trial 411 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 96.00333670772027, 'kernel': 'sigmoid', 'gamma': 'auto', 'coef0': -46.36006752598849, 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,917]\u001b[0m Trial 412 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'huber', 'penalty': 'l2', 'l1_ratio': 0.17967462169014922, 'max_iter': 3219, 'learning_rate': 'adaptive', 'eta0': 0.0004033105514343423, 'power_t': 0.46379004843503613, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,924]\u001b[0m Trial 413 finished with value: 0.44919786096256686 and parameters: {'classifier': 'Gauss', 'smoothing': 5.3648109115918256e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,931]\u001b[0m Trial 414 finished with value: 0.4385026737967914 and parameters: {'classifier': 'Gauss', 'smoothing': 4.6494830853019484e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,946]\u001b[0m Trial 415 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 8.022102700178845e-06, 'kernel': 'rbf', 'gamma': 'auto', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,961]\u001b[0m Trial 416 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'epsilon_insensitive', 'penalty': 'l2', 'l1_ratio': 0.00011503245513886714, 'max_iter': 4511, 'learning_rate': 'adaptive', 'eta0': 0.1295622871756706, 'power_t': -0.6367053336427935, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,991]\u001b[0m Trial 417 finished with value: 0.39037433155080214 and parameters: {'classifier': 'SGD', 'loss': 'squared_epsilon_insensitive', 'penalty': 'l1', 'l1_ratio': 0.005595931516052885, 'max_iter': 4009, 'learning_rate': 'optimal', 'eta0': 0.797491593667537, 'power_t': -0.6253075279867382, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:40,999]\u001b[0m Trial 418 finished with value: 0.49732620320855614 and parameters: {'classifier': 'Gauss', 'smoothing': 1.4969238749581965e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,007]\u001b[0m Trial 419 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'l2', 'l1_ratio': 1.382264684804027e-06, 'max_iter': 4801, 'learning_rate': 'adaptive', 'eta0': 2.8831220937754424e-10, 'power_t': 0.958467768546472, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,014]\u001b[0m Trial 420 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 144, 'min_samples_split': 0.018378584900405538, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,075]\u001b[0m Trial 421 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 11, 'weights': 'distance', 'p': 4.006995524327497}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,096]\u001b[0m Trial 422 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.019118077925544045, 'kernel': 'sigmoid', 'gamma': 'auto', 'coef0': -13.417658951166175, 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:41,103]\u001b[0m Trial 423 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 38, 'min_samples_split': 0.2942499890340082, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,109]\u001b[0m Trial 424 finished with value: 0.5882352941176471 and parameters: {'classifier': 'Gauss', 'smoothing': 5.55057376227517e-05}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:41,116]\u001b[0m Trial 425 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 98, 'min_samples_split': 0.9901262373910785, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,209]\u001b[0m Trial 426 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'uniform', 'p': 3.0821345094856887}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,219]\u001b[0m Trial 427 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 11708.476485451487, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,283]\u001b[0m Trial 428 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 25, 'weights': 'uniform', 'p': 2.7514264816404848}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,289]\u001b[0m Trial 429 finished with value: 0.48663101604278075 and parameters: {'classifier': 'Gauss', 'smoothing': 8.569290879474344e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,299]\u001b[0m Trial 430 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 6.676706285387401e-08, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:41,330]\u001b[0m Trial 431 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 7.32882229215192, 'kernel': 'linear', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,406]\u001b[0m Trial 432 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 15, 'weights': 'uniform', 'p': 3.660367192152934}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,465]\u001b[0m Trial 433 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 36, 'weights': 'distance', 'p': 3.9594207254356926}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,472]\u001b[0m Trial 434 finished with value: 0.93048128342246 and parameters: {'classifier': 'Gauss', 'smoothing': 0.6386841158273214}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:41,479]\u001b[0m Trial 435 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 149, 'min_samples_split': 0.9086364252892523, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:41,503]\u001b[0m Trial 436 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 1279608.1651750945, 'kernel': 'linear', 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,515]\u001b[0m Trial 437 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'perceptron', 'penalty': 'l1', 'l1_ratio': 1.0265312740437668e-07, 'max_iter': 3034, 'learning_rate': 'adaptive', 'eta0': 6.814080284685415e-10, 'power_t': 0.5477833945946644, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,526]\u001b[0m Trial 438 finished with value: 0.9358288770053476 and parameters: {'classifier': 'SVC', 'C': 2731.6400661688504, 'kernel': 'poly', 'degree': 5, 'gamma': 'auto', 'coef0': -22.720392492553454, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,534]\u001b[0m Trial 439 finished with value: 0.4385026737967914 and parameters: {'classifier': 'Gauss', 'smoothing': 4.7245684287726825e-08}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,596]\u001b[0m Trial 440 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 34, 'weights': 'distance', 'p': 4.9186074288556245}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,603]\u001b[0m Trial 441 finished with value: 0.8770053475935828 and parameters: {'classifier': 'Gauss', 'smoothing': 0.28281000036406373}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,613]\u001b[0m Trial 442 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 12, 'min_samples_split': 0.8391196504523938, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,619]\u001b[0m Trial 443 finished with value: 0.5882352941176471 and parameters: {'classifier': 'Gauss', 'smoothing': 5.369312998849473e-05}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,626]\u001b[0m Trial 444 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 93, 'min_samples_split': 0.8507263597202585, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,709]\u001b[0m Trial 445 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 49, 'weights': 'uniform', 'p': 2.411249075327763}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,715]\u001b[0m Trial 446 finished with value: 0.6951871657754011 and parameters: {'classifier': 'Gauss', 'smoothing': 0.00374794602680118}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,781]\u001b[0m Trial 447 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 12, 'weights': 'uniform', 'p': 4.147314050342121}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,857]\u001b[0m Trial 448 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 15, 'weights': 'uniform', 'p': 1.1231592986694374}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,918]\u001b[0m Trial 449 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 48, 'weights': 'distance', 'p': 3.4065743076176522}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,926]\u001b[0m Trial 450 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 133, 'min_samples_split': 0.3878819158251522, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,985]\u001b[0m Trial 451 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 4, 'weights': 'uniform', 'p': 4.417751649877035}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:41,993]\u001b[0m Trial 452 finished with value: 0.40106951871657753 and parameters: {'classifier': 'Gauss', 'smoothing': 5.580164173572149e-09}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,001]\u001b[0m Trial 453 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 67, 'min_samples_split': 0.79971317696814, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,007]\u001b[0m Trial 454 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 23, 'min_samples_split': 0.324427456343453, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,016]\u001b[0m Trial 455 finished with value: 0.9090909090909091 and parameters: {'classifier': 'SVC', 'C': 1.4945074699523857, 'kernel': 'poly', 'degree': 2, 'gamma': 'scale', 'coef0': -46.97533525874156, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,023]\u001b[0m Trial 456 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 174, 'min_samples_split': 0.05030883705026928, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,031]\u001b[0m Trial 457 finished with value: 0.6631016042780749 and parameters: {'classifier': 'Gauss', 'smoothing': 0.0007390447563457046}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,038]\u001b[0m Trial 458 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 39, 'min_samples_split': 0.39278871933562465, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,048]\u001b[0m Trial 459 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 18799130.13925665, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': 21.234871499668927, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,106]\u001b[0m Trial 460 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 16, 'weights': 'distance', 'p': 2.5373759435610426}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,112]\u001b[0m Trial 461 finished with value: 0.5347593582887701 and parameters: {'classifier': 'Gauss', 'smoothing': 6.027954005368916e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,120]\u001b[0m Trial 462 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 137, 'min_samples_split': 0.7831537412242235, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,129]\u001b[0m Trial 463 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.00011109391266500172, 'kernel': 'poly', 'degree': 3, 'gamma': 'auto', 'coef0': 0.6720786702301353, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,147]\u001b[0m Trial 464 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'hinge', 'penalty': 'elasticnet', 'l1_ratio': 0.001545267425454358, 'max_iter': 1234, 'learning_rate': 'constant', 'eta0': 3.8566645994846364e-05, 'power_t': 0.07188063979246229, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,165]\u001b[0m Trial 465 finished with value: 0.9625668449197861 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'elasticnet', 'l1_ratio': 8.209849166204201e-06, 'max_iter': 4447, 'learning_rate': 'adaptive', 'eta0': 0.00014423908295019123, 'power_t': 0.1423338627513917, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,254]\u001b[0m Trial 466 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 7, 'weights': 'distance', 'p': 2.2295637098919734}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,265]\u001b[0m Trial 467 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 2.706699599618881e-10, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': -46.83536513548464, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,275]\u001b[0m Trial 468 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 120, 'min_samples_split': 0.5408930278203915, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,283]\u001b[0m Trial 469 finished with value: 0.5401069518716578 and parameters: {'classifier': 'Gauss', 'smoothing': 8.313950038387199e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,293]\u001b[0m Trial 470 finished with value: 0.48663101604278075 and parameters: {'classifier': 'Gauss', 'smoothing': 1.0237631875041524e-07}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,303]\u001b[0m Trial 471 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SGD', 'loss': 'log_loss', 'penalty': 'l1', 'l1_ratio': 6.400109472566846e-10, 'max_iter': 618, 'learning_rate': 'constant', 'eta0': 4.316954929880754e-06, 'power_t': 0.566894272918723, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,312]\u001b[0m Trial 472 finished with value: 0.5721925133689839 and parameters: {'classifier': 'Gauss', 'smoothing': 7.79386526090907e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,380]\u001b[0m Trial 473 finished with value: 0.9625668449197861 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'distance', 'p': 4.097359494454263}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,399]\u001b[0m Trial 474 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.005918420311141623, 'kernel': 'linear', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:42,406]\u001b[0m Trial 475 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 173, 'min_samples_split': 0.7287403535820232, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,415]\u001b[0m Trial 476 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'random', 'max_depth': 18, 'min_samples_split': 0.21714337522991523, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,423]\u001b[0m Trial 477 finished with value: 0.9411764705882353 and parameters: {'classifier': 'SGD', 'loss': 'perceptron', 'penalty': 'elasticnet', 'l1_ratio': 1.231698138916058e-09, 'max_iter': 663, 'learning_rate': 'invscaling', 'eta0': 0.00046389142919913513, 'power_t': 0.8654115684535331, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,433]\u001b[0m Trial 478 finished with value: 0.9358288770053476 and parameters: {'classifier': 'SGD', 'loss': 'squared_hinge', 'penalty': 'l1', 'l1_ratio': 4.798421564493381e-05, 'max_iter': 4907, 'learning_rate': 'invscaling', 'eta0': 0.008561020931527863, 'power_t': -0.998030091956204, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:42,439]\u001b[0m Trial 479 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 158, 'min_samples_split': 0.8410130838684009, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,445]\u001b[0m Trial 480 finished with value: 0.5401069518716578 and parameters: {'classifier': 'Gauss', 'smoothing': 1.4794756836037007e-06}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:42,484]\u001b[0m Trial 481 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SVC', 'C': 188586990.53333056, 'kernel': 'linear', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,498]\u001b[0m Trial 482 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 5.890758589626524e-10, 'kernel': 'linear', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,505]\u001b[0m Trial 483 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 75, 'min_samples_split': 0.8861241174765079, 'max_features': 'sqrt', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,535]\u001b[0m Trial 484 finished with value: 0.9572192513368984 and parameters: {'classifier': 'SGD', 'loss': 'log_loss', 'penalty': 'l1', 'l1_ratio': 0.00025448283715637975, 'max_iter': 4934, 'learning_rate': 'constant', 'eta0': 0.0003038620626491031, 'power_t': 0.5401252453333718, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "/home/lastutf445/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-16 22:07:42,545]\u001b[0m Trial 485 finished with value: 0.9518716577540107 and parameters: {'classifier': 'Tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 165, 'min_samples_split': 0.9272011269000148, 'max_features': 'auto', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,606]\u001b[0m Trial 486 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 32, 'weights': 'distance', 'p': 3.4727694487839296}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,614]\u001b[0m Trial 487 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SGD', 'loss': 'perceptron', 'penalty': 'l2', 'l1_ratio': 1.9898302220098613e-06, 'max_iter': 4242, 'learning_rate': 'invscaling', 'eta0': 1.0089567635901122e-09, 'power_t': 0.03166866241913491, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,697]\u001b[0m Trial 488 finished with value: 0.9732620320855615 and parameters: {'classifier': 'KNN', 'n_neighbors': 13, 'weights': 'uniform', 'p': 3.411725462116857}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,720]\u001b[0m Trial 489 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 293.4559070385571, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': True, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,745]\u001b[0m Trial 490 finished with value: 0.9518716577540107 and parameters: {'classifier': 'SVC', 'C': 7850.181699171499, 'kernel': 'rbf', 'gamma': 'scale', 'shrinking': False, 'probability': True, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,756]\u001b[0m Trial 491 finished with value: 0.93048128342246 and parameters: {'classifier': 'SVC', 'C': 3660535038.702157, 'kernel': 'poly', 'degree': 5, 'gamma': 'auto', 'coef0': -17.398133446861642, 'shrinking': False, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,777]\u001b[0m Trial 492 finished with value: 0.43315508021390375 and parameters: {'classifier': 'SGD', 'loss': 'squared_error', 'penalty': 'l2', 'l1_ratio': 0.10101271112832086, 'max_iter': 1701, 'learning_rate': 'optimal', 'eta0': 0.0004379911344736303, 'power_t': -0.39288854339202195, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,896]\u001b[0m Trial 493 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 25, 'weights': 'uniform', 'p': 4.684204010525096}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,962]\u001b[0m Trial 494 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 27, 'weights': 'distance', 'p': 2.488622770437301}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,971]\u001b[0m Trial 495 finished with value: 0.9679144385026738 and parameters: {'classifier': 'SVC', 'C': 0.00580552253505492, 'kernel': 'sigmoid', 'gamma': 'scale', 'coef0': 39.6692030998024, 'shrinking': True, 'probability': False, 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,978]\u001b[0m Trial 496 finished with value: 0.40106951871657753 and parameters: {'classifier': 'Gauss', 'smoothing': 9.151268641981636e-09}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:42,985]\u001b[0m Trial 497 finished with value: 0.9679144385026738 and parameters: {'classifier': 'Tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 87, 'min_samples_split': 0.7789579501320473, 'max_features': 'log2', 'random_state': 1337}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:43,048]\u001b[0m Trial 498 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 45, 'weights': 'uniform', 'p': 2.971849966497147}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n",
      "\u001b[32m[I 2023-02-16 22:07:43,127]\u001b[0m Trial 499 finished with value: 0.9679144385026738 and parameters: {'classifier': 'KNN', 'n_neighbors': 36, 'weights': 'uniform', 'p': 1.144050491957123}. Best is trial 27 with value: 0.9732620320855615.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_rand = optuna.create_study(direction='maximize', sampler=optuna.samplers.RandomSampler(1337))\n",
    "study_rand.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732620320855615"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_rand.best_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцените на тестовой части конфигурации гиперпараметров, которые были найдены разными методами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'SVC',\n",
       " 'C': 48.81218632183156,\n",
       " 'kernel': 'linear',\n",
       " 'shrinking': True,\n",
       " 'probability': False,\n",
       " 'random_state': 1337}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'KNN',\n",
       " 'n_neighbors': 13,\n",
       " 'weights': 'distance',\n",
       " 'p': 2.813727175872147}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_rand.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best(params):\n",
    "    p = params.copy()\n",
    "    del p[\"classifier\"]\n",
    "    classifiers = {\n",
    "        'KNN': KNeighborsClassifier,\n",
    "        'SVC': SVC,\n",
    "        'Gauss': GaussianNB,\n",
    "        'Tree': DecisionTreeClassifier,\n",
    "        'SGD': SGDClassifier\n",
    "    }\n",
    "    classifier = classifiers[params[\"classifier\"]](**p)\n",
    "    classifier.fit(trainX, trainY)\n",
    "    pred = classifier.predict(testX)\n",
    "    return accuracy_score(testY, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9308510638297872 0.9361702127659575\n"
     ]
    }
   ],
   "source": [
    "print(test_best(study.best_params), test_best(study_rand.best_params))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики зависимости функции ошибки от номера итерации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw(ax, trials):\n",
    "    x = range(1, len(trials) + 1)\n",
    "    y = [i.values[0] for i in trials]\n",
    "    ax.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABL4AAAGwCAYAAACn0KzbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB4VElEQVR4nO3df3xU5Z33//dMyA8CZEKgZCJSQbRqioKAxKjdtjYUqjfVdu9daqW6tNJvqXRt026FbSVFd017u2XpthS6VG675a7Qdm0tq5vWxmqXGo0lpjWiVhEFMQlCZIKBJDhzvn/EGTPJ/DqTmTk/5vV8PPLQDGfmXOdc51y55jrX5/p4DMMwBAAAAAAAALiM1+oCAAAAAAAAANnAwBcAAAAAAABciYEvAAAAAAAAuBIDXwAAAAAAAHAlBr4AAAAAAADgSgx8AQAAAAAAwJUY+AIAAAAAAIArMfAFAAAAAAAAV2LgCwAAAAAAAK7EwBcAAAAAAABciYEvAAAASJJ+//vfa9myZTrjjDPk8Xj0y1/+Mul7HnnkEc2fP1/FxcU655xzdM8992S9nAAAAKkaZ3UBUhEKhfTaa69p0qRJ8ng8VhcHAAA4gGEYOnHihM444wx5vTzrS0VfX5/mzp2rT3/60/r4xz+edPsDBw7o6quv1uc+9zn9v//3/9Tc3KybbrpJVVVVWrJkSUr7pJ8HAADMMtPP8xiGYeSoXGl79dVXNWPGDKuLAQAAHOjQoUM688wzrS6G43g8Hv3iF7/QtddeG3ebW2+9VQ888IA6Ojoir33iE5/Q8ePH1dTUlNJ+6OcBAIB0pdLPc8SMr0mTJkkaOqCysjKLSwMAAJygt7dXM2bMiPQjkHktLS2qq6uLem3JkiX64he/GPc9AwMDGhgYiPwefgZLPw8AAKTKTD/P9MDX73//e911113au3evOjs7kz4JlIbWfqivr9czzzyjGTNm6Otf/7r+7u/+LuV9hqe9l5WV0SECAACmED6XPV1dXaqsrIx6rbKyUr29vTp16pTGjx8/6j2NjY3asGHDqNfp5wEAALNS6eeZXvAivPbD5s2bU9o+vPbDBz/4QbW3t+uLX/yibrrpJv361782u2sAAAA43Lp16xQIBCI/hw4dsrpIAADAxUzP+PrIRz6ij3zkIylvv3XrVs2aNUvf/va3JUkXXHCB9uzZo3/9139NedFTAAAA2I/f71d3d3fUa93d3SorK4s520uSiouLVVxcnIviAQAAmJ/xZVa8tR9aWlrivmdgYEC9vb1RPwAAALCX2tpaNTc3R7320EMPqba21qISAQAARMv6wFeytR9iaWxslM/ni/yQ6QcAACD73nzzTbW3t6u9vV3S0JIV7e3tOnjwoKShMMUbbrghsv3nPvc5vfTSS/rqV7+q5557Tt///vf105/+VF/60pesKD4AAMAoWR/4SgdrPwAAAOTeH//4R1188cW6+OKLJUn19fW6+OKLtX79eklSZ2dnZBBMkmbNmqUHHnhADz30kObOnatvf/vb+uEPf8hyFgAAwDZMr/FlFms/AAAAOMMHPvABGYYR99/vueeemO956qmnslgqAACA9GV9xhdrPwAAAAAAAMAKpge+WPsBAAAAAAAATmB64Iu1HwAAAAAAAOAEHiPRQg420dvbK5/Pp0AgoLKyMquLAwAAHID+gzNQTwAAwCwz/YesL24PxBMMGWo90KMjJ/o1bVKJFs2qUIHXY3WxAAAATEnUp0m1v2OmXxRv22DI0OP7j6nlpaOSPKqdPUWXnj3F8v5VJvt8ueo/plundujfWlEGOxx3JmTzODL92W455/EMb89ChjS5tEhTJxXLX5a5YzV7DjPRTme6TNn+nFx9brYx8AVLNHV0asPufeoM9Edeq/KVqGFZtZbOqbKwZAAAAKlL1KeRlFJ/x0y/KN62H51bpV1/fFXHT56OvP69372o8tJCffPjF1rWv8pkny9X/cd06zTRv+Xq/FvRx3ZLvz6bx5Hpz3bLOY+nqaNTa+97Oqo9Gy4Tx2r2HGainU5W5kzVa7auDydfd4Q6IueaOjq1ekebRl544XHiLSvm2/7GAQDYH/0HZ3ByPSXq08TrYI/s75jpF8XbNhVbLehfZbLPl6v+Y7p1mmp9Z5MVfWy39OuzeRyZ/my3nPN4mjo69bkdbUm38yj9YzV7DjPRTiern0zVa7auDzted2b6Dwx8xTBy+t6CsybryQM9+sP+1/Xa8X5VlZeoorQ47lTLVKb/pTJ1c+Q2vvGF6u0/LWPY9tMmFkse6Uhvv46+OaDjp6L/Pfx5kvT4/mP6w/7XdfiNU5Ikj8ej6ZPH67LZUyPT4GPt8/ipQb32xqmo7S+ZWRF1TkZ+TrxjLC8t1O3/tU8n+t+Kee49kvy+Eu259UpJUuuBHnUFTqmnb1DlpUXq6RtQz8lBdb69z0tnTZEkPXHg2KjzOLLewtt7vR4d6e2P+szjp07LI49qZlXI6/Xo6JsDmjph9Ln1vB02cMnMCu195Q0dOdGvqROKFTKMUWUI183RNwdGXUcj62BkuSomDr0//LkaVrZweYafh+F1MjK8IVbdR863x6Oq8hKVjy+KWc8jr4uR51KSWl46mvBze/vfOW/xPm/4PTX8uIdfg53DtisvLdSfXz2ukCF5PdLcM8sVOHU6qj5j3Qex7sPwNTb8nCbazxsnB0ddL/Gup5HXSvg62PvKG5HremRdh6+higmjr83w+Y5VB+HzOPych98TvobC5Rl+Hcarq3C5h99/x08OlXd4uxLvHn1t2GePbC/D1+TwazVWmxLr+CpKi6POjTGinUp0Dcaqr+MnY5c7UXuR7PjC1/jIvwPD78XXEty7seo6lfY1lb9J4fYqfN+OPNaR7dXIMg1vj2K1vfGu5ZHnuTPOcWWakwdU8kku6mlkez+8/YjVZsZri0e2V//R8oreHAimVabJpeP0t5fM0I8ee0X9p0MJtivUE/9YJ0m6tLFZPX2Dae1vQlGBbrjsrEi7aIzoWw7/ezu8fRrZ32l56ahe7TmpY32nNb7IK3/ZeM2b8c7f4fDfimkTi/Xln/1JXb39ScsUr189vN7ueODZhMfuLyvW7796ZVR5w/244X9vw32zWP23ZP3UsZhQ5NWNtbPk9Y7ubw7v78X6mzj879nI7wHDj2Hnk4cSnqPKSUXauPzipN8bRvbVYvXzKn3FCpw8rV889ZoG3op//ZaPL9Tm6+dH+qTD/x4Nr4vhdRX+e3G0b0Adr/ZGrrP5756syrKSuH/HJEX1H4efr/C9HP4bPvxYqspLtOvJVxOeu/Lx43RdzbtT+k40/G9qxfgi3fLT9oSfPbG4QLd/dI6qysfHDZsdfo6S3Qvl4wv0gfMqdXIwqEtmVmjFpWep7ZU34vYzkvXZY/VnEoX6xvrOGW8fUvT3FMMw9Ot93Rp4K7UhionFBfrGsvfqjZODo74jJurD/fa5I+pL0HZPm1iob//txSnfW1W+Ej36Dx/Ukwd69PmftClwKvZMNUmqmFCoP9z6IbUfOh7pQ5eNT972jGzj4o1T7Gp9VT0nE5c11nftWG3k8P9P1p6XFnr14ff6o75bZru/x8DXGMSavpfoKY4UPb0vlel/qUzdjDVdPV3lpYUafCukk4Pxb+7y0kItX3jmmPcZnk4vKeExJvOluvdo55MHo86jWcnqbSw8HsnsnZPN8sRTWlQgSQnrPpFMXRfZ+jwzYt2HI+/VbBh5rXg9Usj2rW7ya7y8tFCSTNdjKu2Rk4Xb71/9qTPq2srEcafavib7m5SKXLZX2QzDYuDLGbJdT7lq77OpZJxXhpRwgCEb0unvjFWisMFkJhaP05sDmR+0yieZ/h4Slm6/Id+M5frPpHCfPVZ/Roqux+FlNvP9b6zfU+xmaHA1tQcT6batI9u4dPtrmfiubVY2+nsMfKUhGDL03eYXtKn5hbQ/45x3TdCLr/fF/fcl1dP0xsnTan35jbT3AWBsllRP04TiQt331GGriwJk1ex3lWr/6yetLkbKvv/Ji3XVRWdk9DMZ+HKGbNbTWEIDAQDJWfFwH86VybB7sjqa1NTRqVv/888KnBrbE6JEg16S9Ot9R8b0+QDGjvsQ+cJJg16StObep/Q9eXTVRc5dlwT2EgwZ2rB7H1/IACCLaGNhxobd+7S42p/zTJDenO7NhsKL54110AsAAKQvZEif/0mbmjo6rS4KXKL1QI+jwxsBAHCbzkC/Wg/05Hy/eT3wFQwZ+savnrG6GAAA4G0bdu9T0AkL4cH2jpxg0AsAALux4u9zXg98tR7oUVfvgNXFAAAAb7PqSSDcZ9qkEquLAAAARrDi73NeD3zxJBAAAPvh7zMyYdGsClX5GPwCAMAuqnwlWjSrIuf7zeuBL54EAgBgP/x9RiYUeD1qWFat3C6fCwAA4mlYVp3zhe2lPB/4WjSrQv6yYquLAQAA3jZlQpElTwLhTour/brlQ+dqYnFBzvaZy/58vF0x2Afkn0UzJ6tkXF5/vc8q2tXRCr0eFab4R29yaaG2rpivpXOsyd49zpK92kSB16NvfPS9+tyONquLAljikpmTtXDmZJWPL1LbwTf062e6rS4SMGYLzyrXmZNLdep0kGvaga6Zd4YlTwLhPk0dnVp739M6fvJ01OsFHimYJH9CUYH0lQ+fr8kTinT7f+3Tif7Us3+HDOm2qy9QT9+gNj+y33S5PZJSTe8Qb7vw6+XjC3XjZWdp4VkVeuLAMYUMqSvQr1/v61LfQDCyfWmRVwveXa7/eTH5+nrF4zy68IwyFReO04n+03rx9T6dHAwmfZ/dlBZ59YH3vEu/f+Go3hx2LooLpAHnHU6UkkKv+k+HMv65xQUeLXmvXx6P9Ntnj6gvC/Vu5vp3onEeady47NRP68tvSJJKxkkhw6PBZA2dhq6V9587VfPPqlBv/2kZhrTzyUN6o28wbj14PUPtXKqKCrwaDKZ2vJedXaGpE4v0633dGngr8U5KC736Yt17NGVisXr6BvTHV97Qo395Pe65nVjs1eWzp2p80TidOh3UY/uPpdS2F4/zakLROPWcHEzpGMKKCjxaOsevX/0ptWzV19fMUHlpkTzy6JKzJuvme9ui2qZESgu98pcV66Vjp0yVcaxOD7sQigo8mjejXAve/m55/NSgOo/3a/rk8bps9lRdevYUS/t3eT3wJUlL51Rp64r5MTtG+czjkYxhbU2Vr0QfnVulXX981dLzVF5aqMG3QhnpYFn5h3VyaaEaP36h9r7So23/83LS7eOVNd1jqPKVqGFZ9agR93hfEhKpmFCof7pmjrxejzbs3mc6dfzIay1s5B9Vs39kzZpcWqi/XXimfvWnTtPH4EQej1R3wTR1HO7N2vFOLB6nNwdS/7I4XLzrIpHh13UwZKj1QI+ml4/XT//4atxyjLyuqnwl+l8XVek/2w6rpy9+B6e8tFCSLP+74cYvCIur/VYXAS7Q1NEZ98FmCt8FNRiU3j2lVEvnVGlSyTitfvuzUr3fpk4q1tRJ6UUVZPKeDpw6rX9rflFbVszXV5acr6aOTm15ZP+ofZwaDKU06CVJA28Z2nswoM/+1Sz9++8POLYNOjkY0oMdox+OOH3QS1LGB1XCX1W/c93Fkb5jU0en6fsiFU69nlL1liF9pvYs/eD3B7K2j6GxnKEzmayfMHA6pN/sO6KPzT8zUrcXnenT6h1to94bvg5WvW+WqfKnOuglScsXvVvXzJuesA0P27h8XtT1eOeDzyU81r6BoWNNte0KH//AWyENvGVu0EuSBoOG3jUx9b8Di2ZN0TXzpksaOp5UB70k6eTpUM4HvUYaDBpqffkNffqKWZbN6krEYxhmv1rkXm9vr3w+nwKBgMrKyrKyj2DI0OP7j+kP+1/Xw88e0XPdb2ZlPyOVjy/QWyElvbAnlxbq2nln6P4/dSb8MpaOa+YOXZgejycyInvJzArtfeUNHTnRr2mThhagK/B6Iuep5aWjkjyqnT1Fl8ys0JMHevQ/Lx7Rnw8FNBAM6czy8XrvGT69q6xE0yYWK2QYWnPvUwqcSu9LYvn4Qq28fKbWXHmuJOnx/cf00z8e1P0pjKB/7aoLdONlM/XkgR7teOJl/c+IJ3vhp6HzZyQfWS8fP07X1bxbncf7VVVeovLxRertPy2PPCorGac7//u5lMrz6StmqcDrUcv+Y7pu2+MpnIF3TCop0P+ef6Y+/N4qLThrsp480KM/7H9dr709on7prCmSpJaXjurwG6fk8XhUVV6iitKhTri/7J36jCUYMvTYC0d104//qIG3UvtDFR5wWFztH8qWGjilnr5BVUwsjtR/uDxS7Gtt+Hv8ZSVacNbkqGsw/HtX4JTaDr6hHz9+0NR5i6WkcOhp76dqZ0aeQgRDhu75wwHd8cCzSd9/7bwzdEb5eE0uLVLFhCIdPxl9zE8cOCbJo5q3w7aG/+71enSkt19H3xzQ8VOndfiNU/pl+2tJ9zn8ev7D/tf1Hy2vJLlmC/Xd6y5WKGToF+2HdXIwqEtmVujGy2aqaJw3MkB05ES/pk54p65ee/sarygtjhxbeenQf8vGFyadAeEvK9bvv3plpM72vHhUTc9EzzBI5lOXvjvleg4PwF510Rlq6ugcNQg7uXScas+eoplTJ2pyaVHkXhh5nb3RN6g7Hog/gOsbP06fvnxWpC0KX+9H3xxQz8lBvTbsGh9+/nr6hurZ83b9/8PP/6yu3sQDjn//wXO05kPn6vu/e1E/3PNS3HqumFCoa+aeoTMnl6q8tEhH3+zXvz38YsrnenLpOH2y5iwZhuQbX6hnXguk9HRyzQfPUe3ZUySP9Nt9Xfp52+Goa2JCUYHed+5ULTirInIOvve7/Qn/DlT5SrTn1isz9kQwF/0HjF2m6ykYMnT5N5vHlLnbI8k/7HqM1a4kcu+qSyXJ9N/4bAgfy6P/8EG9/67fZexhR7YfSME+Ej0wTeehZ6ZMKCqQIWVtxqFHkq+0MOohV3gyQLoPSsP34/KFM7Sp+YXMFTaG8vHjVFI4Lml/Y3h7Jw31bR7a16Vftr8W9b1zeH9/wT89lJWHf/euulS1s4e+y8R7IB+eQBC+HoMhQ1d86+GU6yPVtstfVqz+t0JpH6dH0uQJherpS+394WM3ezx2k+m+XCJm+g95P+MrrMDr0eXnTtWJgdP6/iMv5Wy/gVPByGhzohH54ydP657HXomMUCvBtmZdeUFlZHR5uHCjM1z4PF1+7tSo12O9NtK3/vpCrd7Rlla5A6dOa9NvX9B5/klaOqdKl587VUf7BlIa+JpWVqyicV6dGDitpo7uUfsf/jT0X/5mbsynV+Hb9pt/fVHcEez72w+ndCzTyoojDUE6mcve7A/qnsdeUc3ZU1Q0zhv33L/vPe8y/dnSUB33nX4r5UEvaShsYvWONm1JELedqDyxrrVYr4d/93o9GRn4Gjgd0q+f6da1F0+P1EmB15PyU/oPnj8t5r0TNvKYE52D+9sPpzTwFb6ew/V+0ZnlSa7ZCyP7ff/500Z9XoHXM+o8p3LtxJsBEd7vNz76XhWN86p29hQ1dXTqvrbDpu99jyf1P5hv9J3WzT95Sp999XjMp3jHT76l/+7o1pYV00ddo8M7WDf/JHEb1Xvqrai2KN61m8w3PlqdtD387u9e1EAwmPSp5Bt9Q38fht9/Z02ZkHJ72/jx6Hbt/vbDKQ18nVs5UZefO1VNHZ2657FXRu3r5GAwcn+FP39GRWnC68aqBU/hLq0HesY06CUNXZ+dgX61HuhR7ewpWjqnSour/Xp8/zHd/JM2HY8zgBv+Ahlep67KV6KuQL+ls1jCx/Ljlpcz+kXK7oNeZh6e5JpHUmVZsb79t/PUsv+ovve75CGx1847I6V+Qjb8y/+eG7Ovmep9kS3//qmFunT2FG3fc0D//GDyB5ZhHkmlxQVJHxAZkjZfN3/oYeWIyQBfXXpB5OHXHQ88mzA0cORndgb6dcnMCk0uLdQbWZw5fvzUW7rlslkqKxmX8IFuuEzfe/hF7XzyYFQ7UTGhUB+bN1111f7IsbfsP5bxQa+RbacUfX0Nn3QxMmSu9UCPqbYtlbbrtqsv0PlVZbr+h0+YOIpohqSevtMp1fPwTIdmj8duhv/ttBNWvxsmGDK0Yfe+nO7T0NCNXl5aqGkJvmyH789f/alTmz85X/4MpufOVfaspXOqtGXFfFVMKDT93vDxb9i9T8G3W6tUyz1tUkmkbmO1c8M/e3G1X1tWjD6/fl9JwkEds+Ux+5545Q1modeZzn2Q7TKNlKlrNl6506nLsUp3n+H7Kp1rdixS3W+iey+ZsypKU97WePtn2//EHiRKdo2mWs5MXetL51Rp8ycvTrgIdqLjSVamcP1UJfhbEW+R0Wy0rSPLlevrFfklnYdKqXxW+OHfN//6Qnk0eqHjkQO44aySirGtFV7pOWl1EXLKzMOTbIp3nXzjo+/V5edM1bmVk1L6nLLx5vvPmXK0L/5AcrL7IpuO9g2owOvRNJPJygwp5VnRR/sGVDt7KAStdvaUqAeltbOn6GPzz9SdH5sjydyxH+0b0Mcvjv/wNFO+0/yCXjueWgjcv/72L6MGXN7oO63tf3hZgVODY3pwn0iih1/h6+srS87XV5acp8vPmTpqm0yXRxoKVz/65tgeoIR9LIV6Hn7s2TieXLPjMTDja5hMja5OKCowtdijoaEZXV+76oKETyvCo/GTJxRpz61XRoUnfflnf1J3r7knirFG1rNt6ZwqXXl+pWru/K3pJxwjn74umlWR8Enq8ONLVrfDPzv8dCF8foc/3UnETHlSfU8q5c30aHq690E2yzRSKuetYkKhvnZVtdoPJQ6LjFXudOpyrMayz3Sv2bFKZb/pXE/hY/1U7Uz9cM8BU/dHorGoRNeomXJm6lqfPKE46VPHVMfWYpVpeP2EwzHD4ZaxnpiGZattjVWuXF6vyB/ZfigRHsAdGeLljxEOFm/bChPhL5li5mGCnaS7XmQ2jzfV+vtS3XtGzaAZeZ2ker1aWX+plDF8rX/jV8+MecZlqsLlyuZDfDPHbibsc9qkEtVV+3X3H14eYwmT+0WKUSmxhCdphCcIFHg9GT/fsdpOM7JR/5n8zMVvz5ZLJWwz0/u2ih2PgYGvYcyOTMZb8O8Tl8xIqxE79EZqT+KOnOgfFZ4UDptJdaFjK8NKisZ51fjxC9POphmup/CT1ESLL4aPL9W6Hf7ZZr/QmilPKu8xU95MGutn5mKEP5VzfefHhv6IjCtILSxy5FN9s3U5VmPdZzrXbCYk22867ao0dKxF47xjuj/MlCmd69aO98rIz8x2W2a2bR1LuYBULZpVIX9Z8Zi/fFcleMBhZgA31rYLzpqs99/1u5yEQab6MCEcfid5kq4JJGV/ja/ha5M9eaBHLS8dVejttQi//0j89QKHH++2/3kpo4Mw5eMLtfn6+bpkZkXC+guXYc2V52jNleckvE5SfdiQzsMg79uJYuJtXzmpSKdDirt+sNkHfUPJIArHFB6WipHlSvdBspl9JJNuOHQm2qpkevpOq2JCUcrhmCOFH2I9vv+YvF6PugKnxvR5YeH7KZ1sfyPXqPWXlaQ8CSTRfZHJcPXhn1Xg9aQUtill53o2ayzte6K/nVYi1HGYVEcmv1T3Hm1NEKpRl2ZGqlSf5CR6+jiyTFW+Ev1/fzVrVLhLOmElwZChlv3HdH/7YbXsPzbmMJ+tK+ZHMqOZMfz4Uw2byVXoWjphPPHekwo7PuHIdehstureipAsN4aBmb0eRh7rWO4PM2VK57q1472Sqc+0W9sKmFHg9egbH33vmD/no3OrEn4ZCw/gjgyBSmXb8MC+FD8ULta/mRXrYUKifX7jo+/VNz5anXS/Hg1ldsvWo9OR5Q6HOn116fn6/94/W99KIdy0aJw3I9dB+HM9Glo38/JzpqZ0LoeHvCa6ThKFxKZaf/HKu+p9s+J+rkfShmvm6M6PzUkpdDdVmQoPiydWucYaVpypY08nHDpT12gy1847I6oMI8uUipt/0qbrtj2uL/30T+oZw6DXyPvJ7KBXU0enrvjWw7pu2+O6ZWe7rr/7CfW/FYzMTku230T3hZTZcPWR12mysM3wdlaHyZcUFqT9Xruu10pWx2HCGRQSja76y4r1h7UfimR/i/UEJ5XPGW74E61Unh4lypKQqExjCSuJlbUlXoYXM4ZniQwZ0s4nD8V9epDo+JMdX7I6SeXcmj0us+d75JOLROGrmS7vyHKYuX5zUaZEsl33Y7130mHFPrMlleupYkKhbvtf702YcTTcViRbPDeVp3jx2pBUr/tMXeup7DPZ0/pMlylWGe3UtppFVkdnyFY9xcsINqGoQIXjvEkXZ/ZIWX/okKh/JWnMGfNi9dVS6dMlytY3fNtUsvolmjkQL0NeKn3MVPumiTLD/e3CM0ftO/xQdmQmv1SzGqbbPzZzPCO3G3mOk9VRKvWd7nGYzVg+suzJfk9UrnSyTMYKR83Edxwz5/Q7v/2L/vW32c3weO+qSxU4NRizTJ+4ZEZW9j+W+zuepo7OmMl7wjPUy0dk4RxZHjP3xfB9JrvnEu0rXWau53jnOlZ7Nly8iIpk5zPW+2KFbWabmf4DA18jhG8mKXZ4R6odoHifM9LIz83U/jMpUQOT6TJl8/jteG4TsbK8qV6/uSzTWDit7t0mk+c/2WfFy3ybyr5Sue4zfc2kezzZLJNZdr6/GPhyhmzW0/AHbMNDSySlHJKU7YHbRAPM4X9LJXOcb/w4fe/tDHRH3xxI+OAklQcsw/fd0zeoionFUQ8oRv57eWmRjp9857/h7RecNVl7X3kj8mBPHo0qX7oPfFJ9X7zrIN6+JaVcnkw+rDJzPCNDZ8PnON5DilTre6zHYfaB18iyJ/s9WblSvWeG399S6vVt9lykWp+Xf/PhhCHGw+/vI739kXtyammRbtnVrp6TicNVw+1YvOs9nYfeYeH6nDYxs/f3SOFrK95AkEfvZEs9+uZApL0Zfr5itWHp3Ofh63Jk+zdyH8k+J9XreWT7aaYtlRT3M778sz8lvO78b5/PkedwwVmTIyHoicI2s42BrzHK1FMPs09kMr3/TEilgcl0pzCbx2+nc5sKK8sbb9+ZfnKTK1acSzfN3BqrXD4VH8u+kj1dy8Y1k87xZLtMZtm1bWXgyxmsqqdUZ6bcu+pSW6xJZ6dBZrve87AHu1yrdilHKsZS1kwcp9mH3iPlop1Mp822U1tlp7JIzvsbGAsDXxmQyZFpM09kMr3/sbLqhsjm8dvl3KbKyvJmK3TWKrkst93+uNlBLp+Kj2Vf8Z6uZfOaMXM8uSqTWXZsFxj4cgar6un+9sO6ZWd70u2+84l5umZe8nT0uWCHvy25jASAc9nhWrVTOVKR6Qd3Zo8z1meUjy9MuMREWC7aSbNttp3aKjuVJSzV8/npy2dq/bLcrEVnFgNfyBgndgoBq9nxjxuQj+g/OAMzvsyxcu3JcPhYsiyAVq3rB3uxywMRu5QjFZl6cJfucY78jJBhpJSl024zvhbNqsh51FI8g2+FdGljs+3azVTP55QJRWr9Wp0tJ+uY6T+My1GZ4FBk7ALMCYYMbdi9L+Y08XC2mQ2792lxtd+2nS4AyAfJUsaHv4zYLS17OEtgrphZYNmQ1BnoV+uBHlsNFsIaub5W7V6OVIylrJk4zpGfEQwZtmknzbTZrQd6ErZZuWqrmjo69Y+/eFo9ffFnzVnVbi6aVaGKCYUJyyZJx/oGY5bNSbMpJclrdQFgb+EGJt7Xc4+GLnC7dQoBq5j5QwsAsE6ilPHh3+2alj1XwjOYzWaWPHIi/UyUAOzDTu2kmbKk2gZls60Kt5/JBpZyUZZYCrwefSzFiK2RZYv3t6Er0K/VO9rU1NGZsXJmCgNfSMhOjR3gBHb4QwsASM3SOVXasmK+/L7omet+X0neh6UnmsGcDJEAgHvYqZ1MtSxWRy2l035a0W7WVftT2m542ZJFt0hD0S3BkL1W1CLUEUmFG5iRUxn9Np7KCFjF6j+0AABzls6p0uJqv2PWAMqVZDOYY7FreCiAsbFTO5lKWawOZTfTflrZbqZznuwSRmoWA19IiZ0aO8DOrP5DCwAwz0lrAOWK2ZnJRAIA7mandjJZWcJRS6t3tMkjRfXJc9FWmW0/rWo30zlPTo1uIdQRKQs3MNfMm67a2VPo1AAxEB4MAHADszOTMxn2FAwZatl/TPe3H1bL/mO2C5kBYH9Whmim2n5OmVBkeVi92fPk1OgWZnwBQIYRHgwAcLpkM5glqWJCoW77X++VvyxzkQBOyxQGwL6silpKtf1sWfchFY2zfi6SmfPk1OgWj2EYtn+E0tvbK5/Pp0AgoLKyMquLAwApCYYMwoMBC9F/cAbqyb7Cmbuk2CEwmZ6pEN7fyC8n2dofAGRLrtvPXLLLsZnpP1g/vAgALkV4MADAyXIZKuTUTGEAEIudsmFmmhOPjVBHAAAAADHlKlTIqZnCACAeNyeIc9qxMfAFAAAAIK5cZHNzaqYwAEjETtkwM81Jx8bAFwAAAFyPdRftzamZwuAO2WwfaHuQSVxP6WHgCwAAAK5GpkD7c2qmMDhfNtsH2h5kEtdT+ljcHgAAAK4Vzj41cv2orkC/Vu9oU1NHp0Ulw3AFXo8allVLeiczWFj494Zl1cxsQEZls32g7UEmcT2NDQNfNhQMGWrZf0z3tx9Wy/5jZK8BkBG0LQDyDZkCncWJmcLgXNlsH2h7kElcT2NHqKPNMH0RQDbQtgDIR2QKdB6nZQqDc2WzfaDtQSZxPY1dWjO+Nm/erJkzZ6qkpEQ1NTVqbW2Nu+3p06d1++23a/bs2SopKdHcuXPV1NSUdoHdjOmLALKBtgVAviJToDOFM4VdM2+6amdPYdALWZHN9oG2B5nE9TR2pge+du3apfr6ejU0NKitrU1z587VkiVLdOTIkZjbf/3rX9cPfvADffe739W+ffv0uc99Th/72Mf01FNPjbnwbsL0RQDZQNsCwCw3PeAkUyCAeLLZPtD2IJO4nsbO9MDXxo0btWrVKq1cuVLV1dXaunWrSktLtX379pjb//jHP9Y//uM/6qqrrtLZZ5+t1atX66qrrtK3v/3tMRfeTcxMXwSAVNG2ADDDbQ84w5kC480X8mgo7DvdTIGsnQg4Vzbbh2y3PcgvXE9jZ2rga3BwUHv37lVdXd07H+D1qq6uTi0tLTHfMzAwoJKS6JHH8ePHa8+ePWkU172YvgggG2hbAJjhtgec2cwU2NTRqSu+9bCu2/a4btnZruu2Pa4rvvUw4eOAQ2SzfSBLKTKJ62nsTA18HT16VMFgUJWVlVGvV1ZWqqurK+Z7lixZoo0bN+qFF15QKBTSQw89pPvuu0+dnfE7BQMDA+rt7Y36cTumLwLIBtoWAKly6wPObGQKZO1EwB2ymUmULKXIJK6nscl6VsfvfOc7WrVqlc4//3x5PB7Nnj1bK1eujPvkUJIaGxu1YcOGbBfNVsLTF7sC/THX4vFo6KJm+iIAM2hbAKQq0QPO5557LuZ7wg84/+qv/kqzZ89Wc3Oz7rvvPgWDwbj7GRgY0MDAQOT3XDzgzGSmwGRrJ3o0tHbi4mo/T98BB8hmJlGylCKTuJ7SZ2rG19SpU1VQUKDu7u6o17u7u+X3+2O+513vepd++ctfqq+vT6+88oqee+45TZw4UWeffXbc/axbt06BQCDyc+jQITPFdCSmLwLIBtoWANn0ne98R+eee67OP/98FRUVac2aNVq5cqW83vhdzMbGRvl8vsjPjBkzclLWTGUKZO1EwH2ymUmULKXIJK6n9Jga+CoqKtKCBQvU3NwceS0UCqm5uVm1tbUJ31tSUqLp06frrbfe0n/+53/qmmuuibttcXGxysrKon7yAdMXAWQDbQuAVPCAMzWsnQgAgLOYDnWsr6/XjTfeqIULF2rRokXatGmT+vr6tHLlSknSDTfcoOnTp6uxsVGS9MQTT+jw4cOaN2+eDh8+rG984xsKhUL66le/mtkjcQmmLwLIBtoWAMkMf8B57bXXSnrnAeeaNWsSvjf8gPP06dP6z//8T/3t3/5t3G2Li4tVXFycyaLnFGsn2kswZPC3DQCQkOmBr+XLl+v111/X+vXr1dXVpXnz5qmpqSmyHsTBgwejprf39/fr61//ul566SVNnDhRV111lX784x+rvLw8YwfhNuHpiwCQSbQtAJLhAWdyrJ1oH00dndqwe19U6GmVr0QNy6qZzQwAiEhrcfs1a9bEffL3yCOPRP3+/ve/X/v27UtnNwAAAMghHnAmF147cfWONnmkqMEv1k7MnXBmzZGDj+HMmoTyAwDCPIZhxHpYZSu9vb3y+XwKBAJ5s94XAAAYG/oPzuDUemK2kXWCIUNXfOvhuEkGwrPu9tx6JQOQAOBSZvoPac34AgAAAPIZaydax0xmTUL8AQAMfAEAAABpYO1Ea5BZEwBgBgNfAAAAAByDzJoAnI6MtLnFwBcAAAAAxyCzJgAnY43I3PMm3wQAAAAA7CGcWVN6J5NmGJk1AdhZOCPtyHUKwxlpmzo6LSqZuzHwBQAAAMBRls6p0pYV8+X3RYcz+n0l2rJiPrMmANhOMGRow+59MWeqhl/bsHufgqFYW2AsCHUEAAAA4Dhk1gTgJGSktQ4DXwAAAAAcicyaAJyCjLTWIdQRAAAAAAAgi8hIax0GvgAAAAAAALIonJE2XjC2R0PZHclIm3kMfAEAAAAAAGQRGWmtw8AXAAAAAABAlpGR1hosbg8AAAAAAJADZKTNPQa+AAAAAAAAcoSMtLlFqCMAAAAAAABciYEvAAAAAAAAuBIDXwAAAAAAAHAlBr4AAAAAAADgSgx8AQAAAAAAwJUY+AIAAAAAAIArMfAFAAAAAAAAVxpndQEAAAAAuFswZKj1QI+OnOjXtEklWjSrQgVej9XFAgDkAQa+AAAAAGRNU0enNuzep85Af+S1Kl+JGpZVa+mcKgtLBgDIB4Q6AgAAAMiKpo5Ord7RFjXoJUldgX6t3tGmpo5Oi0oGAMgXDHwBAAAAyLhgyNCG3ftkxPi38Gsbdu9TMBRrCwAAMoOBLwAAAAAZ13qgZ9RMr+EMSZ2BfrUe6MldoQAAeYeBLwAAAAAZd+RE/EGvdLYDACAdLG4PAAAAIOOmTSrJ6HYAMotsq8gXDHwBAAAAyLhFsypU5StRV6A/5jpfHkl+39CXbQC5RbZV5BNCHQEAAABkXIHXo4Zl1ZKGBrmGC//esKyaGSZAjpFtFfmGgS8AAABgjIIhQy37j+n+9sNq2X+MTIVvWzqnSltWzJffFx3O6PeVaMuK+cwsAXKMbKvIR4Q6AgAAAGNAyFBiS+dUaXG1n7WEABswk221dvaU3BUMyCIGvgAAAIA0hUOGRs6NCIcMMatpSIHXw5dowAbItop8RKgjAAAAkAZChgA4RTgc+4XuEyltf/TEAKHbcA1mfAEAAABpIGQIgBPECsdOxOuR7njg2cjvhG7D6ZjxBQAAAKSBkCEAdhcvg2MiIyd4ke0RTsfAFwAAAJCGaZNKkm9kYjsAyKRE4dixxMs3Qeg2nI6BLwAAACANi2ZVqMpXoni5CT0aChFaNKsil8UCAEnJw7HD1nzwHN129QWjZnoNNzx0G3AaBr4AAACANBR4PWpYVi1Jowa/wr83LKtWQbxpFACQRamGWZ9bOVFTJxVn9DMBO2HgCwAAAEjT0jlV2rJivvy+6HBGv69EW1bMZzFoAJYxE45N6DbcjKyOAAAAwBgsnVOlxdV+tR7o0ZET/Zo2aSi8kZleAKwUDsfuCvTHXOfLo6FB+nA4tpltASdhxhcAAAAwRgVej2pnT9E186ardvYUBr0AWM5MODah23CztAa+Nm/erJkzZ6qkpEQ1NTVqbW1NuP2mTZt03nnnafz48ZoxY4a+9KUvqb+f2GAAAAAAALLFTDg2odtwK9Ohjrt27VJ9fb22bt2qmpoabdq0SUuWLNHzzz+vadOmjdr+Jz/5idauXavt27frsssu01/+8hf93d/9nTwejzZu3JiRgwAAAAAAAKOZCccmdBtu5DEMI0HS0tFqamp0ySWX6Hvf+54kKRQKacaMGfrCF76gtWvXjtp+zZo1evbZZ9Xc3Bx57ctf/rKeeOIJ7dmzJ6V99vb2yufzKRAIqKyszExxAQBAnqL/4AzUEwAAMMtM/8FUqOPg4KD27t2rurq6dz7A61VdXZ1aWlpivueyyy7T3r17I+GQL730kh588EFdddVVcfczMDCg3t7eqB8AAAAAAADADFOhjkePHlUwGFRlZWXU65WVlXruuedivueTn/ykjh49qiuuuEKGYeitt97S5z73Of3jP/5j3P00NjZqw4YNZooGAAAAAAAARMl6VsdHHnlEd955p77//e+rra1N9913nx544AHdcccdcd+zbt06BQKByM+hQ4eyXUwAAAAAAAC4jKmBr6lTp6qgoEDd3d1Rr3d3d8vv98d8z2233aZPfepTuummm3ThhRfqYx/7mO688041NjYqFArFfE9xcbHKysqifgAAAJB9ZO8GAABuYmrgq6ioSAsWLIhaqD4UCqm5uVm1tbUx33Py5El5vdG7KSgokCSZXFcfAAAAWRTO3t3Q0KC2tjbNnTtXS5Ys0ZEjR2JuH87e3dDQoGeffVZ33323du3alXBJCwAAgFwyHepYX1+vbdu26Uc/+pGeffZZrV69Wn19fVq5cqUk6YYbbtC6desi2y9btkxbtmzRzp07deDAAT300EO67bbbtGzZssgAGAAAAKy3ceNGrVq1SitXrlR1dbW2bt2q0tJSbd++Peb2jz32mC6//HJ98pOf1MyZM/XhD39Y1113XdJZYgAAALlianF7SVq+fLlef/11rV+/Xl1dXZo3b56ampoiC94fPHgwaobX17/+dXk8Hn3961/X4cOH9a53vUvLli3TP//zP2fuKAAAADAm4ezdwx9gppK9e8eOHWptbdWiRYsi2bs/9alPxd3PwMCABgYGIr+TvRsAAGST6YEvSVqzZo3WrFkT898eeeSR6B2MG6eGhgY1NDSksysAAADkANm7AaQiGDLUeqBHR070a9qkEi2aVaECr8fqYgFAXGkNfAEAAADDs3fX1NToxRdf1C233KI77rhDt912W8z3rFu3TvX19ZHfe3t7NWPGjFwVGcAYNHV0asPufeoMvJPAospXooZl1Vo6p8rCkgFAfAx8AQAAYMzZuyXpwgsvVF9fnz772c/qa1/72qgER9JQ9u7i4uLMHwCArGrq6NTqHW0amZ6sK9Cv1TvatGXFfAa/ANiS6cXtAQAA4D5k7wYQTzBkaMPufaMGvSRFXtuwe5+CIe57APbDjC8AAABIGsrefeONN2rhwoVatGiRNm3aNCp79/Tp09XY2ChpKHv3xo0bdfHFF0dCHcneDbhP64GeqPDGkQxJnYF+tR7oUe3sKbkrGACkgIEvAAAASCJ7N4DYjpyIP+iVznYAkEsewwHz0Ht7e+Xz+RQIBFRWVmZ1cQAAgAPQf3AG6gmwv5b9x3TdtseTbnfvqkuZ8QUgJ8z0H1jjCwAAAAAQ16JZFarylcgT5989GsruuGhWRS6LBQApYeALAAAAABBXgdejhmXVkjRq8Cv8e8OyahV44w2NAYB1GPgCAAAAACS0dE6VtqyYL7+vJOp1v69EW1bM19I5VRaVDAASY3F7YIRgyFDrgR4dOdGvaZOGpmzz9AoAAAD5bumcKi2u9tNXBuAoDHwBwzR1dGrD7n1R6ZqrfCVqWFbNUywAAADkvQKvhwXsATgKoY7A25o6OrV6R1vUoJckdQX6tXpHm5o6Oi0qGQAAAAAASAcDX4CGwhs37N4nI8a/hV/bsHufgqFYWwAAAAAAADti4AuQ1HqgZ9RMr+EMSZ2BfrUe6MldoQAAAAAAwJgw8AVIOnIi/qBXOtsBAAAAAADrsbg9IGnapJLkG5nYDukhoyYAAAAAIJMY+AIkLZpVoSpfiboC/THX+fJI8vuGBmKQHWTUBAAAAABkGqGOgIbSMjcsq5Y0NMg1XPj3hmXVzD7KEjJqAgAAAACygYEv4G1L51Rpy4r58vuiwxn9vhJtWTGfWUdZQkZNAIDdBUOGWvYf0/3th9Wy/xh/k3LAjefcjccEAE5AqCMwzNI5VVpc7WedqRwyk1GzdvaU3BUMAAARim8FN55zNx4TADgFM76AEQq8HtXOnqJr5k1X7ewpDHplGRk1AQB2RSh+7rnxnLvxmADASRj4AmApMmoCAOyIUPzcc+M5t9sxEW7pPNQZMHaEOgKwFBk1AQB2RCh+7rnxnNvpmAi3dB7qDMgMZnwBsBQZNQEAdkQofu658Zzb5ZgIt3Qe6gzIHAa+AFiOjJoAALshFD/33HjO7XBMdgu3RHLUGZBZhDoCsAUyagIA7IRQ/Nxz4zm3wzHZKdwSqaHOgMxixhcA2yCjJgDALgjFzz03nnM7HJNdwi2ROuoMyCwGvgAAAIAYCMXPPTeec6uPyQ7hljAnE3WWr9kg8/W4kRihjgAAAEAchOLnnhvPuZXHZIdwS5gz1jrL12yQ+XrcSM5jGIbth0B7e3vl8/kUCARUVlZmdXEAAIAD0H9wBuoJyL5whkBJUQMp4WE3p86mc7N06yz8vpFf8t1e1/l63PnMTP+BUEcAAAAAcDGrwy3tzK6hcenUWb5mg8zX40bqCHUEAAAAAJdzYwjpWNk9NM5sneVrNsh8PW6kjoEvAAAAAMgD4QzaiB8a1xXo1+odbbaZCWemzvI1G2S+HjdSR6gjAAAAAEn2DfsCMsmtoXH5msEzX48bqWPGFwAAAADbh30BmeLW0Lh8zeCZr8eN1DHjCwAAAMhz4bCvkYMB4bCvpo5Oi0oGZJ5bQ+MKvB41LKuW9E42w7Dw7w3Lql23rlu+HjdSx8AXAAAAkMfcGvYFxOPm0Lh8zeCZr8eN1BDqCAAAAOQxt4Z9AfG4PTQuXzN45utxIzkGvgAAAIA85tawLyCecGjc6h1t8khRg19uCY3L1wye+XrcSIxQRwAAACCPuTnsC4iH0DggfzDjCwAAAMhjbg/7AuIhNA7IDwx8AQAAAHksH8K+gHgIjQPcL61Qx82bN2vmzJkqKSlRTU2NWltb4277gQ98QB6PZ9TP1VdfnXahAQAAAGQOYV8AALcyPeNr165dqq+v19atW1VTU6NNmzZpyZIlev755zVt2rRR2993330aHByM/H7s2DHNnTtXf/M3fzO2kgMAAADIGMK+AHcIhgzuY2AY0wNfGzdu1KpVq7Ry5UpJ0tatW/XAAw9o+/btWrt27ajtKyqi1wLYuXOnSktLGfgCAAAAbIawL8DZmjo6tWH3PnUG3snCWuUrUcOyamZuIm+ZCnUcHBzU3r17VVdX984HeL2qq6tTS0tLSp9x99136xOf+IQmTJgQd5uBgQH19vZG/QAAAAAAgNiaOjq1ekdb1KCXJHUF+rV6R5uaOjotKhlgLVMDX0ePHlUwGFRlZWXU65WVlerq6kr6/tbWVnV0dOimm25KuF1jY6N8Pl/kZ8aMGWaKCQAAAABA3giGDG3YvS9mZtbwaxt271MwFGsLwN3SWtw+XXfffbcuvPBCLVq0KOF269atUyAQiPwcOnQoRyUEAAAAAMBZWg/0jJrpNZwhqTPQr9YDPbkrFGATptb4mjp1qgoKCtTd3R31end3t/x+f8L39vX1aefOnbr99tuT7qe4uFjFxcVmigYAAAAAQF46ciL+oFc62wFuYmrGV1FRkRYsWKDm5ubIa6FQSM3NzaqtrU343p/97GcaGBjQihUr0ispAAAAAAAYZdqkkoxuB7iJ6VDH+vp6bdu2TT/60Y/07LPPavXq1err64tkebzhhhu0bt26Ue+7++67de2112rKFLLEAAAAAACQKYtmVajKVyJPnH/3aCi746JZFbksFmALpkIdJWn58uV6/fXXtX79enV1dWnevHlqamqKLHh/8OBBeb3R42nPP/+89uzZo9/85jeZKTUAAAAAAJAkFXg9alhWrdU72uSRoha5Dw+GNSyrVoE33tAY4F4ewzBsn9aht7dXPp9PgUBAZWVlVhcHAAA4AP0HZ8iHegqGDLUe6NGRE/2aNmloxgVfPgFkQ1NHpzbs3he10H2Vr0QNy6q1dE6VhSUDMstM/8H0jC8AAAC41+bNm3XXXXepq6tLc+fO1Xe/+924Gbk/8IEP6NFHHx31+lVXXaUHHngg20V1BL6EAsilpXOqtLjaz2A7MIzpNb4AAADgTrt27VJ9fb0aGhrU1tamuXPnasmSJTpy5EjM7e+77z51dnZGfjo6OlRQUKC/+Zu/yXHJ7ampo1Ord7RFDXpJUlegX6t3tKmpo9OikgFwswKvR7Wzp+iaedNVO3sKg17Ie8z4AgAAgCRp48aNWrVqVSRp0datW/XAAw9o+/btWrt27ajtKyqiF0neuXOnSktLGfjSUHjjht37FGtNEUNDa+5s2L1Pi6v9rv1SGivEU5KlM1GcHHbq5LIDSI57PHsY+AIAAIAGBwe1d+/eqOzcXq9XdXV1amlpSekz7r77bn3iE5/QhAkT4m4zMDCggYGByO+9vb3pF9rGWg/0jJrpNZwhqTPQr9YDPaqd7b6s57FCPMtLCyVJx0+ejryWy7BPJ4edOrnsAJLjHs8uQh0BAACgo0ePKhgMRjJ1h1VWVqqrqyvp+1tbW9XR0aGbbrop4XaNjY3y+XyRnxkzZoyp3HZ15ET8Qa90tnOSeCGex0+ejhr0knIX9unksFMnlx1Actzj2cfAFyKCIUMt+4/p/vbDatl/TMGQfRJ+2rlsAABgaLbXhRdeGHch/LB169YpEAhEfg4dOpSjEubWtEklGd3OKRKFeMYS3m7D7n1j6t8l6ismCzvNxP6zJddlp88N5JaT2ycnIdQRkuw9tdLOZQMAwC2mTp2qgoICdXd3R73e3d0tv9+f8L19fX3auXOnbr/99qT7KS4uVnFx8ZjK6gSLZlWoyleirkB/zC80Hkl+3zvrXrlFshDPWMYa9pmsr+jksNNclp0+N5B7Tm6fnIQZX7D11Eo7lw0AADcpKirSggUL1NzcHHktFAqpublZtbW1Cd/7s5/9TAMDA1qxYkW2i+kYBV6PGpZVSxoa5Bou/HvDsmrXLVw8ltDNdN6bSl/RyWGnuSo7fW7AGk5un5yEga88Z+eplXYuGwAAblRfX69t27bpRz/6kZ599lmtXr1afX19kSyPN9xwQ9Ti92F33323rr32Wk2ZwtPo4ZbOqdKWFfPl90WHM/p9JdqyYr4rZ9GMJXTT7HtT7StOnZjaDEM7hp3mImSWPjdgnXwNi881Qh3znJ2nVtq5bAAAuNHy5cv1+uuva/369erq6tK8efPU1NQUWfD+4MGD8nqjn5s+//zz2rNnj37zm99YUWTbWzqnSour/XmToj5ZiGcs6YZ9ptpXlCFbhp0GQ0bS6yIXIbP0uQHr5GtYfK4x8JXn7Dy10s5lAwDArdasWaM1a9bE/LdHHnlk1GvnnXeeDIOZIIkUeD15M2AQDvFcvaNNHinp4NdYwj5T7QMe7RuIWyarwk5TXU8r0fnMVNnpcwPWycU9DkId856dp1bauWwAAACILV6IZ3lpocpLC6NeG0vYp5m+op3CTs2up5XtstPnBqxlp/bJrZjxlefsPLXSzmUDAABwg1TC7dIRL8RTUsb2Z7avaIew02TraXk0tJ7W4mp/VLmyWXb63Mi1bLU7TmaH9snNGPjKc3aeWmnnsgEAADhdquF26YoX4pmpsM90+opWh52OZT2tbJWdPjdyKdvtjpNZ3T65GaGOsPXUSjuXDQAAwKnMhtvZldP6inZdT8tp5xHO5JZ2B87DjC9IsvfUSjuXDQAAwGnSDbezq0RhlS37j9mq/2jn9bTocyOb3NbuwFkY+EKEnadW2rlsAAAATjKWcDu7GtlXtGs4ld3X06LPjWxxY7sD5yDUEQAAAMgjdg23yxQ7h1OF19OS3lk/K4z1tOBmbm93YG8MfAEAAABvC4YMtew/pvvbD6tl/zEFQ7Hm5TibncPtxipZOJU0FE5lZb2ynhbykZvbHdgfoY4AAACA7Bsel2l2D7cbC6eEU7GeFvKNm9sd2B8zvgAAAJD37Bwel2luDrdzUjhVeD2ta+ZNV+3sKY4830Cq3NzuwP4Y+AIAAEBec0J4XKa5Ndwu1TCpoycGXB3OCtiRW9sdK+RDWH4mEeoIAACAvOaU8LhMc2O4XbJwKknyeqQ7Hng28rsbw1kBu3Jju5Nr+RKWn0nM+AIAAEBec1J4XKa5LdwuUThV2MiJEW4MZwXszG3tTi7lU1h+JjHwBQAAgLxGtjF3iRdOFe+7dS7DWQlPApCufAzLzxRCHQEAAJDXyDbmPiPDqY6eGIgKbxwpF+GshCcBGIt8DcvPBGZ8AQAAIK+RbcydhodTTZ1UnNJ7shXOSngSgLHK57D8sWLgCwAAAHmPbGPuZmU4K+FJADKBsPz0EeoIAAAAiGxjbmZlOCvhSQAygbD89DHjCwAAAHgb2cbcycpwVsKTAGQCYfnpY+ArDjKuAHAq2i8AAEazKpyV8CS4BX1M6xGWnx5CHWMg4woAp6L9AgAgPivCWQlPghvQx7QPwvLN8xiGYfth2t7eXvl8PgUCAZWVlWV1X+GMKyNPSvgSYhQVgF3RfgHRctl/QPqoJ+SD8N9oSVF/p/kbDSegjwk7MtN/INRxGDKuAHAq2i8AAOyL8CQ4FX1MuAGhjsOQcQWAU9F+AQBgb4QnwYnoY8INGPgahowrAJyK9gsAAPsLZw0FnII+JtyAUMdhyLgCwKlovwAAAJBp9DHhBgx8DRPOuBJvsrFHQ5kryLgCwG5ovwAAAJBp9DHhBgx8DVPg9ahhWbUkjbqxw783LKsmDh+A7dB+AQAAINPoY8INGPgagYwrAJyK9gsAAACZRh8TTucxDMP2eUd7e3vl8/kUCARUVlaWk30GQwYZVwA4Eu0XMMSK/gPMs2s90ZYC+Y02YDTOCezETP+BrI5xkHEFgFPRfgHA2DR1dGrD7n3qDLyTpazKV6KGZdXMbADyAG1AbPQx4VRphTpu3rxZM2fOVElJiWpqatTa2ppw++PHj+vmm29WVVWViouL9Z73vEcPPvhgWgUGAAAAsqWpo1Ord7RFfeGVpK5Av1bvaFNTR6dFJQOQC7QBgPuYHvjatWuX6uvr1dDQoLa2Ns2dO1dLlizRkSNHYm4/ODioxYsX6+WXX9bPf/5zPf/889q2bZumT58+5sIDAAAAmRIMGdqwe59irQMSfm3D7n0Khmy/UgjyXDBkqGX/Md3fflgt+49xzaaINgBwJ9Ohjhs3btSqVau0cuVKSdLWrVv1wAMPaPv27Vq7du2o7bdv366enh499thjKiwslCTNnDlzbKUGAAAAMqz1QM+oWR7DGZI6A/1qPdBDuA9sizC99NEGAO5kasbX4OCg9u7dq7q6unc+wOtVXV2dWlpaYr7nV7/6lWpra3XzzTersrJSc+bM0Z133qlgMBh3PwMDA+rt7Y36AQAAALLpyIn4X3jT2Q7INcL0xoY2AHAnUwNfR48eVTAYVGVlZdTrlZWV6urqivmel156ST//+c8VDAb14IMP6rbbbtO3v/1t/dM//VPc/TQ2Nsrn80V+ZsyYYaaYAAAAgGnTJpVkdDsglwjTGzvaAMCd0lrc3oxQKKRp06bp3//937VgwQItX75cX/va17R169a471m3bp0CgUDk59ChQ9kuJgAAAPLcolkVqvKVyBPn3z0aChlbNKsil8UCUmImTA+x0QYA7mRq4Gvq1KkqKChQd3d31Ovd3d3y+/0x31NVVaX3vOc9KigoiLx2wQUXqKurS4ODgzHfU1xcrLKysqgfAAAyhUV/AcRS4PWoYVm1JI364hv+vWFZtQq88b4WA9YhTG/saAMAdzI18FVUVKQFCxaoubk58looFFJzc7Nqa2tjvufyyy/Xiy++qFAoFHntL3/5i6qqqlRUVJRmsQEASE9TR6eu+NbDum7b47plZ7uu2/a4rvjWw6x7AkCStHROlbasmC+/LzqUye8r0ZYV81kcHLZFmF5m0AYA7mM6q2N9fb1uvPFGLVy4UIsWLdKmTZvU19cXyfJ4ww03aPr06WpsbJQkrV69Wt/73vd0yy236Atf+IJeeOEF3Xnnnfr7v//7zB4J4EDBkKHWAz06cqJf0yYNTZvmCRKQPeFFf0fO7wov+kuHFoA09MV3cbWfv9FwlHCYXlegP+Y6Xx4NDd4QppccbQDgLqYHvpYvX67XX39d69evV1dXl+bNm6empqbIgvcHDx6U1/vORLIZM2bo17/+tb70pS/poosu0vTp03XLLbfo1ltvzdxRAA5Eqmkgt5It+uvR0KK/i6v9dGwBqMDrUe3sKVYXA0hZOExv9Y42eaSov3eE6ZlHGwC4h8cwDNsvbNLb2yufz6dAIMB6X3CFeLNOwt0QZp0Amdey/5iu2/Z40u3uXXUpHV2XoP/gDNQTkFk8XAWQD8z0H0zP+HIjws2QS8w6AazBor8AgHxAmB4ARMv7gS+eiCDXzKSaZtYJkDks+gsAyBeE6QHAO0xldXSbcLjZyEGI8CLHZPhCNjDrBLBGeNHfeM+7PRp68MGivwCcKBgy1LL/mO5vP6yW/ccUDNl+NRMAAHIib2d8EW4GqzDrJH8RVm0tFv0F4FZEMAAAEF/eDnwRbgarkGo6P/GlxB6WzqnSlhXzR9WFn7oA4FDxEuaEIxhImAMAyHd5O/BFuBmswqyT/MOXEnth0V8AbkEEAwAAyeXtGl+Em8FK4Vknfl/09eX3lTAI4jLJvpRIQ19KWIslt8KL/l4zb7pqZ0/hCyEwzObNmzVz5kyVlJSopqZGra2tCbc/fvy4br75ZlVVVam4uFjvec979OCDD+aotPkh3vpdZiIYAADIV3k744twM1iNWSf5gbBqAE6ya9cu1dfXa+vWraqpqdGmTZu0ZMkSPf/885o2bdqo7QcHB7V48WJNmzZNP//5zzV9+nS98sorKi8vz33hXSpRqPzAW6GUPoMIBgBAPsvbgS/CzWAHpJp2P8KqATjJxo0btWrVKq1cuVKStHXrVj3wwAPavn271q5dO2r77du3q6enR4899pgKCwslSTNnzsxlkV0tWaj8F+vOTelziGAAAOSzvA11lAg3A5B9hFUDcIrBwUHt3btXdXV1kde8Xq/q6urU0tIS8z2/+tWvVFtbq5tvvlmVlZWaM2eO7rzzTgWDwbj7GRgYUG9vb9QPRkslVP7e1oPyl5Uo3mNaj4ZmhxHBkDnxwk4BAPaVtzO+wgg3A5BNhFUDcIqjR48qGAyqsrIy6vXKyko999xzMd/z0ksv6eGHH9b111+vBx98UC+++KI+//nP6/Tp02poaIj5nsbGRm3YsCHj5XebVELlu3oH9KW692jTb/9CBEMOkKEZAJwpr2d8hbHIMYBsCYdVSxr1RJ4vJQCcLhQKadq0afr3f/93LViwQMuXL9fXvvY1bd26Ne571q1bp0AgEPk5dOhQDkvsHKmGwM+cWkoEQw6Ew05HDkaGw06bOjotKhkAIJm8n/EFANkWDqse+ZTYz1NiADYydepUFRQUqLu7O+r17u5u+f3+mO+pqqpSYWGhCgoKIq9dcMEF6urq0uDgoIqKika9p7i4WMXFxZktvAuZCZWvnT2FCIY0BUNG0vOWLOzUo6EMzYur/ZxzOFYq9wLekanzxXnPDQa+ACAHCKsGYHdFRUVasGCBmpubde2110oamtHV3NysNWvWxHzP5Zdfrp/85CcKhULyeocCCf7yl7+oqqoq5qAXUmc2VJ6EOealGrpIhma4HWG85mTqfHHec4dQRwDIEcKqAdhdfX29tm3bph/96Ed69tlntXr1avX19UWyPN5www1at25dZPvVq1erp6dHt9xyi/7yl7/ogQce0J133qmbb77ZqkNwDULls8tM6CIZmuFmhPGak6nzxXnPLQa+AAAAIElavny5/uVf/kXr16/XvHnz1N7erqampsiC9wcPHlRn5zud8RkzZujXv/61nnzySV100UX6+7//e91yyy1au3atVYeQc9nM8kcG8uxIJWPmht37InVJhmbYTabanVTvhcG3QmQzlfm2I9ufg9QR6ggAAICINWvWxA1tfOSRR0a9Vltbq8cffzzLpbKnXISpECqfeWZDFxfNqlB5aaGOnzwdc3syNCOXMtnupHovXNrYrJ6+wTHvz+kyFfZM+HTuMeMLAAAAMCmXYSqEymeW2dDFh/Z1xR30koa+pBJ2ilzIdLuT6r0wfNBrLPtzukyFPRM+nXsMfAEAAAAmEKbibGZCF8N1nUh5aaEWV8fOfApkSjbanXTDc7PdzmUzhHwsMhX2TPh07hHqCAAAAJhAmIqzmcmYmayuJen4ydPUNbIuG+1OsnshkWy1c3bOdGg22262PwepY8aXy9l1tBwA4qHdAmB3hKk4m5mMmdQ17CIb12KieyFVmbz27Z7pMFPZdsnam3vM+HIxO4+WA0AstFsAnIAwlewIhoycLeIfzpg58m+Ob3yhVl4+MxK6SF3nRi7r3qmydS3GuxcqJhSqpy/+2nZhR08MKBgyxlxfyUI5PRoKrVxc7R/TvsZ6rcU7X36T/dVMfY5Z+XqveQzDsP2j9N7eXvl8PgUCAZWVlVldHEcIj5aPrNzwJU0KbAB2Q7uFTKP/4AxOrKdgyNAV33o4aZjKnluvzIsvFJlg1YOPYMjQ9x5+Uf/3Dwd0/NQ7X/LD+15c7aeus4yHXqnJdrszckBkwVmT9f67fpdSGGQm6qtl/zFdty15huB7V12admhlJq+1TA0g5XIgym33mpn+A6GOLsSCqwCchnYLgJMQppJZVoY3PbSvS5t++5eoQa/h+35oXxd1nUV2D22zk2y3OyOzxxaN86YcBpmJ+sp2WHGmr7VMZdvNVdbefL/XGPhyITMLHwKAHdBuAXCacJiK3xcdVuT3lTBD1QQrH3ykuu/F1X7qOgt46GVertudePsbKRP1lc2w4ny/1vL9+CXW+HIlFuEE4DS0WwCcaOmcKi2u9ufleimZYmWGTDP7pq4zj+yo6cn1tRje3z1/OKA7Hng27nZjra9sZjrM92st349fYuDLlViEE4DT0G45Q74uiAokEg5TQXqsfPBhdt/UdWbx0Ct9ub4WC7weTZ1UnNK26dZXOJRz9Y42eaSowa+xhnLm+7WW78cvMfDlStkcLQeAbKDdsj+3LYgKZEN4cLgrcEo9fYOqmFgsfxmDxIlY+eCDhy7W4vw7Q7hde6H7RErbJ6qvZA/QspXpMN+vtXw/fomBL1fK5mg5AGQD7Za9xcu4GV4QlTVugNiDw2EMEsdn5YMPHrpYi/Nvf4natVjKSwvj1leqD9CyEcqZ79davh+/xOL2rsWCq0hFMGSoZf8x3d9+WC37j7l6QUPYH+2WPbEgKpBcvGxZYZ15kjUrHVZmyCQ7p7U4//aWrF2L5fjJ03poX1fKnxUvo2CmMx3m+7WW78cvSR7DMGzfU+3t7ZXP51MgEFBZWZnVxXEU1mNBPIQtwa5ot+ylZf8xXbft8aTb3bvqUtutfUP/wRmcXk/BkKErvvVw0i+H4Sfqe269kjYtBiv7JfSJrMX5t59U27WRYrVzyT4rl21jvl9rbjt+M/0HQh1djkU4EQthS7Az2i17YUFUILFk2bLC8iFr1lhYmTWRjI3W4vzbT6rt2kix2jk7ZRTM92stn4+fgS8gzyQLW/JoKGxpcbU/LxpBAImxICqQmNlBXwaJ47PywQcPXazF+beXsbZTw99vtwdo+X6t5evxs8YXkGfMPHUBgPCCqPGGwT0amibv5gVRgUTMDvoySAzA7sbaTg1/Pw/QYAcMfAF5xm5PXQDYGwuiAomFB4eTYZAYgFMke+gVT6x2jgdosAMGvoA8w1MXAGaRcROILzw4nMoXRAaJAThBoode8cR7GMYDNNgBWR2BPBPOrNIV6I+5zhdZpwDE47SMm/QfnMEt9RQrW1aYk7NmAchf8bIAfnRulX71p05T2QHdllEQ1jPTf2DgC8hD4ayOkqIGv8JfX5nBAcAN6D84g5vqKTw43BU4pZ6+QVVMLJa/zP6DxLAPpz1ggPvFuybTuVa5vpFJDHwBSIqnLgDcjv6DM1BPwBD6ZgCQOjP9h3E5KhMAm1k6p0qLq/08dQEAALBYeDb+yBkJXYF+rd7Rxmx8ABgDBr6APFbg9ah29hSriwEAAJC3giFDG3bvi7n2qqGhpSg27N6nxdV+HlAipkyGEBKO6D5m6tSt9c/AFwAAAABYpPVAT8ykCGGGpM5Av1oP9PDAEqNkMkSWcFv3MVOnbq5/bzpv2rx5s2bOnKmSkhLV1NSotbU17rb33HOPPB5P1E9JSUnc7QEAAAAgXxw5EX/QK53tkD/CIbIjB07DIbJNHZ2WfBbswUydur3+TQ987dq1S/X19WpoaFBbW5vmzp2rJUuW6MiRI3HfU1ZWps7OzsjPK6+8MqZCw96CIUMt+4/p/vbDatl/TMGQ7fMnAAAAAJaYNim1SQHJtqMPnl+ShchKQyGyqVwHmfwsWGPk/T/4VijlOs2H+jcd6rhx40atWrVKK1eulCRt3bpVDzzwgLZv3661a9fGfI/H45Hf7x9bSeEIbp4eCQAAAGTaolkVqvKVqCvQH/OLp0eS3ze01k489MHzTyZDZAm3dbZY93/FhEL19J2O+57hdaq3/z+VbZ1a/6ZmfA0ODmrv3r2qq6t75wO8XtXV1amlpSXu+958802dddZZmjFjhq655ho988wzCfczMDCg3t7eqB/Yn9unRwIAAACZVuD1qGFZtaShQa7hwr83LKuOu8A0ffD8lMkQWcJtnSve/Z9o0Gu4Iyf686L+TQ18HT16VMFgUJWVlVGvV1ZWqqurK+Z7zjvvPG3fvl3333+/duzYoVAopMsuu0yvvvpq3P00NjbK5/NFfmbMmGGmmLBAPkyPBACzCDsBAKRi6ZwqbVkxX35fdDij31eiLSvmx521RR88f2UqRDbTn4XcSXT/p2rapJK8qP+sZ3Wsra1VbW1t5PfLLrtMF1xwgX7wgx/ojjvuiPmedevWqb6+PvJ7b28vg182x/RYAIhG2AkAwIylc6q0uNqv1gM9OnKiX9MmDYU3xpvpJdEHz2eZCJHNxmchd5Ld/4mMrFO317+pGV9Tp05VQUGBuru7o17v7u5OeQ2vwsJCXXzxxXrxxRfjblNcXKyysrKoH9hbPkyPBIBUEXYCAEhHgdej2tlTdM286aqdPSXhoJdEHzyfjTVENlufhdxJ974eWaf5UP+mBr6Kioq0YMECNTc3R14LhUJqbm6OmtWVSDAY1NNPP62qKp52u0k+TI8EgFQQdgIAyBX64Pkt3RDZbH8WciPV+7piQlHU77Hq1O31bzrUsb6+XjfeeKMWLlyoRYsWadOmTerr64tkebzhhhs0ffp0NTY2SpJuv/12XXrppTrnnHN0/Phx3XXXXXrllVd00003ZfZIYCmmxwLAEMJOAAC5Qh8c6YTI5uKzkH2p3v+P/sMHtfeVN5LWqZvr3/TA1/Lly/X6669r/fr16urq0rx589TU1BRZ8P7gwYPyet+ZSPbGG29o1apV6urq0uTJk7VgwQI99thjqq6uztxRwHLh6ZGrd7TJI0XdeG6ZHgkAqSDsBACQK/TBIb0TImu3z0J2pXr/F43zplynbq1/j2EYto+16O3tlc/nUyAQYL0vm2MxZwD5rmX/MV237fGk29276lJXdizshP6DM1BPwNjRBwfyV77e/2b6D1nP6oj84ubpkQCQCsJOAAC5Rh8cyF/c/8kx8IWMc+v0SABIBWEnAAAr0AcH8hf3f2KmsjoCAIDk3J4ZBwAAAHAKZnwBAJAFTDsHEEswZNAuuBR1C64BwJ4Y+AIAIEuYdg5guHxdgDgfULfgGgDsi1BHAAAAIMuaOjq1ekdb1JdiSeoK9Gv1jjY1dXRaVDKMFXULrgHA3hj4AgAAALIoGDK0Yfe+mJlew69t2L1PwVCsLWBnqdbt4Fshtew/pvvbD6tl/zHq2kW4vwH7I9QRAAAAyKLWAz2jZoIMZ0jqDPSr9UAP4dEOk2rdXtrYrJ6+wcjrhMC5B/c3YH/M+AIAAACy6MiJ+F+K09kO9pFqnQ0f9JIIgXMT7m/A/hj4AgAAALJo2qSSjG4H+0i3zgiBcw/ub8D+GPgCAAAAsmjRrApV+UrkifPvHg2Fvi2aVZHLYiEDktVtIsND4OBc3N+A/THwBQAAgIjNmzdr5syZKikpUU1NjVpbW+Nue88998jj8UT9lJQwq2GkAq9HDcuqJWnUl+Pw7w3LqlXgTWf4BFZKVLepIgTO2bi/Aftj4AsAAACSpF27dqm+vl4NDQ1qa2vT3LlztWTJEh05ciTue8rKytTZ2Rn5eeWVV3JYYudYOqdKW1bMl98XPTDo95Voy4r5LHLuYPHqtmJCYUrvz7cQuGDIcF2Gy3y+v91Yn8O5/fjyhccwDNvXXG9vr3w+nwKBgMrKyqwuDgAAcAD6D+bV1NTokksu0fe+9z1JUigU0owZM/SFL3xBa9euHbX9Pffcoy9+8Ys6fvx42vvMt3oKhgy1HujRkRP9mjZpKPyJmSDuMLJuF5w1We+/63fqCvQr1hcuj4YGRvbcemXeXANNHZ3asHtfVBZEN2W4zLf72+316fbjczoz/QdmfAEAAECDg4Pau3ev6urqIq95vV7V1dWppaUl7vvefPNNnXXWWZoxY4auueYaPfPMMwn3MzAwoN7e3qiffFLg9ah29hRdM2+6amdPcfWX4nwzsm6LxnkJgRumqaNTq3e0RQ0iSO7KcJlP97fb69Ptx5dvGPgCAIsxhRqAHRw9elTBYFCVlZVRr1dWVqqrqyvme8477zxt375d999/v3bs2KFQKKTLLrtMr776atz9NDY2yufzRX5mzJiR0eMA7CSfQ+CGC4YMbdi9L+bMNzJcOo/b69Ptx5ePxlldAADIZ0yhBuBktbW1qq2tjfx+2WWX6YILLtAPfvAD3XHHHTHfs27dOtXX10d+7+3tZfALrrZ0TpUWV/vzKgRupNYDPaNmzgw3PMNl7ewpuSsY0uL2+nT78eUjBr4AwCLhKdQjnxWFp1Dn05NgANabOnWqCgoK1N3dHfV6d3e3/H5/Sp9RWFioiy++WC+++GLcbYqLi1VcXDymsgJOEw6By1epZq4kw6UzuL0+3X58+YhQRwCwAFOoAdhNUVGRFixYoObm5shroVBIzc3NUbO6EgkGg3r66adVVcWgPazB8gH2lGrmynzLcOlUbq/PdI/Pzu2PncuWC8z4AgALMIUagB3V19frxhtv1MKFC7Vo0SJt2rRJfX19WrlypSTphhtu0PTp09XY2ChJuv3223XppZfqnHPO0fHjx3XXXXfplVde0U033WTlYSBPsXyAfS2aVaEqX0nSDJeLZlXkumhIg9vrM53js3P7Y+ey5QozvgDAAkyhBmBHy5cv17/8y79o/fr1mjdvntrb29XU1BRZ8P7gwYPq7Hwnk9Ubb7yhVatW6YILLtBVV12l3t5ePfbYY6qurrbqEJCnyMBmbwVeDxkuXcTt9Wn2+Ozc/ti5bLnkMQzD9nPcent75fP5FAgEVFZWZnVxAGDMWvYf03XbHk+63b2rLmXGF5Am+g/OQD1lRzBk5M1i6sGQoSu+9XDcmdTh2Rl7br3StefAKZh54i5ur89Ujs/O7Y+dy5YJZvoPhDoCgAXcPkUcAGAdt38ZHYnlA5yDDJfu4vb6TOX47Nz+2LlsucbAFwBYIDyFevWONnmkqMEvN0wRBwBYIx8zBrN8gLPke4ZLt3F7fSY7Pju3P3YuW66xxhcAWGTpnCptWTFffl90Rhi/r8SVX0wAANmVrxmD3Z5hDkBsdshUaOf2x85lyzVmfAGAhdw+RRwAkDv5GtbC8gFA/rFLSLed2x87ly3XmPEFABYLT6G+Zt501c6ewqAXACAt+RrW4vYMcwCi2SlToZ3bHzuXLdcY+AIAAABcIJ/DWlg+AMgPdgzptnP7Y+ey5RKhjgAAAIAL5HtYC8sHAO5n15BuO7c/di5brjDwBQAAALgAGYPdn2EOyHd2Dum2c/tj57LlAqGOAAAAgEsQ1gLAzfI5pBvpY8YXAAAA4CKEtQBwq3wP6UZ6GPgCAAAAXCbfw1oAuBMh3UgHoY4A8lowZKhl/zHd335YLfuP5TQDDAAAAABzCOmGWcz4ApC3mjo6tWH3vqjMMFW+EjUsq+YPJgAAyAvBkEFYLByHkG6YwcAXgLzU1NGp1TvaRq0N0BXo1+odbTwtAgAArsdDQDgZId1IFaGOAPJOMGRow+59MRfEDL+2Yfc+wh4BAIBrhR8CDh/0kt55CNjU0WlRyQAgsxj4ApB3Wg/0jOrkDWdI6gz0q/VAT+4KBQAAkCM8BASQTxj4ApB3jpyIP+iVznb5hGQAAAA4Hw8BAeQT1vgCkHemTSpJvpGJ7fIF64AAAOAOPAQEkE+Y8QUg7yyaVaEqX4ni5XzxaGhAZ9GsilwWy9ZYBwQAAPfgISAwGpEN7sWMLwB5p8DrUcOyaq3e0SaPFLW+RXgwrGFZNemQ35ZsHRCPhtYBWVzt55xZiHT0AIBUhR8CdgX6Y/5990jy8xAQeYTIBndjxheAvLR0TpW2rJgvvy/6SabfV6ItK+bzB24Y1gGxv6aOTl3xrYd13bbHdcvOdl237XFd8a2HmYkHAIgp/BBQ0qgZ8DwERL4hssH90hr42rx5s2bOnKmSkhLV1NSotbU1pfft3LlTHo9H1157bTq7BYCMWjqnSntuvVL3rrpU3/nEPN276lLtufVKBr1GYB0Qe6OzBgBIBw8BATKc5gvToY67du1SfX29tm7dqpqaGm3atElLlizR888/r2nTpsV938svv6yvfOUret/73jemAgNAJhV4PaqdPcXqYtga64DYF2GoAICxWDqnSour/YTKI2+ZiWzgO4NzmZ7xtXHjRq1atUorV65UdXW1tm7dqtLSUm3fvj3ue4LBoK6//npt2LBBZ5999pgKDADILZIB2BdhqACAsQo/BLxm3nTVzp7CoBfyCpEN+cHUwNfg4KD27t2rurq6dz7A61VdXZ1aWlrivu/222/XtGnT9JnPfCal/QwMDKi3tzfqBwBgDdYBsS86awDcgmxq1qMOkI9yHdnAfWYNU6GOR48eVTAYVGVlZdTrlZWVeu6552K+Z8+ePbr77rvV3t6e8n4aGxu1YcMGM0UDAGRReB2Qkdlu/GS7sRRhqADcgGxq1qMOkK+SZTiVpPLSwoxENnCfWSerWR1PnDihT33qU9q2bZumTp2a8vvWrVunQCAQ+Tl06FAWSwkASAXJAOyHMFQATkeCDutRB8hn4ciGRPOujp88rYf2dY1pP9xn1jI142vq1KkqKChQd3d31Ovd3d3y+/2jtt+/f79efvllLVu2LPJaKBQa2vG4cXr++ec1e/bsUe8rLi5WcXGxmaIBAHKAZAD2Eu6srd7RJo8U1WkjDBWA3ZGgw3rUASAtrvarvLRQx0+ejvnvY70P3HqfBUOGYxJjmJrxVVRUpAULFqi5uTnyWigUUnNzs2pra0dtf/755+vpp59We3t75OejH/2oPvjBD6q9vV0zZswY+xEAAJDHSEcPwKlI0GE96gAYug/iDXpJY78P3HifNXV06opvPazrtj2uW3a267ptj+uKbz1s25lrpmZ8SVJ9fb1uvPFGLVy4UIsWLdKmTZvU19enlStXSpJuuOEGTZ8+XY2NjSopKdGcOXOi3l9eXi5Jo14HAADpIR09ACciQYf1qAMg+/eB2+6zcNjmyBls4bBNOz54NT3wtXz5cr3++utav369urq6NG/ePDU1NUUWvD948KC83qwuHQYAAEYgDBWA05Cgw3rUAZD9+8BN95lTwzZND3xJ0po1a7RmzZqY//bII48kfO8999yTzi4BAAAAuEiybGoeDYVtk6Aje6gDIPv3gZvuMzNhm3Z6IMvULAAAAAA5F07QIWlUdloSdOQGdQBk/z5w033m1LDNvB/4CoYMtew/pvvbD6tl/zEFQ4kSmbpv/wAAAIBVSNBhPeoAyP594Jb7zKlhmx7DMGw/0tLb2yufz6dAIKCysrKMfW5TR6c27N4XNVWvyleihmXVObnwrN4/AABulq3+AzKLeoI09DCYBB3Wog6A7N8HTr/PgiFDV3zr4aRhm3tuvTLrx2Wm/5C3A1/xMhGEqybbo65W7x8AALdjQMUZqCcAAJwjPJYhKWo8I9djGWb6D3kZ6pgsE4E0lIkgW2GHVu8fAAAAAADALCeGbaaV1dHprM5EYPX+AQAAAAAA0rF0TpUWV/sdE7aZlwNfVmcisHr/AAAAAAAA6SrwehwzUScvQx2tzkRg9f4BAAAAAADyQV4OfC2aVaEqX4niTcLzaCi74qJZFa7cPwAAAAAAQD7Iy4GvAq9HDcuqJWnU4FP494Zl1VmLT7V6/wAAAAAAAPkgLwe+JOszEVi9fwAAAAAAALfLy8Xtw6zORGD1/gEAAADACsGQwfcgADmR1wNfkvWZCKzePwAAAADkUlNHpzbs3qfOwDtZ7Kt8JWpYVk3kC4CMy9tQRwAAAABAbjV1dGr1jraoQS9J6gr0a/WONjV1dFpUMgBulfczvgAAAAC3c0pYmVPKifQEQ4Y27N4nI8a/GRpK9LVh9z4trvbbvt65VpErTrnW7FxOBr4AAAAAF3NKWJlTyon0tR7oGTXTazhDUmegX60Hemy9HAzXKnLFKdea3ctJqCMAAAAiNm/erJkzZ6qkpEQ1NTVqbW1N6X07d+6Ux+PRtddem90CwhSnhJU5pZwYmyMn4g96pbOdFbhWkStOudacUE4GvgAAACBJ2rVrl+rr69XQ0KC2tjbNnTtXS5Ys0ZEjRxK+7+WXX9ZXvvIVve9978tRSZGKZGFl0lBYWTAUa4vccUo5MXbTJpVkdLtc41pFrjjlWnNKORn4AgAAgCRp48aNWrVqlVauXKnq6mpt3bpVpaWl2r59e9z3BINBXX/99dqwYYPOPvvsHJYWyZgJK7OSU8qJsVs0q0JVvhLFW/XHo6HwqEWzKnJZrJRxrSJXnHKtOaWcDHwBAABAg4OD2rt3r+rq6iKveb1e1dXVqaWlJe77br/9dk2bNk2f+cxnUtrPwMCAent7o36QHU4JK3NKOTF2BV6PGpZVS9Kowa/w7w3Lqm2zIPZIXKvIFadca04pJwNfAAAA0NGjRxUMBlVZWRn1emVlpbq6umK+Z8+ePbr77ru1bdu2lPfT2Ngon88X+ZkxY8aYyp1LwZChlv3HdH/7YbXsP2Z56EYyTgkrc0o5kRlL51Rpy4r58vui69PvK9GWFfNtsRB2PFyr+cXKNt8p15pTyklWRwAAAJh24sQJfepTn9K2bds0derUlN+3bt061dfXR37v7e11xOCX3TNWxRIOK+sK9Mdcf8WjocEGq8PKnFJOZM7SOVVaXO1X64EeHTnRr2mThurXrjO9wrhW84fVbb5TrjWnlJMZXwAAANDUqVNVUFCg7u7uqNe7u7vl9/tHbb9//369/PLLWrZsmcaNG6dx48bpP/7jP/SrX/1K48aN0/79+2Pup7i4WGVlZVE/dueEjFWxOCWszCnlRGYVeD2qnT1F18ybrtrZUxxRv1yr+cEObb5TrjWnlJOBLwAAAKioqEgLFixQc3Nz5LVQKKTm5mbV1taO2v7888/X008/rfb29sjPRz/6UX3wgx9Ue3u7I2ZxpcIpGavicUpYmVPKCXCtupud2nynXGtOKCehjgAAAJAk1dfX68Ybb9TChQu1aNEibdq0SX19fVq5cqUk6YYbbtD06dPV2NiokpISzZkzJ+r95eXlkjTqdSczk7GqdvaU3BXMBKeElTmlnHYUDBmctxwJhgz5xhfpq0vOU0/foComFstfxjl3C7u1+U5pF+1eTga+AAAAIElavny5Xn/9da1fv15dXV2aN2+empqaIgveHzx4UF5vfgUMOCVjVTLhsDK7c0o57cTqtYjySaJzbZcv+BgbO7b5TmkX7VxOBr4AAAAQsWbNGq1Zsybmvz3yyCMJ33vPPfdkvkAWc0rGKuSn8FpEI4OuwmsR2SXMyA041/mBNt+d8uuRHQAAAGBCOGNVvLkcHg3N+LA6YxXyj53WInI7znX+oM13Jwa+AAAAgDickrEK+cfMWkQYG851/qDNdycGvgAAAIAEnJCxCvnHjmsRuRXnOr/Q5rsPa3wBADKGrFIA3MruGatioU12N9Yiyh3OdebZvX1yYpuP+Bj4AgBkBFmlALidnTNWjUSb7H7htYi6Av0x157yaGiGCmsRjR3nOrOc0j45qc1HYoQ6AgDGLJzpaOT6F+FMR00dnRaVDADyD21yfmAtotzhXGcO7ROswMAXAGBMyHQEAPZBm5xfWIsodzjXY0f7BKsQ6ggAGBMzmY6YLg4A2UWbnH9Yiyh3ONdjQ/sEqzDwBQAYEzIdAYB90CbnJ9Yiyh3Odfpon2AVQh0BAGNCpiMAsA/aZAB2RfsEqzDwBQAYk3Cmo3iT/D0aytRDpiMAyD7aZAB2RfsEqzDwBQAYEzIdAYB90CYDsCvaJ1iFgS8AwJiR6QgA7IM2GYBd0T7BCh7DMGyfK7S3t1c+n0+BQEBlZWVWFwcAEEcwZJDpCLZB/8EZqKfsoU0GYFe0TxgrM/0HsjoCADKGTEcAYB+0yQDsivYJuZRWqOPmzZs1c+ZMlZSUqKamRq2trXG3ve+++7Rw4UKVl5drwoQJmjdvnn784x+nXWAAAAAAAAAgFaYHvnbt2qX6+no1NDSora1Nc+fO1ZIlS3TkyJGY21dUVOhrX/uaWlpa9Oc//1krV67UypUr9etf/3rMhQcAAAAAAADiMb3GV01NjS655BJ973vfkySFQiHNmDFDX/jCF7R27dqUPmP+/Pm6+uqrdccdd6S0PWs/AAAAs+g/OAP1BAAAzDLTfzA142twcFB79+5VXV3dOx/g9aqurk4tLS1J328Yhpqbm/X888/rr/7qr+JuNzAwoN7e3qgfAAAAAAAAwAxTA19Hjx5VMBhUZWVl1OuVlZXq6uqK+75AIKCJEyeqqKhIV199tb773e9q8eLFcbdvbGyUz+eL/MyYMcNMMQEAAAAAAID0Frc3a9KkSWpvb9eTTz6pf/7nf1Z9fb0eeeSRuNuvW7dOgUAg8nPo0KFcFBMAAAAAAAAuMs7MxlOnTlVBQYG6u7ujXu/u7pbf74/7Pq/Xq3POOUeSNG/ePD377LNqbGzUBz7wgZjbFxcXq7i42EzRAAAAAAAAgCimZnwVFRVpwYIFam5ujrwWCoXU3Nys2tralD8nFAppYGDAzK4BAAAAAAAAU0zN+JKk+vp63XjjjVq4cKEWLVqkTZs2qa+vTytXrpQk3XDDDZo+fboaGxslDa3XtXDhQs2ePVsDAwN68MEH9eMf/1hbtmzJ7JEAAAAAAAAAw5ge+Fq+fLlef/11rV+/Xl1dXZo3b56ampoiC94fPHhQXu87E8n6+vr0+c9/Xq+++qrGjx+v888/Xzt27NDy5ctT3qdhGJJEdkcAAJCycL8h3I+APdHPAwAAZpnp53kMB/QGX331VTI7AgCAtBw6dEhnnnmm1cVAHPTzAABAulLp5zli4CsUCum1117TpEmT5PF4MvrZvb29mjFjhg4dOqSysrKMfjaS4/xbi/NvPerAWpx/a2X7/BuGoRMnTuiMM86Imo0Oe6Gf516cf2tx/q1HHViL828tO/XzTIc6WsHr9Wb9SW1ZWRk3g4U4/9bi/FuPOrAW599a2Tz/Pp8vK5+LzKGf536cf2tx/q1HHViL828tO/TzePwJAAAAAAAAV2LgCwAAAAAAAK6U9wNfxcXFamhoUHFxsdVFyUucf2tx/q1HHViL828tzj+yjWvMWpx/a3H+rUcdWIvzby07nX9HLG4PAAAAAAAAmJX3M74AAAAAAADgTgx8AQAAAAAAwJUY+AIAAAAAAIArMfAFAAAAAAAAV8rrga/Nmzdr5syZKikpUU1NjVpbW60ukiv8/ve/17Jly3TGGWfI4/Hol7/8ZdS/G4ah9evXq6qqSuPHj1ddXZ1eeOGFqG16enp0/fXXq6ysTOXl5frMZz6jN998M4dH4VyNjY265JJLNGnSJE2bNk3XXnutnn/++aht+vv7dfPNN2vKlCmaOHGi/vqv/1rd3d1R2xw8eFBXX321SktLNW3aNP3DP/yD3nrrrVweimNt2bJFF110kcrKylRWVqba2lr993//d+TfOf+5881vflMej0df/OIXI69x/rPrG9/4hjweT9TP+eefH/l3zj9yhX5e9tDXsw79POvRz7MP+nm559R+Xt4OfO3atUv19fVqaGhQW1ub5s6dqyVLlujIkSNWF83x+vr6NHfuXG3evDnmv/+f//N/9G//9m/aunWrnnjiCU2YMEFLlixRf39/ZJvrr79ezzzzjB566CH913/9l37/+9/rs5/9bK4OwdEeffRR3XzzzXr88cf10EMP6fTp0/rwhz+svr6+yDZf+tKXtHv3bv3sZz/To48+qtdee00f//jHI/8eDAZ19dVXa3BwUI899ph+9KMf6Z577tH69eutOCTHOfPMM/XNb35Te/fu1R//+EddeeWVuuaaa/TMM89I4vznypNPPqkf/OAHuuiii6Je5/xn33vf+151dnZGfvbs2RP5N84/coF+XnbR17MO/Tzr0c+zB/p51nFkP8/IU4sWLTJuvvnmyO/BYNA444wzjMbGRgtL5T6SjF/84heR30OhkOH3+4277ror8trx48eN4uJi49577zUMwzD27dtnSDKefPLJyDb//d//bXg8HuPw4cM5K7tbHDlyxJBkPProo4ZhDJ3vwsJC42c/+1lkm2effdaQZLS0tBiGYRgPPvig4fV6ja6ursg2W7ZsMcrKyoyBgYHcHoBLTJ482fjhD3/I+c+REydOGOeee67x0EMPGe9///uNW265xTAMrv9caGhoMObOnRvz3zj/yBX6eblDX89a9PPsgX5ebtHPs45T+3l5OeNrcHBQe/fuVV1dXeQ1r9eruro6tbS0WFgy9ztw4IC6urqizr3P51NNTU3k3Le0tKi8vFwLFy6MbFNXVyev16snnngi52V2ukAgIEmqqKiQJO3du1enT5+OqoPzzz9f7373u6Pq4MILL1RlZWVkmyVLlqi3tzfyNAupCQaD2rlzp/r6+lRbW8v5z5Gbb75ZV199ddR5lrj+c+WFF17QGWecobPPPlvXX3+9Dh48KInzj9ygn2ct+nq5RT/PWvTzrEE/z1pO7OeNy9on29jRo0cVDAajTrYkVVZW6rnnnrOoVPmhq6tLkmKe+/C/dXV1adq0aVH/Pm7cOFVUVES2QWpCoZC++MUv6vLLL9ecOXMkDZ3foqIilZeXR207sg5i1VH435Dc008/rdraWvX392vixIn6xS9+oerqarW3t3P+s2znzp1qa2vTk08+OerfuP6zr6amRvfcc4/OO+88dXZ2asOGDXrf+96njo4Ozj9ygn6etejr5Q79POvQz7MO/TxrObWfl5cDX0C+uPnmm9XR0REVd43cOO+889Te3q5AIKCf//znuvHGG/Xoo49aXSzXO3TokG655RY99NBDKikpsbo4eekjH/lI5P8vuugi1dTU6KyzztJPf/pTjR8/3sKSAYC70M+zDv08a9DPs55T+3l5Geo4depUFRQUjMou0N3dLb/fb1Gp8kP4/CY6936/f9Tis2+99ZZ6enqoHxPWrFmj//qv/9Lvfvc7nXnmmZHX/X6/BgcHdfz48ajtR9ZBrDoK/xuSKyoq0jnnnKMFCxaosbFRc+fO1Xe+8x3Of5bt3btXR44c0fz58zVu3DiNGzdOjz76qP7t3/5N48aNU2VlJec/x8rLy/We97xHL774Itc/coJ+nrXo6+UG/Txr0c+zBv08+3FKPy8vB76Kioq0YMECNTc3R14LhUJqbm5WbW2thSVzv1mzZsnv90ed+97eXj3xxBORc19bW6vjx49r7969kW0efvhhhUIh1dTU5LzMTmMYhtasWaNf/OIXevjhhzVr1qyof1+wYIEKCwuj6uD555/XwYMHo+rg6aefjuqUPvTQQyorK1N1dXVuDsRlQqGQBgYGOP9Z9qEPfUhPP/202tvbIz8LFy7U9ddfH/l/zn9uvfnmm9q/f7+qqqq4/pET9POsRV8vu+jn2RP9vNygn2c/junnZW3ZfJvbuXOnUVxcbNxzzz3Gvn37jM9+9rNGeXl5VHYBpOfEiRPGU089ZTz11FOGJGPjxo3GU089ZbzyyiuGYRjGN7/5TaO8vNy4//77jT//+c/GNddcY8yaNcs4depU5DOWLl1qXHzxxcYTTzxh7Nmzxzj33HON6667zqpDcpTVq1cbPp/PeOSRR4zOzs7Iz8mTJyPbfO5znzPe/e53Gw8//LDxxz/+0aitrTVqa2sj//7WW28Zc+bMMT784Q8b7e3tRlNTk/Gud73LWLdunRWH5Dhr1641Hn30UePAgQPGn//8Z2Pt2rWGx+MxfvOb3xiGwfnPteHZfgyD859tX/7yl41HHnnEOHDggPGHP/zBqKurM6ZOnWocOXLEMAzOP3KDfl520dezDv0869HPsxf6ebnl1H5e3g58GYZhfPe73zXe/e53G0VFRcaiRYuMxx9/3OoiucLvfvc7Q9KonxtvvNEwjKE017fddptRWVlpFBcXGx/60IeM559/Puozjh07Zlx33XXGxIkTjbKyMmPlypXGiRMnLDga54l17iUZ//f//t/INqdOnTI+//nPG5MnTzZKS0uNj33sY0ZnZ2fU57z88svGRz7yEWP8+PHG1KlTjS9/+cvG6dOnc3w0zvTpT3/aOOuss4yioiLjXe96l/GhD30o0hkyDM5/ro3sEHH+s2v58uVGVVWVUVRUZEyfPt1Yvny58eKLL0b+nfOPXKGflz309axDP8969PPshX5ebjm1n+cxDMPI3nwyAAAAAAAAwBp5ucYXAAAAAAAA3I+BLwAAAAAAALgSA18AAAAAAABwJQa+AAAAAAAA4EoMfAEAAAAAAMCVGPgCAAAAAACAKzHwBQAAAAAAAFdi4AsAAAAAAACuxMAXAAAAAAAAXImBLwAAAAAAALgSA18AAAAAAABwJQa+AAAAAAAA4Er/P2OdwvCbJ/X9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "draw(axes[0], study.get_trials())\n",
    "draw(axes[1], study_rand.get_trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          0.37433155080213903,
          0.5775401069518716,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.6203208556149733,
          0.9518716577540107,
          0.9679144385026738,
          0.9572192513368984,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9572192513368984,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9625668449197861,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.37433155080213903,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9625668449197861,
          0.9679144385026738,
          0.9037433155080213,
          0.9518716577540107,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9625668449197861,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9572192513368984,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.5401069518716578,
          0.9679144385026738,
          0.9572192513368984,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.6684491978609626,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9411764705882353,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.49732620320855614,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9625668449197861,
          0.9732620320855615,
          0.9786096256684492,
          0.9572192513368984,
          0.9572192513368984,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.6684491978609626,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9572192513368984,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9518716577540107,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.7593582887700535,
          0.9625668449197861,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9572192513368984,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.5828877005347594,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9572192513368984,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9518716577540107,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.5240641711229946,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9625668449197861,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9518716577540107,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.7486631016042781,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9572192513368984,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9625668449197861,
          0.9732620320855615,
          0.9625668449197861,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.41711229946524064,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9572192513368984,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9358288770053476,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.5721925133689839,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.44919786096256686,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9572192513368984,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9625668449197861,
          0.9732620320855615,
          0.9732620320855615,
          0.6203208556149733,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9037433155080213,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.40641711229946526,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9625668449197861,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.32085561497326204,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9572192513368984,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.5401069518716578,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9572192513368984,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9518716577540107,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9518716577540107,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.5882352941176471,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9518716577540107,
          0.9679144385026738,
          0.9732620320855615,
          0.9518716577540107,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.4919786096256685,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9625668449197861,
          0.9732620320855615,
          0.9518716577540107,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.40106951871657753,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9625668449197861,
          0.9732620320855615,
          0.9625668449197861,
          0.9679144385026738,
          0.9625668449197861,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9572192513368984,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.5294117647058824,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9518716577540107,
          0.9732620320855615,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9625668449197861,
          0.9679144385026738
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          0.37433155080213903,
          0.5775401069518716,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492,
          0.9786096256684492
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          0.9518716577540107,
          0.9518716577540107,
          0.9679144385026738,
          0.9090909090909091,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.9625668449197861,
          0.9518716577540107,
          0.9411764705882353,
          0.9679144385026738,
          0.9679144385026738,
          0.6684491978609626,
          0.9679144385026738,
          0.6310160427807486,
          0.9679144385026738,
          0.9679144385026738,
          0.7593582887700535,
          0.9625668449197861,
          0.39037433155080214,
          0.9679144385026738,
          0.9679144385026738,
          0.9572192513368984,
          0.8983957219251337,
          0.5828877005347594,
          0.9732620320855615,
          0.8288770053475936,
          0.5614973262032086,
          0.9679144385026738,
          0.5614973262032086,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9572192513368984,
          0.7005347593582888,
          0.9625668449197861,
          0.9625668449197861,
          0.5133689839572193,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9625668449197861,
          0.9518716577540107,
          0.9572192513368984,
          0.5989304812834224,
          0.9679144385026738,
          0.9679144385026738,
          0.946524064171123,
          0.9732620320855615,
          0.9518716577540107,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.6042780748663101,
          0.9732620320855615,
          0.9518716577540107,
          0.9732620320855615,
          0.9679144385026738,
          0.48128342245989303,
          0.37433155080213903,
          0.9679144385026738,
          0.9679144385026738,
          0.40106951871657753,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.732620320855615,
          0.9572192513368984,
          0.9518716577540107,
          0.9679144385026738,
          0.9518716577540107,
          0.93048128342246,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9358288770053476,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9518716577540107,
          0.9572192513368984,
          0.9625668449197861,
          0.6951871657754011,
          0.9518716577540107,
          0.9732620320855615,
          0.8449197860962567,
          0.9518716577540107,
          0.6951871657754011,
          0.9679144385026738,
          0.9679144385026738,
          0.9572192513368984,
          0.9679144385026738,
          0.9518716577540107,
          0.4385026737967914,
          0.5721925133689839,
          0.40106951871657753,
          0.9197860962566845,
          0.7593582887700535,
          0.9679144385026738,
          0.9625668449197861,
          0.9572192513368984,
          0.9572192513368984,
          0.9679144385026738,
          0.9572192513368984,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.8877005347593583,
          0.9625668449197861,
          0.6898395721925134,
          0.9679144385026738,
          0.48663101604278075,
          0.9625668449197861,
          0.9679144385026738,
          0.6737967914438503,
          0.9679144385026738,
          0.9518716577540107,
          0.9518716577540107,
          0.9679144385026738,
          0.6951871657754011,
          0.6631016042780749,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.5882352941176471,
          0.9679144385026738,
          0.5721925133689839,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9732620320855615,
          0.9625668449197861,
          0.9679144385026738,
          0.9572192513368984,
          0.9679144385026738,
          0.5828877005347594,
          0.5935828877005348,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9625668449197861,
          0.5133689839572193,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9572192513368984,
          0.9679144385026738,
          0.9679144385026738,
          0.5080213903743316,
          0.7593582887700535,
          0.6577540106951871,
          0.9679144385026738,
          0.9625668449197861,
          0.6844919786096256,
          0.9679144385026738,
          0.9679144385026738,
          0.9625668449197861,
          0.9518716577540107,
          0.5454545454545454,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9625668449197861,
          0.9679144385026738,
          0.9679144385026738,
          0.6951871657754011,
          0.9679144385026738,
          0.9518716577540107,
          0.9625668449197861,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.3850267379679144,
          0.5347593582887701,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.6256684491978609,
          0.9679144385026738,
          0.9572192513368984,
          0.9518716577540107,
          0.9572192513368984,
          0.9679144385026738,
          0.7540106951871658,
          0.9679144385026738,
          0.9679144385026738,
          0.9572192513368984,
          0.9679144385026738,
          0.45989304812834225,
          0.9518716577540107,
          0.4385026737967914,
          0.6898395721925134,
          0.9625668449197861,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.7914438502673797,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9625668449197861,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9572192513368984,
          0.9625668449197861,
          0.9679144385026738,
          0.946524064171123,
          0.9518716577540107,
          0.9625668449197861,
          0.9572192513368984,
          0.9679144385026738,
          0.9518716577540107,
          0.49732620320855614,
          0.9679144385026738,
          0.40641711229946526,
          0.9518716577540107,
          0.9679144385026738,
          0.5721925133689839,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9625668449197861,
          0.9625668449197861,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9625668449197861,
          0.9625668449197861,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.9572192513368984,
          0.9679144385026738,
          0.946524064171123,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9572192513368984,
          0.7379679144385026,
          0.9518716577540107,
          0.9090909090909091,
          0.9625668449197861,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.6310160427807486,
          0.9625668449197861,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.3850267379679144,
          0.9625668449197861,
          0.40106951871657753,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9572192513368984,
          0.5133689839572193,
          0.9679144385026738,
          0.9625668449197861,
          0.9518716577540107,
          0.9679144385026738,
          0.9090909090909091,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9625668449197861,
          0.9679144385026738,
          0.9572192513368984,
          0.9518716577540107,
          0.9518716577540107,
          0.946524064171123,
          0.9572192513368984,
          0.9518716577540107,
          0.9679144385026738,
          0.9518716577540107,
          0.7540106951871658,
          0.9679144385026738,
          0.9518716577540107,
          0.9625668449197861,
          0.9518716577540107,
          0.5828877005347594,
          0.9732620320855615,
          0.9518716577540107,
          0.9518716577540107,
          0.5401069518716578,
          0.946524064171123,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.7165775401069518,
          0.7433155080213903,
          0.9625668449197861,
          0.9679144385026738,
          0.9679144385026738,
          0.8235294117647058,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.8342245989304813,
          0.9679144385026738,
          0.9679144385026738,
          0.5882352941176471,
          0.946524064171123,
          0.5401069518716578,
          0.8235294117647058,
          0.9625668449197861,
          0.9679144385026738,
          0.5614973262032086,
          0.5828877005347594,
          0.9411764705882353,
          0.6470588235294118,
          0.9679144385026738,
          0.5721925133689839,
          0.9625668449197861,
          0.5614973262032086,
          0.9518716577540107,
          0.49732620320855614,
          0.9572192513368984,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.5614973262032086,
          0.9572192513368984,
          0.679144385026738,
          0.37433155080213903,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.5775401069518716,
          0.9732620320855615,
          0.9732620320855615,
          0.9625668449197861,
          0.9625668449197861,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9411764705882353,
          0.9679144385026738,
          0.47593582887700536,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.7433155080213903,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9358288770053476,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.5721925133689839,
          0.9679144385026738,
          0.9518716577540107,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9625668449197861,
          0.44919786096256686,
          0.4385026737967914,
          0.9679144385026738,
          0.9679144385026738,
          0.39037433155080214,
          0.49732620320855614,
          0.9518716577540107,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.9518716577540107,
          0.5882352941176471,
          0.9518716577540107,
          0.9625668449197861,
          0.9518716577540107,
          0.9679144385026738,
          0.48663101604278075,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9679144385026738,
          0.93048128342246,
          0.9679144385026738,
          0.9572192513368984,
          0.9572192513368984,
          0.9358288770053476,
          0.4385026737967914,
          0.9679144385026738,
          0.8770053475935828,
          0.9679144385026738,
          0.5882352941176471,
          0.9679144385026738,
          0.9679144385026738,
          0.6951871657754011,
          0.9732620320855615,
          0.9679144385026738,
          0.9679144385026738,
          0.9518716577540107,
          0.9625668449197861,
          0.40106951871657753,
          0.9518716577540107,
          0.9679144385026738,
          0.9090909090909091,
          0.9518716577540107,
          0.6631016042780749,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.5347593582887701,
          0.9518716577540107,
          0.9679144385026738,
          0.9625668449197861,
          0.9625668449197861,
          0.9732620320855615,
          0.9679144385026738,
          0.9518716577540107,
          0.5401069518716578,
          0.48663101604278075,
          0.9518716577540107,
          0.5721925133689839,
          0.9625668449197861,
          0.9679144385026738,
          0.9518716577540107,
          0.9679144385026738,
          0.9411764705882353,
          0.9358288770053476,
          0.9679144385026738,
          0.5401069518716578,
          0.9572192513368984,
          0.9679144385026738,
          0.9518716577540107,
          0.9572192513368984,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9518716577540107,
          0.9518716577540107,
          0.93048128342246,
          0.43315508021390375,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.40106951871657753,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          0.9518716577540107,
          0.9518716577540107,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9679144385026738,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615,
          0.9732620320855615
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study_rand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите также информацию о полезности гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "probability (CategoricalDistribution): 0.015189562879919872<extra></extra>",
          "shrinking (CategoricalDistribution): 0.03223005772391176<extra></extra>",
          "C (FloatDistribution): 0.05600250017828376<extra></extra>",
          "kernel (CategoricalDistribution): 0.8965778792178846<extra></extra>"
         ],
         "marker": {
          "color": "rgb(66,146,198)"
         },
         "orientation": "h",
         "text": [
          "0.02",
          "0.03",
          "0.06",
          "0.90"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.015189562879919872,
          0.03223005772391176,
          0.05600250017828376,
          0.8965778792178846
         ],
         "y": [
          "probability",
          "shrinking",
          "C",
          "kernel"
         ]
        }
       ],
       "layout": {
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Importance for Objective Value"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = optuna.visualization.plot_param_importances(study, params=[\"C\", \"kernel\", \"shrinking\", \"probability\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "weights (CategoricalDistribution): 0.0009334421191644106<extra></extra>",
          "p (FloatDistribution): 0.020961154927432633<extra></extra>",
          "n_neighbors (IntDistribution): 0.9781054029534029<extra></extra>"
         ],
         "marker": {
          "color": "rgb(66,146,198)"
         },
         "orientation": "h",
         "text": [
          "<0.01",
          "0.02",
          "0.98"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.0009334421191644106,
          0.020961154927432633,
          0.9781054029534029
         ],
         "y": [
          "weights",
          "p",
          "n_neighbors"
         ]
        }
       ],
       "layout": {
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Importance for Objective Value"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = optuna.visualization.plot_param_importances(study_rand, params=[\"n_neighbors\", \"weights\", \"p\"])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
